{"meta":{"title":"小余哥|猿无忧","subtitle":"","description":"小余哥个人博客，致力于分享一些技术教程和有趣的技术实践，以及日常踩坑记录。","author":"小余哥|猿无忧","url":"https://xiaoyuge5201.github.io","root":"/"},"pages":[{"title":"简单的聊下自己","date":"2022-05-28T09:17:44.296Z","updated":"2022-05-28T09:17:44.296Z","comments":true,"path":"about/index.html","permalink":"https://xiaoyuge5201.github.io/about/index.html","excerpt":"","text":"现在的年纪还没有到写自传的时候，只能是在这里简简单单的聊下自己。 我呢，一个普普通通的程序猿。没错就是大家眼中那种熬夜猝死、脱发、肥胖、死宅、一个书包走天下的一类人。 平时无非就是加加班、打打游戏、看看博客、偶尔追剧，和大部分普通人也没多大区别； 长相呢，也就那样(请勿舔屏，谢谢) 和下面这四位以及屏幕前的你霸占江湖颜值榜多年 不过岁月是把杀猪刀，谁也逃不过；哎，不说了，都是泪！！！ 弄这个博客网呢，也就是在学习、工作中遇到了一些问题或者学习到一些东西，在这上面记录一下，当然博客都是一搜一大把，而且内容也大差不差的，这无可厚非； 暂时写到这里（其实也没啥写的），在下面贴一些鸡汤请大家喝，毕竟看到这里也累了，喝一碗再走。 1.你真正喜欢想要的，没有一样是可以轻易得到的。 2.愿我走过的苦难你不必经历，愿我已有的幸福你正在触及。 3.打你脸的时候别问我为什么，因为我给你糖的时候你从来不会说谢谢。 4.习惯这个东西很可怕，特别是你不得不面对改变的时候。 5.这个世界就是这样，总有一大群人和你一起欢笑，却只有一个人陪你黯然神伤。 6.喜欢就争取，得到就珍惜，错过就忘记。 7.不要总去顾及别人的目光，做好自己，青春无悔。"},{"title":"404 Not Found：该页无法显示","date":"2022-03-27T14:06:03.328Z","updated":"2022-03-27T14:06:03.328Z","comments":true,"path":"/404.html","permalink":"https://xiaoyuge5201.github.io/404.html","excerpt":"","text":""},{"title":"书单","date":"2022-05-28T09:20:39.996Z","updated":"2022-05-28T09:20:39.996Z","comments":true,"path":"books/index.html","permalink":"https://xiaoyuge5201.github.io/books/index.html","excerpt":"","text":""},{"title":"友链","date":"2022-05-28T09:21:27.578Z","updated":"2022-05-28T09:21:27.578Z","comments":true,"path":"links/index.html","permalink":"https://xiaoyuge5201.github.io/links/index.html","excerpt":"","text":""},{"title":"个人项目","date":"2022-05-28T09:20:26.265Z","updated":"2022-05-28T09:20:26.265Z","comments":true,"path":"repository/index.html","permalink":"https://xiaoyuge5201.github.io/repository/index.html","excerpt":"","text":""},{"title":"博客分类","date":"2022-05-28T09:21:03.090Z","updated":"2022-05-28T09:21:03.090Z","comments":true,"path":"categories/index.html","permalink":"https://xiaoyuge5201.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-03-27T14:06:03.489Z","updated":"2022-03-27T14:06:03.489Z","comments":true,"path":"tags/index.html","permalink":"https://xiaoyuge5201.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"专题—接口设计","slug":"special-interface","date":"2022-11-23T12:58:03.000Z","updated":"2022-11-26T08:23:45.811Z","comments":false,"path":"special-interface/","link":"","permalink":"https://xiaoyuge5201.github.io/special-interface/","excerpt":"","text":"1. 接口的幂等性 1.1 幂等性描述 幂等是一个数据和计算机学概念，在数学中某一元运算为幂等时，作用多次和作用一次的结果相同 在数学中，幂等用函数表达式就是：f(x) = f(f(x)) 1.2 接口幂等性 在HTTP/1.1中，对幂等性进行类定义，它描述一次和多次请求某个资源对资源本身应该具有同样的结果（网络超时等问题除外）， 即多次调用方法或者接口不会改变业务状态，可以保证重复调用的结果和单次调用的结果一致。 幂等性指的是作用于结果而非资源本身。例如，HTTP GET方法可能会每次得到不同的返回内容，但并不影响资源。 1.3 为什么需要实现幂等性 在接口调用时一般情况下都能正常返回信息不会出现重复提交，不过出现以下几种情况会有问题，如： 前端重复提交表单：比如用户注册时，因网络波动没有及时对用户做出提交成功响应，致使用户认为没有提交成功，然后多次进行提交操作，这时就会发生重复提交请求 用户恶意刷单：比如用户投票，如果用户针对一个内容重复提交投票，接口接收到用户重复提交的投票信息，影响实际的计算结果 接口超时重复提交：如果存在超时重试机制，尤其是第三方调用接口时，为了防止网络波动超时等造成的请求失败，都会添加重试机制，导致一个请求多次提交 消息进行重复消费：当使用MQ消息中间件时，如果发生消息中间件出现错误为即使提交消费消息，导致发生重复消费； 使用幂等性最大的优势在于使接口保证任何幂等性操作，避免因重试等造成系统未知问题。 1.4 幂等性对系统的影响 幂等性时为了简化客户端逻辑处理，能防止重复提交等操作，但也额外增加了服务端业务逻辑复杂性，主要是 把并行执行的功能改成了串行，降低了执行效率 增加了额外控制幂等的业务代码，使原本的业务功能复杂化 所以我们需要根据实际的业务场景来考虑是否引入幂等性 1.5 Restful API 接口的幂等性 现在流行的Restful 推荐的几种HTTP方法中幂等性如下： 类型 是否幂等 描述 GET 是 Get 方法用于获取资源。其一般不会也不应当对系统资源进行改变，所以是幂等的 POST 否 Post 方法一般用于创建新的资源。其每次执行都会新增数据，所以不是幂等的 PUT - Put 方法一般用于更新资源。该操作则分情况来判断是不是满足幂等，更新操作中直接根据某个值进行更新，也能保持幂等。不过执行累加操作的更新是非幂等 DELETE - Delete 方法一般用于删除资源。该操作则分情况来判断是不是满足幂等，当根据唯一值进行删除时，删除同一个数据多次执行效果一样。不过需要注意，带查询条件的删除则就不一定满足幂等了。例如在根据条件删除一批数据后，这时候新增加了一条数据也满足条件，然后又执行了一次删除，那么将会导致新增加的这条满足条件数据也被删除。 1.6 实现幂等性的方案 方案1：数据库唯一主键 描述 利用数据库主键唯一约束的特性，依赖来说唯一主键比较适用于插入时的幂等性，其能保证一张表只能存在一条带该唯一主键的记录 使用数据库唯一主键完成幂等性时需要注意的是，该主键一般来说并不是使用数据库自增主键，而是使用分布式ID作为主键，这样才能保证在分布式环境下ID的全局一致性 使用操作 插入 删除 使用限制 需要生成全局唯一主键ID 主要流程 分布式ID服务可以使用Snowflake算法、数据库号段模式、Redis自增等方式生成； 方案2：数据库乐观锁 描述 一般只适用于更新操作的过程，在表中增加version版本字段，每次对该表的这条数据更新时，都会带上上次更新后的version值 使用操作 更新 使用限制 需要在业务表中添加额外字段 主要流程 方案3：防重Token令牌 描述 针对客户端连续点击或者调用方的超时重试等情况，例如提交订单，此种操作就可以用 Token 的机制实现防止重复提交。简单的说就是调用方在调用接口的时候先向后端请求一个全局 ID（Token），请求的时候携带这个全局 ID 一起请求（Token 最好将其放到 Headers 中），后端需要对这个 Token 作为 Key，用户信息作为 Value 到 Redis 中进行键值内容校验，如果 Key 存在且 Value 匹配就执行删除命令，然后正常执行后面的业务逻辑。如果不存在对应的 Key 或 Value 不匹配就返回重复执行的错误信息，这样来保证幂等操作 使用操作 更新 插入 使用限制 需要生成全局唯一 Token串 需要使用Redis进行数据校验 主要流程 Token可以是一个序列号，也可以是分布式ID或者UUID串 验证成功：说明存在该token，是第一次调用接口，可以执行后面的业务代码，同时在redis中删除该token 验证失败：说明存在该token，是重复调用接口，不可以执行后面的业务代码； 注意，在并发情况下，执行 Redis 查找数据与删除需要保证原子性，否则很可能在并发下无法保证幂等性。其实现方法可以使用分布式锁或者使用 Lua 表达式来注销查询与删除操作。 方案4：下游传递唯一序列号 描述 所谓请求序列号，其实就是每次向服务端请求时候附带一个短时间内唯一不重复的序列号，该序列号可以是一个有序 ID，也可以是一个订单号，一般由下游生成，在调用上游服务端接口时附加该序列号和用于认证的 ID。 当上游服务器收到请求信息后拿取该 序列号 和下游 认证ID 进行组合，形成用于操作 Redis 的 Key，然后到 Redis 中查询是否存在对应的 Key 的键值对，根据其结果： 如果存在，就说明已经对该下游的该序列号的请求进行了业务处理，这时可以直接响应重复请求的错误信息。 如果不存在，就以该 Key 作为 Redis 的键，以下游关键信息作为存储的值（例如下游商传递的一些业务逻辑信息），将该键值对存储到 Redis 中 ，然后再正常执行对应的业务逻辑即可。 使用操作 更新 插入 删除 使用限制 需要第三方传递唯一序列号 需要使用Redis进行数据校验 主要流程 ① 下游服务生成分布式 ID 作为序列号，然后执行请求调用上游接口，并附带“唯一序列号”与请求的“认证凭据ID”。 ② 上游服务进行安全效验，检测下游传递的参数中是否存在“序列号”和“凭据ID”。 ③ 上游服务到 Redis 中检测是否存在对应的“序列号”与“认证ID”组成的 Key，如果存在就抛出重复执行的异常信息，然后响应下游对应的错误信息。如果不存在就以该“序列号”和“认证ID”组合作为 Key，以下游关键信息作为 Value，进而存储到 Redis 中，然后正常执行接来来的业务逻辑。 上面步骤中插入数据到 Redis 一定要设置过期时间。这样能保证在这个时间范围内，如果重复调用接口，则能够进行判断识别。如果不设置过期时间，很可能导致数据无限量的存入 Redis，致使 Redis 不能正常工作。 总结 对于下单等存在唯一主键的可以使用&quot;唯一主键方案&quot;的方式实现 对于更新订单状态等相关的更新场景操作，可以使用&quot;乐观锁方案&quot; 对于上下游这种，下游请求上游，上游服务可以使用&quot;下游传递唯一序列号方案&quot;更为合理 类似于前端重复提交、重复下单、没有唯一ID号的场景，可以通过token与Redis配置的&quot;防重Token方案&quot;更为快捷 方案 适用方法 复杂度 缺点 数据库唯一主键 插入、删除 简单 只能用于存在唯一主键的场景 数据库乐观锁 更新 简单 只能用于更新操作，表中需要添加额外字段 请求序列号 插入、删除、更新 简单 1. 需要保证下游生成唯一序列号； 2. 需要Redis存储序列号 防重Token令牌 插入、更新、删除 适中 需要Redis存储序列号 2. SpringBoot 防重Token令牌方案 该方案能保证在不同请求动作下的幂等性，实现逻辑可以看上面写的”防重Token令牌”方案; 2.1 引入相关依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;idempotent-token&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;idempotent-token&lt;/name&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;parent&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;version&gt;2.3.5.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 2.2 配置文件 123456789101112131415# 配置redis连接参数spring: redis: ssl: false host: localhost port: 6379 database: 0 timeout: 1000 password: lettuce: pool: max-active: 100 max-wait: -1 min-idle: 0 max-idle: 20 2.3 Token获取/验证接口 创建用于操作Token相关的Service类，包含创建token以及验证方法，其中： Token创建： 使用UUID工具创建token串，设置IDEMPOTENT_TOKEN_PREFIX:+token串作为key,以用户信息作为value，存入Redis; Token验证：接口Token串参数，加上前缀生成key，再传入用户信息value,使用Lua表达式（Lua表达式能保证命令执行的原子性）进行查找对应的key和value，执行完成后验证命令的返回结果，如果不为空且非0则验证成功，反之则失败; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * @author xiaoyuge */@Slf4j@Servicepublic class TokenUtilService &#123; @Autowired private StringRedisTemplate redisTemplate; /** * redis 的token键前缀 */ private static final String IDEMPOTENT_TOKEN_PREFIX = &quot;IDEMPOTENT_TOKEN:&quot;; /** * 创建token存入redis， 并返回token * @param value 用于辅助验证的value * @return token串 */ public String generateToken(String value) &#123; String token = UUID.randomUUID().toString(); //拼接redis key String key = IDEMPOTENT_TOKEN_PREFIX + token; //存储到redis 中，设置过期时间为5分钟 redisTemplate.opsForValue().set(key, value, 5, TimeUnit.MINUTES); return token; &#125; /** * 验证token的正确性 * @param token token字符串 * @param value 辅助验证信息 * @return 验证结果 */ public boolean validateToken(String token, String value) &#123; //设置Lua脚本，其中KEY[1] 是key, KEYS[2] 是value； 如果根据key获取到的值是value,那么删除key否则返回0 String script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == KEYS[2] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; RedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(script, Long.class); //拼接key String key = IDEMPOTENT_TOKEN_PREFIX + token; //执行lua脚本，传递数组参数[key, value] Long result = redisTemplate.execute(redisScript, Arrays.asList(key, value)); if (result == null &amp;&amp; result != 0L) &#123; log.info(&quot;验证token= &#123;&#125;,key=&#123;&#125;, value=&#123;&#125;成功&quot;, token, key, value); return true; &#125; return false; &#125;&#125; 2.4 创建Controller 创建用于测试的 Controller 类，里面有获取 Token 与测试接口幂等性的接口，内容如下： 123456789101112131415161718192021222324252627282930313233343536/** * @author xiaoyuge */@Slf4j@RestControllerpublic class TokenController &#123; @Resource private TokenUtilService tokenUtilService; /** * 获取token * @return token串 */ @GetMapping(&quot;/token&quot;) public String getToken()&#123; //获取用户信息 String username = &quot;xiaoyuge&quot;; //使用用户信息作为辅助验证 //获取token并返回 return tokenUtilService.generateToken(username); &#125; /** * 接口幂等性测试接口 * @param token token串 * @return 执行结果 */ @PostMapping(&quot;/test&quot;) public String testIdempotence(@RequestHeader(value = &quot;token&quot;) String token)&#123; //获取用户信息，和上面保持一样的业务逻辑 String username = &quot;xiaoyuge&quot;; //根据token和用户相关信息到redis验证是否存在对应的信息 boolean result = tokenUtilService.validateToken(token, username); return result ? &quot;正常调用&quot;:&quot;重复调用&quot;; &#125;&#125; 2.5 创建Springboot启动类 123456@SpringBootApplicationpublic class IdempotentApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(IdempotentApplication.class, args); &#125;&#125; 2.6 创建测试类 测试多次访问同一个接口，是否只有第一次执行成功 12345678910111213141516171819202122232425262728@Slf4j@SpringBootTest@RunWith(SpringRunner.class)public class IdempotentTest &#123; @Autowired private WebApplicationContext webApplicationContext; @Test public void interfaceIdempotenceTest() throws Exception &#123; //初始化MockMvc MockMvc mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); //调用获取 token 接口 String token = mockMvc.perform(MockMvcRequestBuilders.get(&quot;/token&quot;) .accept(MediaType.TEXT_HTML)) .andReturn() .getResponse().getContentAsString(); log.info(&quot;获取的token串：&#123;&#125;&quot;, token); for (int i = 0; i &lt; 5; i++) &#123; log.info(&quot;第&#123;&#125;次调用接口&quot;, i+1); String result = mockMvc.perform(MockMvcRequestBuilders.post(&quot;/test&quot;) .header(&quot;token&quot;, token) .accept(MediaType.TEXT_HTML)) .andReturn().getResponse().getContentAsString(); log.info(&quot;调用结果:&#123;&#125;&quot;, result); &#125; &#125;&#125; 调用结果返回如下： 1234567891011[main] org.example.IdempotentTest : 获取的token串：ed965e9e-42ce-4865-a1fd-25d13ad5544b[main] org.example.IdempotentTest : 第1次调用接口[main] org.example.IdempotentTest : 调用结果:正常调用[main] org.example.IdempotentTest : 第2次调用接口[main] org.example.IdempotentTest : 调用结果:重复调用[main] org.example.IdempotentTest : 第3次调用接口[main] org.example.IdempotentTest : 调用结果:重复调用[main] org.example.IdempotentTest : 第4次调用接口[main] org.example.IdempotentTest : 调用结果:重复调用[main] org.example.IdempotentTest : 第5次调用接口[main] org.example.IdempotentTest : 调用结果:重复调用","categories":[{"name":"interface","slug":"interface","permalink":"https://xiaoyuge5201.github.io/categories/interface/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]},{"title":"破解LIMIT和OFFSET分页性能瓶颈","slug":"limit-offset","date":"2022-11-20T04:56:15.000Z","updated":"2022-11-20T12:10:19.948Z","comments":false,"path":"limit-offset/","link":"","permalink":"https://xiaoyuge5201.github.io/limit-offset/","excerpt":"","text":"1. 分页方法分类 LIMIT X 12-- LIMIT X 表示: 读取 X 条数据select * from user limit 20 LIMIT Y OFFSET X 123-- LIMIT Y OFFSET X 表示: 跳过 X 条数据，读取 Y 条数据select * from user limit 20 OFFSET 10-- 从第10+1 行开始读取20条数据 LIMIT X, Y 12-- 跳过 X 条数据，读取 Y 条数据select * from user limit 20 , 10 对于简单的小型应用程序和数据量不是很大的场景，这种方式还是没有问题的，但是一旦数据量过大，这种分页方式存在瓶颈。 2. LIMIT和OFFSET 的问题 OFFSET 和 LIMIT 对于数据量少的项目来说是没有问题的，但是，当数据库里的数据量超过服务器内存能够存储的能力，并且需要对所有数据进行分页，问题就会出现，为了实现分页，每次收到分页请求时，数据库都需要进行低效的全表遍历 全表遍历就是一个全表扫描的过程，就是根据双向链表把磁盘上的数据页加载到磁盘的缓存页里去，然后在缓存页内部查找那条数据，这个过程是非常满的，所以说当数据量大的时候，全表遍历的性能非常低，时间特别长，应该尽量避免全表遍历 为了获取一页的数据：10万行中的第50000行到第50020行需要先获取 5 万行，这么做非常低效！ 3. 初探LIMIT查询效率 3.1 建表 测试数据库采用的是（存储引擎采用InnoDB） 表结构如下： 123456CREATE TABLE `user` ( `id` int NOT NULL AUTO_INCREMENT, `name` varchar(100) DEFAULT NULL, `age` int DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 3.2 插入数据 12345678910111213-- 创建存储过程， 参数param1 为int 类型CREATE DEFINER=`root`@`localhost` PROCEDURE `insert_limit_test`(param1 int)BEGIN -- for循环遍历 插入 350万条数据 WHILE param1 &lt; 3500000 DO -- 插入表数据 INSERT INTO `user` ( `name`, `age` ) VALUES (CONCAT(&#x27;name_&#x27;,param1) , (param1 % 4)+10 ); SET param1 = param1 + 1; END WHILE;END;-- 调用存储过程CALL insert_limit_test(1); 1234567mysql&gt; select count(*) from user;+----------+| count(*) |+----------+| 3499999 |+----------+1 row in set (0.11 sec) 3.3 开始测试 首先偏移量设置为0，取20条数据(中间输出省略) 1234567891011mysql&gt; select * from user limit 0,20;+----+---------+------+| id | name | age |+----+---------+------+| 1 | name_1 | 11 |#...中间输出省略| 18 | name_18 | 12 || 19 | name_19 | 13 || 20 | name_20 | 10 |+----+---------+------+20 rows in set (0.00 sec) 可以看到查询时间基本忽略不计，于是我们要一步一步的加大这个偏移量然后进行测试，先将偏移量改为10000(中间输出省略)： 123456789101112mysql&gt; select * from user limit 10000,20;+-------+------------+------+| id | name | age |+-------+------------+------+| 10001 | name_10001 | 11 || 10002 | name_10002 | 12 | #...中间输出省略| 10018 | name_10018 | 12 || 10019 | name_10019 | 13 || 10020 | name_10020 | 10 |+-------+------------+------+20 rows in set (0.00 sec) 可以看到查询时间还是非常短的，几乎可以忽略不计，于是我们将偏移量直接上到340W(中间输出省略)： 1234567891011mysql&gt; select * from user limit 3400000,20;+---------+--------------+------+| id | name | age |+---------+--------------+------+| 3400001 | name_3400001 | 11 |#...中间输出省略| 3400018 | name_3400018 | 12 || 3400019 | name_3400019 | 13 || 3400020 | name_3400020 | 10 |+---------+--------------+------+20 rows in set (0.48 sec) 这个时候就可以看到非常明显的变化了，查询时间增到了0.48s。 3.4 分析原因 根据下面的结果可以看到三条查询语句都进行了全表扫描： 1234567891011121314151617181920212223mysql&gt; explain select * from user limit 0,20;+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+| 1 | SIMPLE | user | NULL | ALL | NULL | NULL | NULL | NULL | 3493299 | 100.00 | NULL |+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+1 row in set, 1 warning (0.00 sec)mysql&gt; explain select * from user limit 10000, 20;+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+| 1 | SIMPLE | user | NULL | ALL | NULL | NULL | NULL | NULL | 3493299 | 100.00 | NULL |+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+1 row in set, 1 warning (0.01 sec)mysql&gt; explain select * from user limit 3400000, 20;+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+| 1 | SIMPLE | user | NULL | ALL | NULL | NULL | NULL | NULL | 3493299 | 100.00 | NULL |+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+1 row in set, 1 warning (0.00 sec) 此时就可以知道的是，在偏移量非常大的时候，就像案例中的LIMIT 3400000,20这样的查询。 此时MySQL就需要查询3400020行数据，然后在返回最后20条数据。 前边查询的340W数据都将被抛弃，这样的执行结果可不是我们想要的。 接下来就是优化大偏移量的性能问题 4. 优化 1SELECT * FROM user WHERE id&gt;10 limit 20 这是一种基于指针的分页。你要在本地保存上一次接收到的主键 (通常是一个 ID) 和 LIMIT，而不是 OFFSET 和 LIMIT，那么每一次的查询可能都与此类似。 为什么？因为通过显式告知数据库最新行，数据库就确切地知道从哪里开始搜索（基于有效的索引），而不需要考虑目标范围之外的记录。 我们再来一次测试(中间输出省略)： 123456789101112131415161718mysql&gt; select * from user where id &gt; 3400000 limit 20;+---------+--------------+------+| id | name | age |+---------+--------------+------+| 3400001 | name_3400001 | 11 |#....中间输出省略| 3400019 | name_3400019 | 13 || 3400020 | name_3400020 | 10 |+---------+--------------+------+20 rows in set (0.00 sec)mysql&gt; EXPLAIN SELECT * FROM user WHERE id&gt;3400000 LIMIT 20;+----+-------------+-------+------------+-------+---------------+---------+---------+------+--------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+------+--------+----------+-------------+| 1 | SIMPLE | user | NULL | range | PRIMARY | PRIMARY | 4 | NULL | 198326 | 100.00 | Using where |+----+-------------+-------+------------+-------+---------------+---------+---------+------+--------+----------+-------------+1 row in set, 1 warning (0.00 sec) 返回同样的结果，第一个查询使用了0.48 sec，而第二个仅用了0.00 sec。 注意：如果我们的表没有主键，比如是具有多对多关系的表，那么就使用传统的 OFFSET/LIMIT 方式，只是这样做存在潜在的慢查询问题。所以建议在需要分页的表中使用自动递增的主键，即使只是为了分页。 继续优化 类似于查询 SELECT * FROM table_name WHERE id &gt; 3400000 LIMIT 20; 这样的效率非常快,因为主键上是有索引的,但是这样有个缺点,就是ID必须是连续的,并且查询不能有WHERE语句,因为WHERE语句会造成过滤数据。那使用场景就非常的局限了，于是我们可以这样 使用覆盖索引优化 mysql的查询完全命中索引的时候，称为覆盖索引，是非常快的，因为查询只需要在索引上进行查找，之后就可以直接返回，而不用再回数据表那数据，因此我们可以先查处索引的ID，然后根据ID取数据 123456789101112-- user 为表名SELECT * FROM (SELECT id FROM user LIMIT 3400000,20) a LEFT JOIN user b ON a.id = b.id;mysql&gt; explain SELECT * FROM (SELECT id FROM user LIMIT 3400000,20) a LEFT JOIN user b ON a.id = b.id;+----+-------------+------------+------------+--------+---------------+---------+---------+------+---------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+------------+------------+--------+---------------+---------+---------+------+---------+----------+-------------+| 1 | PRIMARY | &lt;derived2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | 3400020 | 100.00 | NULL || 1 | PRIMARY | b | NULL | eq_ref | PRIMARY | PRIMARY | 4 | a.id | 1 | 100.00 | NULL || 2 | DERIVED | user | NULL | index | NULL | PRIMARY | 4 | NULL | 3493299 | 100.00 | Using index |+----+-------------+------------+------------+--------+---------------+---------+---------+------+---------+----------+-------------+3 rows in set, 1 warning (0.00 sec) 或者是 1234567891011SELECT * FROM user a INNER JOIN (SELECT id FROM user LIMIT 3400000,20) b USING (id);mysql&gt; explain SELECT * FROM user a INNER JOIN (SELECT id FROM user LIMIT 3400000,20) b USING (id);+----+-------------+------------+------------+--------+---------------+---------+---------+------+---------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+------------+------------+--------+---------------+---------+---------+------+---------+----------+-------------+| 1 | PRIMARY | &lt;derived2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | 3400020 | 100.00 | NULL || 1 | PRIMARY | a | NULL | eq_ref | PRIMARY | PRIMARY | 4 | b.id | 1 | 100.00 | NULL || 2 | DERIVED | user | NULL | index | NULL | PRIMARY | 4 | NULL | 3493299 | 100.00 | Using index |+----+-------------+------------+------------+--------+---------------+---------+---------+------+---------+----------+-------------+3 rows in set, 1 warning (0.00 sec) 5. 总结 数据量大的时候不能使用OFFSET/LIMIT来进行分页，因为OFFSET越大，查询时间越久。 当然不能说所有的分页都不可以，如果你的数据就那么几千、几万条，那就很无所谓，随便使用。 如果我们的表没有主键，比如是具有多对多关系的表，那么就使用传统的 OFFSET/LIMIT 方式。 这种方法适用于要求ID为数值类型，并且查出的数据ID连续的场景且不能有其他字段的排序。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"select ... for update表锁还是行锁","slug":"select-for-update","date":"2022-11-03T13:40:16.000Z","updated":"2022-11-03T15:20:46.270Z","comments":false,"path":"select-for-update/","link":"","permalink":"https://xiaoyuge5201.github.io/select-for-update/","excerpt":"","text":"1. 概要 Select 查询语句是不会枷锁的，但是Select … for update 除了有查询语句的作用，还是加锁，而且是悲观锁。 使用索引： 行锁 未使用索引：表锁 2. 建表 123456789101112131415--建表语句CREATE TABLE t_user ( id INT ( 11 ) NOT NULL AUTO_INCREMENT, name VARCHAR ( 255 ) DEFAULT NULL, age INT ( 11 ) DEFAULT NULL, addr VARCHAR ( 255 ) DEFAULT NULL, PRIMARY KEY ( id ), -- 主键索引 KEY idx_age ( age ) USING BTREE -- 唯一索引) ENGINE = INNODB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8;-- 插入数据INSERT INTO t_user (name, age, addr) VALUES (&#x27;张三&#x27;, 12, &#x27;上海&#x27;);INSERT INTO t_user (name, age, addr) VALUES (&#x27;李四&#x27;, 31, &#x27;广东&#x27;);INSERT INTO t_user (name, age, addr) VALUES (&#x27;王五&#x27;, 32, &#x27;南昌&#x27;);INSERT INTO t_user (name, age, addr) VALUES (&#x27;赵六&#x27;, 24, &#x27;广东&#x27;); 需要关闭自动提交，通过set @@autocommit = 0;设置为手动提交，0代表手动提交，1代表自动提交 3. 验证 3.1 场景一 使用主键id为1条件去查询，然后开启另一个事务对主键id为1对数据进行更新； 第一个事务使用select … for update查询，没有提交事务； 第二个事务，去更新主键id为1的数据，被阻塞了，长时间拿不到锁导致报错 结论：使用主键字段进行select … for update操作会锁住当前记录。 3.2 场景二 使用主键id=1为条件查询，开启另一个事务对主键id=2的数据进行更新 第一个事务使用select … for update查询，没有提交事务； 第二个事务对另一条id为2的数据更新，可以看到更新成功。 结论：使用主键字段进行select … for update操作会锁住当前记录，其他行数据可以进行正常的更新操作。 3.3 场景三 使用 唯一索引age12 查询，开启另一个事务对 唯一索引age=12 的数据进行更新 第一个事务使用select … for update查询，没有提交事务； 第二个事务对age=12的数据更新，被阻塞了。 结论：使用唯一索引字段进行select … for update操作会锁住当前记录，其他数据可以进行正常的更新操作。 3.4 场景四 使用普通字段 addr 进行操作 第一个事务使用select … for update查询，没有提交事务； 第二个事务进行任何数据更新操作，被阻塞了。 结论：使用非索引字段进行select … for update操作都会锁表，没有commit之前任何更新操作无法获取锁。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"过滤器Filter与拦截器区别","slug":"filter-interceptor","date":"2022-10-29T14:25:32.000Z","updated":"2022-10-30T04:28:48.707Z","comments":false,"path":"filter-interceptor/","link":"","permalink":"https://xiaoyuge5201.github.io/filter-interceptor/","excerpt":"","text":"1. 过滤器（Filter） Servlet中的过滤器Filter实现了javax.servlet.Filter接口的服务器端程序，主要用途是设置字符集（CharacterEncodingFilter）、控制权限、控制转向、用户是否已经登陆、有没有权限访问该页面等。其工作原理是，只要你在web.xml文件配置好要拦截的客户端请求，它都会帮你拦截到请求，此时，其实你可以对请求或响应(Request、response)统一设置编码； 它web应用启动而启动，只初始化一次，以后就可以拦截相关请求，只有当你的web应用停止或重新部署的时候才销毁。 Filter可以认为是Servlet的一种&quot;加强版&quot;，它主要用于对用户请求进行预处理，也可以对HttpServletResponse进行后处理，是个典型的处理链。 Filter可以对用户请求生成响应，和Servlet相同 处理流程：用户请求-&gt;Filter预处理-&gt;Servlet处理请求生成响应-&gt;Filter对响应进行后处理 1.1 Filter用处 在HttpServletRequest到达Servlet之前，拦截客户的HttpServletRequest。 根据需要检查HttpServletRequest，也可以修改HttpServletRequest头和数据。 在HttpServletResponse到达客户端之前，拦截HttpServletResponse。 根据需要检查HttpServletResponse，也可以修改HttpServletResponse头和数据。 Filter有如下几个种类。 1.2 Filter种类 用户授权的Filter：Filter负责检查用户请求，根据请求过滤用户非法请求。 日志Filter：详细记录某些特殊的用户请求。 负责解码的Filter:包括对非标准编码的请求解码。 能改变XML内容的XSLT Filter等。 Filter可以负责拦截多个请求或响应；一个请求或响应也可以被多个Filter拦截。 1.3 创建Filter步骤 创建Filter处理类，并实现javax.servlet.Filter接口 web.xml文件中配置Filter（或者使用@WebFilter注解） javax.servlet.Filter接口中中定义的三个方法： void init(FilterConfig config):用于完成Filter的初始化。 void destory():用于Filter销毁前，完成某些资源的回收。 void doFilter(ServletRequest request,ServletResponse response,FilterChain chain):实现过滤功能，该方法就是对每个请求及响应增加的额外处理。该方法可以实现对用户请求进行预处理(ServletRequest request)，也可实现对服务器响应进行后处理(ServletResponse response)—它们的分界线为是否调用了chain.doFilter(),执行该方法之前，即对用户请求进行预处理；执行该方法之后，即对服务器响应进行后处理。 2. 拦截器（Interceptor） 拦截器是在面向切面变成中应用的，就是service或一个方法前/后调用一个方法。是基础java的放射机制。拦截是不是在web.xml 在AOP（Aspect-Oriented Programming)中用于某个方法或字段被访问之前，进行拦截，然后在之前或之后加入某些操作，甚至在抛出异常的时候做业务逻辑的操作。拦击器是AOP的一种实现策略。 2.1 拦截器的实现方式 SpringMVC中的Interceptor拦截请求是通过HandlerInterceptor来实现的，在SpringMVC中定义Interceptor主要有两种方式： 实现Spring的HandlerInterceptor接口或者继承了实现HandlerInterceptor接口的类（比如 HandlerInterceptorAdapter ） 实现Spring的WebRequestInterceptor接口，或者继承了实现WebRequestInterceptor接口的类 Interceptor中的方法： preHandle (HttpServletRequest request, HttpServletResponse response, Object handle) 方法，顾名思义，该方法将在请求处理之前进行调用。SpringMVC 中的Interceptor 是链式的调用的，在一个应用中或者说是在一个请求中可以同时存在多个Interceptor 。每个Interceptor 的调用会依据它的声明顺序依次执行，而且最先执行的都是Interceptor 中的preHandle 方法，所以可以在这个方法中进行一些前置初始化操作或者是对当前请求的一个预处理，也可以在这个方法中进行一些判断来决定请求是否要继续进行下去。该方法的返回值是布尔值Boolean类型的，当它返回为false 时，表示请求结束，后续的Interceptor 和Controller 都不会再执行；当返回值为true 时就会继续调用下一个Interceptor 的preHandle 方法，如果已经是最后一个Interceptor 的时候就会是调用当前请求的Controller 方法 postHandle (HttpServletRequest request, HttpServletResponse response, Object handle, ModelAndView modelAndView) 方法，由preHandle 方法的解释我们知道这个方法包括后面要说到的afterCompletion 方法都只能是在当前所属的Interceptor 的preHandle 方法的返回值为true 时才能被调用。postHandle 方法，顾名思义就是在当前请求进行处理之后，也就是Controller 方法调用之后执行，但是它会在DispatcherServlet 进行视图返回渲染之前被调用，所以我们可以在这个方法中对Controller 处理之后的ModelAndView 对象进行操作。postHandle 方法被调用的方向跟preHandle 是相反的，也就是说先声明的Interceptor 的postHandle 方法反而会后执行，这和Struts2 里面的Interceptor 的执行过程有点类型。Struts2 里面的Interceptor 的执行过程也是链式的，只是在Struts2 里面需要手动调用ActionInvocation 的invoke 方法来触发对下一个Interceptor 或者是Action 的调用，然后每一个Interceptor 中在invoke 方法调用之前的内容都是按照声明顺序执行的，而invoke 方法之后的内容就是反向的。 afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handle, Exception ex) 方法，该方法也是需要当前对应的Interceptor 的preHandle 方法的返回值为true 时才会执行。顾名思义，该方法将在整个请求结束之后，也就是在DispatcherServlet 渲染了对应的视图之后执行。这个方法的主要作用是用于进行资源清理工作的 123456789101112131415161718192021222324252627282930313233import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.log4j.Logger;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;public class ExecuteTimeInterceptor extends HandlerInterceptorAdapter&#123; private static final Logger logger = Logger.getLogger(ExecuteTimeInterceptor.class); //before the actual handler will be executed public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; long startTime = System.currentTimeMillis(); request.setAttribute(&quot;startTime&quot;, startTime); return true; &#125; //after the handler is executed public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; long startTime = (Long)request.getAttribute(&quot;startTime&quot;); long endTime = System.currentTimeMillis(); //统计耗时 long executeTime = endTime - startTime; //modified the exisitng modelAndView modelAndView.addObject(&quot;executeTime&quot;,executeTime); //log it if(logger.isDebugEnabled())&#123; logger.debug(&quot;[&quot; + handler + &quot;] executeTime : &quot; + executeTime + &quot;ms&quot;); &#125; &#125;&#125; 非Springboot项目 使用mvc:interceptors标签来声明需要加入到SpringMVC拦截器链中的拦截器 12345678910111213&lt;mvc:interceptors&gt; &lt;!-- 使用bean定义一个Interceptor，直接定义在mvc:interceptors根下面的Interceptor将拦截所有的请求 --&gt; &lt;bean class=&quot;com.company.app.web.interceptor.AllInterceptor&quot;/&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/parent/**&quot;/&gt; &lt;bean class=&quot;com.company.authorization.interceptor.SecurityInterceptor&quot; /&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/parent/**&quot;/&gt; &lt;bean class=&quot;com.company.authorization.interceptor.SecuritySystemInterceptor&quot; /&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 可以利用mvc:interceptors标签声明一系列的拦截器，然后它们就可以形成一个拦截器链，拦截器的执行顺序是按声明的先后顺序执行的，先声明的拦截器中的preHandle方法会先执行，然而它的postHandle方法和afterCompletion方法却会后执行。 在mvc:interceptors标签下声明interceptor主要有两种方式： 直接定义一个Interceptor实现类的bean对象。使用这种方式声明的Interceptor拦截器将会对所有的请求进行拦截。 使用mvc:interceptor标签进行声明。使用这种方式进行声明的Interceptor可以通过mvc:mapping子标签来定义需要进行拦截的请求路径。 经过上述两步之后，定义的拦截器就会发生作用对特定的请求进行拦截了 Springboot项目 配置拦截器 1234567891011121314151617@Configuration//@Configurationpublicpublic class WebAppConfigurer implements WebMvcConfigurer &#123; /** * 配置拦截器 */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 多个拦截器组成一个拦截器链 registry.addInterceptor(new ExecuteTimeInterceptor()).addPathPatterns(&quot;/**&quot;); //API限流拦截 registry.addInterceptor(accessLimitAjaxInterceptor()).addPathPatterns(&quot;/**&quot;).excludePathPatterns(&quot;/static/**&quot;,&quot;/login.html&quot;); registry.addInterceptor(accessInterceptor()).addPathPatterns(&quot;/**&quot;).excludePathPatterns(&quot;/static/**&quot;,&quot;/login.html&quot;); &#125;&#125; 2.2 拦截器（interceptor）使用 请求到达DispatcherServlet DispatcherServlet发送至Interceptor，执行preHandler 请求到达Controller 请求结束后，执行postHandler 3. 过滤器（Filter）与 拦截器（Interceptor）的区别 Spring的Interceptor(拦截器)与Servlet的Filter有相似之处，比如二者都是AOP编程思想的体现，都能实现权限检查、日志记录等。不同的是： Filter Interceptor Summary Filter 接口定义在 javax.servlet 包中 接口 HandlerInterceptor 定义在org.springframework.web.servlet 包中 Filter 定义在 web.xml 中 Filter在只在 Servlet 前后起作用。Filters 通常将 请求和响应（request/response） 当做黑盒子，Filter 通常不考虑servlet 的实现。 拦截器能够深入到方法前后、异常抛出前后等，因此拦截器的使用具有更大的弹性。允许用户介入（hook into）请求的生命周期，在请求过程中获取信息，Interceptor 通常和请求更加耦合。 在Spring架构的程序中，优先使用拦截器，几乎所有的Filter能够做的事情，Interceptor都可以实现 Filter 是 Servlet 规范规定的。 而拦截器既可以用于Web程序，也可以用于Application、Swing程序中。 使用范围不同 Filter 是在 Servlet 规范中定义的，是 Servlet 容器支持的。 而拦截器是在 Spring容器内的，是Spring框架支持的。 规范不同 Filter 不能够使用 Spring 容器资源 拦截器是一个Spring的组件，归Spring管理，配置在Spring文件中，因此能使用Spring里的任何资源、对象，例如 Service对象、数据源、事务管理等，通过IoC注入到拦截器即可 Spring使用interceptor更容易 Filter 是被 Server(like Tomcat) 调用 Interceptor 是被 Spring 调用 Filter优先于interceptor执行 3.1 执行顺序 用户请求 -&gt; 过滤前 -&gt; 拦截前 -&gt; Action处理 -&gt; 拦截后 -&gt; 过滤后 -&gt; 响应 4. 过滤器（Filter）与 拦截器（Interceptor）常见用途 Authentication Filters Logging and Auditing Filtersx Image conversion Filters Data compression Filters Encryption Filters Tokenizing Filters Filters that trigger resource access events XSL/T filters Mime-type chain Filter Request Filters 可以: 执行安全检查 perform security checks 格式化请求头和主体 reformat request headers or bodies 审查或者记录日志 audit or log requests 根据请求内容授权或者限制用户访问 Authentication-Blocking requests based on user identity. 根据请求频率限制用户访问 Response Filters 可以: 压缩响应内容,比如让下载的内容更小 Compress the response stream 追加或者修改响应 append or alter the response stream 创建或者整体修改响应 create a different response altogether 根据地方不同修改响应内容 Localization-Targeting the request and response to a particular locale. 5. 总结 过滤器：所谓过滤器顾名思义是用来过滤的，在java web中，你传入的request,response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者struts的action进行业务逻辑，比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉）,或者在传入servlet或者struts的action前统一设置字符集，或者去除掉一些非法字符（聊天室经常用到的，一些骂人的话）。filter 流程是线性的， url传来之后，检查之后，可保持原来的流程继续向下执行，被下一个filter, servlet接收等. java的拦截器 主要是用在插件上，扩展件上比如 hibernate spring struts2等 有点类似面向切片的技术，在用之前先要在配置文件即xml文件里声明一段的那个东西。 拦截器（Interceptor）是基于Java的反射机制，而过滤器（Filter）是基于函数回调。从灵活性上说拦截器功能更强大些，Filter能做的事情，都能做，而且可以在请求前，请求后执行，比较灵活。Filter主要是针对URL地址做一个编码的事情、过滤掉没用的参数、安全校验（比较泛的，比如登录不登录之类），太细的话，还是建议用interceptor。","categories":[{"name":"filter","slug":"filter","permalink":"https://xiaoyuge5201.github.io/categories/filter/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]},{"title":"Mysql重置密码","slug":"mysql-forget-pwd","date":"2022-10-29T13:43:23.000Z","updated":"2022-10-29T14:07:46.399Z","comments":false,"path":"mysql-forget-pwd/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql-forget-pwd/","excerpt":"","text":"Mysql 安装的时候忘记保存默认密码，需要重置密码； 1. 跳过Mysql密码认证 1vim /etc/my.cnf 在文档内[mysqld]第一行添加skip-grant-tables用来跳过密码验证的过程 2. 重启Mysql 1234service mysqld restart#或者systemctl restart mysqld 然后再输入mysql -uroot -p 一直按enter 就可以顺利进入数据库 123show databases;use mysql;select * from user; 3. 创建用户 1234create user &#x27;root&#x27;@&#x27;localhost&#x27; identity by &#x27;123456&#x27;;-- lolcahost表示本地，mysql登陆的时候不用指定IP登陆-- 如果需要外网访问，则将localhost改成 % 此步骤可能会报以下错误，没报错的跳过第4步 1234567mysql&gt; ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement#输入mysql&gt; flush privileges;刷新配置# 再次创建用户mysql&gt; create user &#x27;root&#x27;@&#x27;localhost&#x27; identity by &#x27;123456&#x27;; 再次报错，这步没报错的也是直接跳到赋予权限那一步，报错的以下操作： 12mysql&gt; drop user &#x27;root&#x27;@&#x27;localhost&#x27;;mysql&gt; create user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;123456&#x27;; 4. 赋予root权限 1234mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;localhost&#x27; WITH GRANT OPTION; #赋予所有库所有表操作权限mysql&gt; flush privileges;mysql&gt; exit; 再次查询user表，会发现用户表新建了一个root用户 5. 修改配置文件 1234567vim /etc/my.cnf##删除配置#skip-grant-table=1##保存并重启mysqlservice myqld restart","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"Tidb查询优化","slug":"tidb-optimization","date":"2022-10-15T06:23:37.000Z","updated":"2022-10-15T06:44:22.007Z","comments":false,"path":"tidb-optimization/","link":"","permalink":"https://xiaoyuge5201.github.io/tidb-optimization/","excerpt":"","text":"1. tidb查询优化 tidb数据库查询3亿条数据需要花费20s以上，然后按照下面的优化方式执行过后，查询只需要1.5s； 查看表的健康度 12345 show stats_healthy where table_name=&#x27;xxxx&#x27;; ``` 2. 查看自动统计状态 ```sql show variables like &#x27;%auto_analyze%&#x27;; tidb_auto_analyze_start_time和tidb_auto_analyze_end_time控制了自动收集统计信息的窗口； tidb_auto_analyze_ratio 控制了可以进行自动收集统计信息的阈值，默认为0.5，如果后续表的数据量增加，可以酌情调整这个参数到0.3或者0.2，意味着这张表的数据修改超过总表行数的30%或者20%就会自动收集，会更敏感一些 官方文档：https://docs.pingcap.com/zh/tidb/dev/statistics#自动更新 调整自动收集统计信息的阈值 1set global tidb_auto_analyze_ratio = 0.2; 查看健康度低于阈值的表信息 1show stats_healthy where healthy&lt;80; 低于80的重新收集统计信息 1analyze table xxx 加快索引添加速度 12345show global variables like &#x27;tidb_ddl_reorg_%&#x27;; # 记录原来的数值， 添加完索引后记得改回去set global tidb_ddl_reorg_batch_size = 1024;set global tidb_ddl_reorg_worker_cnt = 16; 如果某张表因为业务需求导入了大量的数据，而这些数据在达到tidb_auto_analyze_start_time之前就需要使用SQL进行查询，此时建议对导入的表进行手动的收集； 我们也可以分析业务的行为，如果某张表有定时任务会自动插入大量数据，自动任务完成后需要产生报表的需求，也建议在自动任务结束后手动对相关的表进行手动收集；","categories":[{"name":"tidb","slug":"tidb","permalink":"https://xiaoyuge5201.github.io/categories/tidb/"}],"tags":[{"name":"tidb","slug":"tidb","permalink":"https://xiaoyuge5201.github.io/tags/tidb/"}]},{"title":"CentOS Kafka 3.2.0 单机集群安装（伪集群）","slug":"kafka-colony-install","date":"2022-07-03T13:45:23.000Z","updated":"2022-09-18T08:24:01.222Z","comments":false,"path":"kafka-colony-install/","link":"","permalink":"https://xiaoyuge5201.github.io/kafka-colony-install/","excerpt":"","text":"1. 准备工作 由于没有那么多台机器，所以在同一台机器上运行多个Kafka服务，只是端口不同 安装路径： /usr/local/tools ; 服务器IP： 192.168.44.161 基于Kafka单机版安装流程，请查看 CentOS安装kafka 3.2.0单机版 所有Kafka节点连接到相同的ZK（或ZK集群），需要先安装一个ZK，请参考 CentOS安装Zookeeper 3.7.1单节点 , 在本例中ZK也安装在这台机器上。 注意：单机的kafka和集群的Kafka不要混用一个ZK，否则会出现数据混乱的问题。 2. 下载解压kafka 1234cd /usr/local/toolswget https://dlcdn.apache.org/kafka/3.2.0/kafka_2.12-3.2.0.tgztar -xzvf kafka_2.12-3.2.0.tgzcd kafka_2.12-3.2.0 3. 修改配置文件 复制3个配置文件 1234cd configcp server.properties server1.properties cp server.properties server2.properties cp server.properties server3.properties 修改配置文件中的broker.id分别为1、2、3 listeners这一行取消注释，端口号分别为9093、9094、9095 log.dirs分别设置为kafka-logs1、kafka-logs2、kafka-logs3（先创建） 1mkdir -p /tmp/kafka-logs1 /tmp/kafka-logs2 /tmp/kafka-logs3 server1.properties 的配置： 123broker.id=1listeners=PLAINTEXT://192.168.44.161:9093log.dirs=/tmp/kafka-logs1 server2.properties 的配置: 123broker.id=2listeners=PLAINTEXT://192.168.44.161:9094log.dirs=/tmp/kafka-logs2 server3.properties 的配置： 123broker.id=3listeners=PLAINTEXT://192.168.44.161:9095log.dirs=/tmp/kafka-logs3 如果listeners取消注释导致topic创建失败，可以修改为 12listeners=PLAINTEXT://:9093advertised.listeners=PLAINTEXT://10.1.14.159:9093 4. 启动3个服务 启动ZK12cd /usr/local/tools/apache-zookeeper-3.7.1-bin/bin./zkServer.sh start 启动Kafka 1234cd ../bin./kafka-server-start.sh -daemon ../config/server1.properties./kafka-server-start.sh -daemon ../config/server2.properties./kafka-server-start.sh -daemon ../config/server3.properties PS：如果遇到zk node exists的问题，先把brokers节点删掉（临时解决方案）。 5. 集群下创建Topic 在bin目录下，创建一个名为ygbtest的topic，只有一个服务本一个分区： 1sh kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic ygbtest 查看一创建的topic： 1sh kafka-topics.sh -list -zookeeper localhost:2181 6. 集群下启动Consumer 在一个新的原车鞥窗口中： 1sh kafka-console-consumer.sh --bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 --topic ygbtest --from-beginning kafka相关命令可以查看这篇博客 kafka常用命令 7. 集群下启动Producer 打开一个新的窗口，在kafka解压目录下： 1sh kafka-console-producer.sh --broker-list 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 --topic ygbtest 8. 集群下Producer窗口发送消息 在生产者Producer窗口输入hello world 回车","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://xiaoyuge5201.github.io/tags/kafka/"}]},{"title":"基于Canal和Kafka实现数据同步","slug":"canal-kafka-async","date":"2022-07-03T08:38:33.000Z","updated":"2022-07-03T14:11:49.199Z","comments":false,"path":"canal-kafka-async/","link":"","permalink":"https://xiaoyuge5201.github.io/canal-kafka-async/","excerpt":"","text":"1. 前言 Canal的作用：把自己&quot;伪装&quot;成一个Mysql的slave，不停同步master的binlog数据，再把binlog数据以TCP或者MQ的方式（支持kafka、RabbitMQ、RocketMQ）发送给需要同步数据的项目 canal项目地址：https://github.com/alibaba/canal/releases , 2022-05-24发布的最新版1.1.6。 测试需要同步的目标数据库是192.168.44.121上部署的数据库 2. 在目标数据库上创建用户和数据库 注意 121 的数据库首先要开启binlog，binlog-format必须是ROW 12log-bin=/var/lib/mysql/mysql-binbinlog-format=ROW 用户和数据库创建 12345678910111213-- 创建canal专用的用户，用于访问master获取binlogCREATE USER canal IDENTIFIED BY &#x27;123456&#x27;;-- 给canal用户分配查询和复制的权限GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO canal@&#x27;%&#x27;;-- 刷新权限FLUSH PRIVILEGES;ALTER USER &#x27;canal&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;123456&#x27;;-- 创建测试数据库CREATE DATABASE `canaltest` CHARSET `utf8mb4` COLLATE `utf8mb4_unicode_ci`; 3. 安装ZK和kafka 在192.168.44.161机器上安装ZK和kafka, 这里我们安装伪集群版本，具体步骤请参考 CentOS Kafka 3.2.0 单机集群安装（伪集群） 4. 安装canal 下载canal 以安装目录:/usr/local/tools/canal 为例。 123456cd /usr/local/tools/midir canalcd canalwget https://github.com/alibaba/canal/releases/download/canal-1.1.6/canal.deployer-1.1.6.tar.gztar -zxvf canal.deployer-1.1.6.tar.gz 如果下载慢的话，可以先下载到本地，然后上传到服务器 修改配置：conf/canal.properties 12cd /usr/local/tools/canal/confvim canal.propertis 修改配置如下： 12canal.serverMode=kafkacanal.mq.servers = 192.168.44.160:9092 修改配置：example/instance.properties 12cd /usr/local/tools/canal/examplevim instance.properties 1234567canal.instance.master.address=192.168.44.121:3306canal.instance.dbUsername=canalcanal.instance.dbPassword=123456# 新增canal.instance.defaultDatabaseName=canaltest# 这个topic会自动创建canal.mq.topic=canal-topic 启动canal 1234cd /usr/local/tools/canal/binsh startup.sh# 查看实例日志tail -100f /usr/local/tools/canal/logs/canal/canal.log 5. 建表测试 在canaltest数据随表建一张表，做增删改的操作。 在Kafka服务器上消费这个topic 1./kafka-console-consumer.sh --bootstrap-server 192.168.44.160:9092 --topic canal-topic kafka相关命令可以查看这篇博客 kafka常用命令 成功消费到canal发送的消息：","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Canal","slug":"Canal","permalink":"https://xiaoyuge5201.github.io/tags/Canal/"}]},{"title":"RocketMQ 二主二从异步集群部署","slug":"rocketmq-colony-install","date":"2022-07-03T03:37:05.000Z","updated":"2022-07-03T04:51:50.592Z","comments":false,"path":"rocketmq-colony-install/","link":"","permalink":"https://xiaoyuge5201.github.io/rocketmq-colony-install/","excerpt":"","text":"1. 节点规划 第一台机器 192.168.44.163 端口 名称 9876 NameServer1 10910 BrokerA-master 10921 BrokerB-slave 第二台机器 192.168.44.164 端口 名称 9876 NameServer2 10911 BrokerA-slave 10920 BrokerB-slave 2. 下载并解压 具体操作可以查看 CentOS安装RocketMQ以及常用命令 123456cd /usr/local/toolswget https://dlcdn.apache.org/rocketmq/4.9.4/rocketmq-all-4.9.4-bin-release.zip#解压unzip rocketmq-all-4.9.4-bin-release.zip #改名mv rocketmq-all-4.9.4-bin-release rocketmq 在两台机器上都下载、解压好。 在rocketmq/conf目录下，有三种建议配置模式： 2m-2s-async(2主2从异步) —— 本文采用这种 2m-2s-sync (2主2从同步) 2m-noslave (2主) 现在需要修改两台机器上2m-2s-async这个目录中的文件。 配置文件修改之前先备份。 3. 配置第一台机器163 192.168.44.163的两个配置文件 broker-a.properties 12cd /usr/local/tools/rocketmq/conf/2m-2s-asyncvim broker-a.properties 修改的内容（名字自定义，保持一直，否则不能组成集群） 1brokerClusterName=ygb-cluster 增加内容: 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10910#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=192.168.44.163:9876;192.168.44.164:9876#存储路径storePathRootDir=/usr/local/tools/rocketmq/store/broker-a#commitLog 存储路径storePathCommitLog=/usr/local/tools/rocketmq/store/broker-a/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/tools/rocketmq/store/broker-a/consumequeue#消息索引存储路径storePathIndex=/usr/local/tools/rocketmq/store/broker-a/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/tools/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/tools/rocketmq/store/abort broker-b-s.properties 1vim broker-b-s.properties 修改的内容（名字自定义，保持一直，否则不能组成集群） 1brokerClusterName=ygb-cluster 增加内容: 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10921#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=192.168.44.163:9876;192.168.44.164:9876#存储路径storePathRootDir=/usr/local/tools/rocketmq/store/broker-b-s#commitLog 存储路径storePathCommitLog=/usr/local/tools/rocketmq/store/broker-b-s/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/tools/rocketmq/store/broker-b-s/consumequeue#消息索引存储路径storePathIndex=/usr/local/tools/rocketmq/store/broker-b-s/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/tools/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/tools/rocketmq/store/abort 4. 配置第二台机器164 192.168.44.164的两个配置文件; 修改的内容基本一致，主要是注意一下端口号、路径名。 broker-b.properties 12cd /usr/local/tools/rocketmq/conf/2m-2s-asyncvim broker-b.properties 修改的内容（名字自定义，保持一直，否则不能组成集群） 1brokerClusterName=ygb-cluster 增加内容: 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10920#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=192.168.44.163:9876;192.168.44.164:9876#存储路径storePathRootDir=/usr/local/tools/rocketmq/store/broker-b#commitLog 存储路径storePathCommitLog=/usr/local/tools/rocketmq/store/broker-b/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/tools/rocketmq/store/broker-b/consumequeue#消息索引存储路径storePathIndex=/usr/local/tools/rocketmq/store/broker-b/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/tools/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/tools/rocketmq/store/abort broker-a-s.properties 12cd /usr/local/tools/rocketmq/conf/2m-2s-asyncvim broker-a-s.properties 修改的内容（名字自定义，保持一直，否则不能组成集群） 1brokerClusterName=ygb-cluster 增加内容: 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10911#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=192.168.44.163:9876;192.168.44.164:9876#存储路径storePathRootDir=/usr/local/tools/rocketmq/store/broker-a-s#commitLog 存储路径storePathCommitLog=/usr/local/tools/rocketmq/store/broker-a-s/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/tools/rocketmq/store/broker-a-s/consumequeue#消息索引存储路径storePathIndex=/usr/local/tools/rocketmq/store/broker-a-s/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/tools/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/tools/rocketmq/store/abort 5. 创建数据目录 在第一台机器163 执行（只需要执行一次） 1mkdir -p /usr/local/tools/rocketmq/store/broker-a /usr/local/tools/rocketmq/store/broker-a/consumequeue /usr/local/tools/rocketmq/store/broker-a/commitlog /usr/local/tools/rocketmq/store/broker-a/index /usr/local/tools/rocketmq/logs /usr/local/tools/rocketmq/store/broker-b-s /usr/local/tools/rocketmq/store/broker-b-s/consumequeue /usr/local/tools/rocketmq/store/broker-b-s/commitlog /usr/local/tools/rocketmq/store/broker-b-s/index 在第二台机器164 执行（只需要执行一次） 1mkdir -p /usr/local/tools/rocketmq/store/broker-a-s /usr/local/tools/rocketmq/store/broker-a-s/consumequeue /usr/local/tools/rocketmq/store/broker-a-s/commitlog /usr/local/tools/rocketmq/store/broker-a-s/index /usr/local/tools/rocketmq/logs /usr/local/tools/rocketmq/store/broker-b /usr/local/tools/rocketmq/store/broker-b/consumequeue /usr/local/tools/rocketmq/store/broker-b/commitlog /usr/local/tools/rocketmq/store/broker-b/index 6. 启动两个NameServer 启动第一台163的NameServer 1nohup sh /usr/local/tools/rocketmq/bin/mqnamesrv &gt;/usr/local/tools/rocketmq/logs/mqnamesrv.log 2&gt;&amp;1 &amp; 启动第二台164的NameServer 1nohup sh /usr/local/tools/rocketmq/bin/mqnamesrv &gt;/usr/local/tools/rocketmq/logs/mqnamesrv.log 2&gt;&amp;1 &amp; 7. 启动Broker 启动 163 机器上的broker-a-master（在163上执行） 1nohup sh /usr/local/tools/rocketmq/bin/mqbroker -c /usr/local/tools/rocketmq/conf/2m-2s-async/broker-a.properties &gt; /usr/local/tools/rocketmq/logs/broker-a.log 2&gt;&amp;1 &amp; 在虚拟机中可能由于内存不够导致无法启动，日志文件中出现如下错误： 12nohup: ignoring inputJava HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00000005c0000000, 8589934592, 0) failed; error=&#x27;Cannot allocate memory&#x27; (errno=12) 1vim /usr/local/tools/rocketmq/bin/runbroker.sh 把8g和4g改成512m和256m 1JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m&quot; 再次启动。 启动 164 机器上的broker-a-s（在164上执行） 1nohup sh /usr/local/tools/rocketmq/bin/mqbroker -c /usr/local/tools/rocketmq/conf/2m-2s-async/broker-a-s.properties &gt; /usr/local/tools/rocketmq/logs/broker-a-s.log 2&gt;&amp;1 &amp; 启动 164 的broker-b-master（在164上执行） 1nohup sh /usr/local/tools/rocketmq/bin/mqbroker -c /usr/local/tools/rocketmq/conf/2m-2s-async/broker-b.properties &gt; /usr/local/tools/rocketmq/logs/broker-b.log 2&gt;&amp;1 &amp; 启动 163 机器上的broker-b-s（在163上执行） 1nohup sh /usr/local/tools/rocketmq/bin/mqbroker -c /usr/local/tools/rocketmq/conf/2m-2s-async/broker-b-s.properties &gt; /usr/local/tools/rocketmq/logs/broker-b-s.log 2&gt;&amp;1 &amp; 查看两台机器的端口启动情况 1netstat -an|grep 端口号","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://xiaoyuge5201.github.io/tags/rocketmq/"}]},{"title":"CentOS安装RocketMQ以及常用命令","slug":"rocketmq-install","date":"2022-07-02T07:53:24.000Z","updated":"2022-07-03T05:21:08.945Z","comments":false,"path":"rocketmq-install/","link":"","permalink":"https://xiaoyuge5201.github.io/rocketmq-install/","excerpt":"","text":"1.前言 nameserver默认端口：9876 rocketmq默认端口：10911 服务器IP：172.21.16.253 安装路径：/usr/local/tools 2. 下载 RocketMQ官网链接：http://rocketmq.apache.org/ ,然后选择Lastest Release进入下载界面 右键复制链接地址，wget下载，或者下载后上传到Centos服务器上。 12cd /usr/local/toolswget https://dlcdn.apache.org/rocketmq/4.9.4/rocketmq-all-4.9.4-bin-release.zip 3. 解压 解压二进制包，修改文件夹名称 12unzip rocketmq-all-4.9.4-bin-release.zip mv rocketmq-all-4.9.4-bin-release rocketmq 如果提示-bash: unzip: command not found 123#安装zip 和 unzipyum install zipyum install unzip 创建数据存储目录 1mkdir -p /usr/local/tools/rocketmq/store/broker-a /usr/local/tools/rocketmq/store/broker-a/consumequeue /usr/local/tools/rocketmq/store/broker-a/commitlog /usr/local/tools/rocketmq/store/broker-a/index /usr/local/tools/rocketmq/broker-a/logs 4. 修改配置文件 12cd /usr/local/tools/rocketmq/confvim broker.conf 增加内容 1234567891011121314151617181920#Broker 对外服务的监听端口listenPort=10911#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#nameServer地址，分号分割namesrvAddr=localhost:9876#存储路径storePathRootDir=/usr/local/tools/rocketmq/store/broker-a#commitLog 存储路径storePathCommitLog=/usr/local/tools/rocketmq/store/broker-a/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/tools/rocketmq/store/broker-a/consumequeue#消息索引存储路径storePathIndex=/usr/local/tools/rocketmq/store/broker-a/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/tools/rocketmq/store/broker-a/checkpoint#abort 文件存储路径abortFile=/usr/local/tools/rocketmq/store/broker-a/abort 5. 启动 依次启动nameserver和broker ,这两个命令可以做成alias 1234cd /usr/local/tools/rocketmq/binnohup sh mqnamesrv &amp;nohup sh mqbroker -c /usr/local/tools/rocketmq/conf/broker.conf &amp; 在虚拟机中有可能因为内存不够而启动失败 1）设置bin目录下的 runserver.sh 1JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn512m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot; 2）设置bin目录下的 runbroker.sh 1JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m&quot; 3）如果改了上面两个还不行，那在修改bin目录下面的tools.sh 1JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn256m -XX:PermSize=128m -XX:MaxPermSize=128m&quot; 6. 查看日志 启动成功后查看mq动态日志 12tail -f ~/logs/rocketmqlogs/namesrv.logtail -f ~/logs/rocketmqlogs/broker.log 7.关闭服务 1234cd /usr/local/tools/rocketmq/binsh mqshutdown namesrvsh mqshutdown broker 8. 常用命令 RocketMQ 提供有控制台及一系列控制台目录，用户管理员对主题、集群、broker等信息的管理。 进入rocketmq下的bin目录，可以看到该目录下有个mqadmin脚本 查看帮助 1sh mqadmin help 命令名称 例如，查看updateTopic的使用 1sh mqadmin help updateTopic 下面列举一些常用的命令。 8.1 创建（修改）Topic 指令： updateTopic 类路径：com.alibaba.rocketmq.tools.command.topic.UpdateTopicSubCommand 参数 参数 是否必填 说明 -b 如果 -c为空，则必填 broker地址，表示topic建在该broker -c 如果 -b为空，则必填 cluster名称，表示topic建在该集群（集群可通过clusterList查询） -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… -p 否 指定新topic的权限限制( W -r 否 可读队列数（默认为8） -w 否 可写队列数（默认为8） -t 是 topic名称（名称只能使用字符 [1]+$ ） 举例 12# 在集群DefaultCluster上创建主题ZTEExample，nameserve地址为172.21.16.253:9876sh mqadmin updateTopic –n 172.21.16.253:9876 –c DefaultCluster –t ZTEExample 8.2 删除Topic 指令： deleteTopic 类路径：com.alibaba.rocketmq.tools.command.topic.DeleteTopicSubCommand 参数 参数 是否必填 说明 -c 是 cluster名称，表示删除某集群下的某个topic （集群可通过clusterList查询） -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… -t 是 topic名称（名称只能使用字符 [2]+$ ） 举例 12# 在集群DefaultCluster上删除主题ZTEExample，nameserve地址为172.21.16.253:9876sh mqadmin deleteTopic –n 172.21.16.253:9876 –c DefaultCluster –t ZTEExample 8.3 创建（修改）订阅组 指令： updateSubGroup 类路径：com.alibaba.rocketmq.tools.command.consumer.UpdateSubGroupSubCommand 参数 参数 是否必填 说明 -b 如果 -c为空，则必填 broker地址，表示topic建在该broker -c 如果 -b为空，则必填 cluster名称，表示topic建在该集群（集群可通过clusterList查询） -d 否 是否容许广播方式消费 -g 是 订阅组名 -i 否 从哪个broker开始消费 -m 否 是否容许从队列的最小位置开始消费，默认会设置为false -q 否 消费失败的消息放到一个重试队列，每个订阅组配置几个重试队列 -r 否 重试消费最大次数，超过则投递到死信队列，不再投递，并报警 -s 否 消费功能是否开启 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… -w 否 发现消息堆积后，将Consumer的消费请求重定向到另外一台Slave机器 8.4 删除订阅组配置 指令： deleteSubGroup 类路径：com.alibaba.rocketmq.tools.command.consumer.DeleteSubscriptionGroupCommand 参数 参数 是否必填 说明 -b 如果 -c为空，则必填 broker地址，表示订阅组建在该broker -c 如果 -b为空，则必填 cluster名称，表示topic建在该集群（集群可通过clusterList查询） -g 是 订阅组名 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 8.5 更新broker配置文件 指令： updateBrokerConfig 类路径：com.alibaba.rocketmq.tools.command.broker.UpdateBrokerConfigSubCommand 参数 参数 是否必填 说明 -b 如果 -c为空，则必填 broker地址，表示订阅组建在该broker -c 如果 -b为空，则必填 cluster名称，表示topic建在该集群（集群可通过clusterList查询） -k 否 是否容许广播方式消费 -v 是 value值 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 8.6 查看topic 列表信息 指令： topicList 类路径：com.alibaba.rocketmq.tools.command.broker.UpdateBrokerConfigSubCommand 参数 参数 是否必填 说明 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# nameserve地址为172.21.16.253:9876;sh mqadmin topicList -n 172.21.16.253:9876 8.7 查看路由信息 指令： topicRoute 类路径： com.alibaba.rocketmq.tools.command.topic.TopicRouteSubCommand 参数 参数 是否必填 说明 -t 是 topic名称 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# 查看主题%DLQ%consumer1的路由，nameserve地址为172.21.16.253:9876sh mqadmin topicRoute -n 172.21.16.253:9876 -t %DLQ%consumer1 8.8 查看topic统计信息 指令： topicStatus 类路径：com.alibaba.rocketmq.tools.command.topic.TopicStatsSubCommand 参数 参数 是否必填 说明 -t 是 topic名称 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# 查看主题%DLQ%consumer1的统计信息，nameserve地址为172.21.16.253:9876sh mqadmin topicStatus -n 172.21.16.253:9876 -t %DLQ%consumer1 8.9 查看broker统计信息 指令： brokerStatus 类路径：com.alibaba.rocketmq.tools.command.broker.BrokerStatsSubCommand 参数 参数 是否必填 说明 -b 是 broker地址 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# 查看broker(crmdb)的统计信息，broker地址为172.21.16.253:10911,nameserve地址为172.21.16.253:9876sh mqadmin brokerStatus –n 172.21.16.253:9876 -b 172.21.16.253:10911 8.10 根据消息ID查询消息 指令： queryMsgById 类路径：com.alibaba.rocketmq.tools.command.message.QueryMsgByIdSubCommand 参数 参数 是否必填 说明 -i 是 msgId -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12#查询msgId= C0A89F8000002A9F000000000000449A的消息，nameserve地址为172.21.16.253:9876sh mqadmin queryMsgById -n 172.21.16.253:9876 -i C0A89F8000002A9F000000000000449A 8.11 根据消息key查询消息 指令： queryMsgByKey 类路径：com.alibaba.rocketmq.tools.command.message.QueryMsgByKeySubCommand 参数 参数 是否必填 说明 -f 否 被查询消息的截止时间 -k 是 msgKey -t 是 Topic名称 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# 查询Topic= TopicTest下key=i0的消息，nameserve地址为172.21.16.253:9876sh mqadmin queryMsgByKey -n 172.21.16.253:9876 -t TopicTest -k i0 8.12 根据Offset查询消息 指令： queryMsgByOffset 类路径：com.alibaba.rocketmq.tools.command.message.QueryMsgByOffsetSubCommand 参数 参数 是否必填 说明 -b 是 Broker名称，表示订阅组建在该broker（这里需要注意填写的是broker的名称，不是broker的地址，broker名称可以在clusterList查到） -i 是 query队列id -o 是 offset值 -t 是 Topic名称 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12#查询brokerName=broker-a，Topic= TopicTest的第1个队列下offset=0的消息，nameserve地址为172.21.16.253:9876sh mqadmin queryMsgByOffset -n 172.21.16.253:9876 -b broker-a -i 0 -t TopicTest -o 0 8.13 查询Producer的网络连接 该命令只打印当前与cluster连接的producer网络连接信息 指令： producerConnection 类路径：com.alibaba.rocketmq.tools.command.connection.ProducerConnectionSubCommand 参数 参数 是否必填 说明 -g 是 生产者所属组名 -t 是 topic名称 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# 查询当前属于group（生产者组）=simple-producer-test的生产者到topic=ZTEExample的网络连接，nameserve地址为172.21.16.253:9876sh mqadmin producerConnection -n 172.21.16.253:9876 -g simple-producer-test -t ZTEExample 8.14 查询Consumer的网络连接 该命令只打印当前与cluster连接的Consumer网络连接信息 指令： consumerConnection 类路径：com.alibaba.rocketmq.tools.command.connection.ConsumerConnectionSubCommand 参数 参数 是否必填 说明 -g 是 生产者所属组名 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# 查询当前属于group（消费者组）=simple-consumer-test的消费者的网络连接，nameserve地址为172.21.16.253:9876sh mqadmin consumerConnection -n 172.21.16.253:9876 -g simple-consumer-test 8.15 查看订阅组消费状态 指令： consumerProgress 类路径：com.alibaba.rocketmq.tools.command.consumer.ConsumerProgressSubCommand 参数 参数 是否必填 说明 -g 是 消费者所属组名 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12# 查询当前属于group（消费者组）=simple-consumer-test的订阅状态，nameserve地址为172.21.16.253:9876sh mqadmin consumerProgress -n 172.21.16.253:9876 -g simple-consumer-test 8.16 查看集群消息 指令： clusterList 类路径：com.alibaba.rocketmq.tools.command.cluster.ClusterListSubCommand 参数 参数 是否必填 说明 -m 否 打印更多信息 (增加打印出如下信息 #InTotalYest, #OutTotalYest, #InTotalToday ,#OutTotalToday) -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 123# 查询当前集群状态，nameserve地址为172.21.16.253:9876sh mqadmin clusterList -n 172.21.16.253:9876 sh mqadmin clusterList -n 172.21.16.253:9876 –m 8.17 添加（更新）KV配置信息 指令： updateKvConfig 类路径：com.alibaba.rocketmq.tools.command.namesrv.UpdateKvConfigCommand 参数 参数 是否必填 说明 -k 是 key值 -v 是 value值 -s 是 Namespace值 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 8.18 删除KV配置信息 指令： deleteKvConfig 类路径：com.alibaba.rocketmq.tools.command.namesrv.DeleteKvConfigCommand 参数 参数 是否必填 说明 -k 是 key值 -s 是 Namespace值 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 8.19 添加（更新）Project group配置信息 指令： updateProjectGroup 类路径：com.alibaba.rocketmq.tools.command.namesrv.UpdateProjectGroupCommand 参数 参数 是否必填 说明 -i 是 服务器ip -p 是 project group名 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 8.20 删除Project group配置信息 指令： deleteProjectGroup 类路径：com.alibaba.rocketmq.tools.command.namesrv.DeleteProjectGroupCommand 参数 参数 是否必填 说明 -i 是 服务器ip -p 是 project group名 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 8.21 取得Project group配置信息 指令： getProjectGroup 类路径：com.alibaba.rocketmq.tools.command.namesrv.GetProjectGroupCommand 参数 参数 是否必填 说明 -i 是 服务器ip -p 是 project group名 -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 8.22 获取Consumer消费进度 该命令只打印当前与cluster连接的consumer的消费进度 指令： getConsumerStatus 类路径：com.alibaba.rocketmq.tools.command.offset.GetConsumerStatusCommand 参数 参数 是否必填 说明 -g 是 消费者所属组名 -t 是 查询主题 -i 否 Consumer客户端ip -h 否 打印帮助 -n 是 nameserve服务地址列表，格式ip:port;ip:port;… 举例 12#查询属于group（消费者组）=simple-consumer-test的消费者在Topic=ZTEExample上的消费状态，nameserve地址为172.21.16.253:9876sh mqadmin getConsumerStatus -n 172.21.16.253:9876 -g simple-consumer-test -t ZTEExample a-zA-Z0-9_- ↩︎ a-zA-Z0-9_- ↩︎","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://xiaoyuge5201.github.io/tags/rocketmq/"}]},{"title":"Apache archiva Maven私有仓库搭建","slug":"Apache-archiva","date":"2022-06-28T03:49:42.000Z","updated":"2022-06-29T08:41:13.587Z","comments":false,"path":"Apache-archiva/","link":"","permalink":"https://xiaoyuge5201.github.io/Apache-archiva/","excerpt":"","text":"1. 搭建 环境准备 JDK 1.8 Apache Archiva 2.2.8 Apache-maven 3.6.3 （ https://maven.apache.org/download.cgi ） Apache Archiva安装文件下载 123456archiva官网地址：https://archiva.apache.org/index.cgi#a下载地址：https://archiva.apache.org/download.cgi （这个太慢了，几K/s，坑）镜像仓库：https://mirrors.tuna.tsinghua.edu.cn/apache/archiva建议从镜像仓库拉取！！！ 将下载的tar.gz包上传到服务器相应位置 解压tar.gz包 12tar -zxvf ./apache-archiva-2.2.8-bin.tar.gz chmod 775 ./apache-archiva-2.2.8 修改端口（8080默认），如不需要，请跳过 启动 123cd /User/xiaoyuge/maven/apache-archiva-2.2.8/bin./archiva start #执行启动命令，建议第一次启动使用：./archiva console 可以打印启动信息./archiva stop #停止命令 各版本操作系统下详细安装及服务注册参照：http://archiva.apache.org/docs/2.2.8/adminguide/standalone.html 将 archiva在Centos中安装成服务(root执行) 1ln -sf /Users/xiaoyuge/maven/apache-archiva-2.2.8/bin/archiva /etc/init.d/archiva 这样就可以通过service启动 12service archiva startservice archiva stop 启动成功后，访问maven服务器地址: http://ip:8080 点击右上角的Create Admin User创建管理员账号 2. 上传私有jar包 访问：http://localhost:8080/#upload，上传私有jar包到仓库 Repository Id 选择 Archiva Managed Internal Repository则是把依赖作为正式版. 查看地址：http://host:port/repository/internal Repository Id 选择Archiva Managed Snapshot则是把依赖作为快照版. 查看地址：http://host:port/repository/snapshots 按照以下步骤依次操作： 保存后，提示以下信息表示上传成功！ 在左侧菜单栏Browse中查看上传的jar ，如下所示： 也可以通过命令的方式上传（需要配置maven 的setting.xml） 在/Users/xiaoyuge/Desktop有一个junit-4.13.2.jar，使用mvn deploy命令上传如下 1mvn deploy:deploy-file -Dfile=/Users/xiaoyuge/Desktop/junit-4.13.2.jar -DrepositoryId=archiva-releases -DgroupId=junit -DartifactId=junit -Dversion=4.13.2 -Durl=http://localhost:8080/repository/internal 命令解释： -Dfile ：要上传到私服的jar包， jar包全路径 -DrepositoryId： 仓库ID，要与maven 的setting.xml配置文件中的server一致，否则401； -DgroupId： groupId主包名 -DartifactId： 项目名 -Dversion：版本号 -Durl：远程仓库地址 上传结果如下如所示： 同时在私服仓库中可以查看到刚上传的jar 3. 项目使用 配置maven中的setting.xml文件，配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;localRepository&gt;\\Common\\my_repository&lt;/localRepository&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;archiva-releases&lt;/id&gt;&lt;!--要和mvn命令中的 -DrepositoryId 一致--&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;xiaoyuge0318&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;archiva-snapshots&lt;/id&gt;&lt;!--要和mvn命令中的 -DrepositoryId 一致--&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;xiaoyuge0318&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;!-- 私服地址 start --&gt; &lt;mirror&gt; &lt;!-- 正式版 --&gt; &lt;id&gt;archiva-releases&lt;/id&gt; &lt;mirrorOf&gt;internal&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8080/repository/internal&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;!-- 快照版 --&gt; &lt;id&gt;archiva-snapshots&lt;/id&gt; &lt;mirrorOf&gt;snapshots&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8080/repository/snapshots&lt;/url&gt; &lt;/mirror&gt;true &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;!-- 正式版 --&gt; &lt;repository&gt; &lt;id&gt;internal&lt;/id&gt; &lt;name&gt;Archiva Managed Internal Repository&lt;/name&gt; &lt;url&gt;http://localhost:8080/repository/internal&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;!-- 快照版 --&gt; &lt;repository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;Archiva Managed Snapshots Repository&lt;/name&gt; &lt;url&gt;http://localhost:8080/repository/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- 私服地址END --&gt;&lt;/settings&gt;","categories":[{"name":"apache","slug":"apache","permalink":"https://xiaoyuge5201.github.io/categories/apache/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/tags/linux/"}]},{"title":"深入Tomcat源码学习","slug":"tomcat","date":"2022-06-26T01:48:09.000Z","updated":"2022-06-28T03:10:01.709Z","comments":false,"path":"tomcat/","link":"","permalink":"https://xiaoyuge5201.github.io/tomcat/","excerpt":"","text":"1. Tomcat简介 Apache是web服务器，Tomcat是应用服务器，apache tomcat只是一个servlet容器，是Apache的扩展；Apache和Tomcat都可以做为独立的web服务器来运行，但是Apache不能解释java程序（jsp,servlet）。 两者都是一种容器，只不过发布的东西不同：Apache是html容器，功能像IIS一样；Tomcat是jsp/servlet容器，用于发布jsp及java的，类似的有IBM的websphere、BEA的Weblogic，sun的JRun等等。 打个比方：Apache是一辆卡车，上面可以装一些东西如html等。但是不能装水，要装水必须要有容器（桶），Tomcat就是一个桶（装像Java这样的水），而这个桶也可以不放在卡车上。 官网地址： https://tomcat.apache.org/ 1.1 网络架构图 1.2 web监听端口 DefaultServletSocketFactory.java 12345@Overridepublic ServerSocket createSocket (int port, int backlog, InetAddress ifAddress) throws IOException &#123; return new ServerSocket (port, backlog, ifAddress);&#125; 1.3 Servlet容器 找到Tomcat源码中对应一个web项目的类 Context.class 找到Tomcat源码 —&gt;web.xml文件对应的类 12&lt;Context path=&quot;/app&quot; doBase=&quot;E:\\\\app&quot;/&gt;&lt;Context path=&quot;/app1&quot; doBase=&quot;E:\\\\app1&quot;/&gt; 既然这段配置能够代表一个web项目在磁盘的访问路径，Context标签就是代表一个web项目 在tomcat官网中（https://tomcat.apache.org/tomcat-8.0-doc/architecture/overview.html）可以看到相应的文档说明 123A Context represents a web application. A Host may contain multiple contexts, each with a unique path. The Context interface may be implemented to create custom Contexts, but this is rarely the case because the StandardContext provides significant additional functionality.//大致意思：一个Context文表示web应用程序。一个主机可以包含多个Context，每个Context都有一个唯一的路径。上下文接口可以用来创建自定义Context，但这种情况很少发生，因为StandardContext提供了重要的附加功能。 那么在StandardContext中是如何加载这些项目的？ 123456789101112131415161718192021222324252627282930313233343536public boolean loadOnStartup(Container children[]) &#123; // Collect &quot;load on startup&quot; servlets that need to be initialized TreeMap&lt;Integer, ArrayList&lt;Wrapper&gt;&gt; map = new TreeMap&lt;&gt;(); for (int i = 0; i &lt; children.length; i++) &#123; Wrapper wrapper = (Wrapper) children[i]; int loadOnStartup = wrapper.getLoadOnStartup(); if (loadOnStartup &lt; 0) continue; Integer key = Integer.valueOf(loadOnStartup); ArrayList&lt;Wrapper&gt; list = map.get(key); if (list == null) &#123; list = new ArrayList&lt;&gt;(); map.put(key, list); &#125; list.add(wrapper); &#125; // Load the collected &quot;load on startup&quot; servlets for (ArrayList&lt;Wrapper&gt; list : map.values()) &#123; for (Wrapper wrapper : list) &#123; try &#123; wrapper.load(); &#125; catch (ServletException e) &#123; getLogger().error(sm.getString(&quot;standardWrapper.loadException&quot;, getName()), StandardWrapper.getRootCause(e)); // NOTE: load errors (including a servlet that throws // UnavailableException from tht init() method) are NOT // fatal to application startup, excepted if failDeploymentIfServletLoadedOnStartupFails is specified if(getComputedFailCtxIfServletStartFails()) &#123; return false; &#125; &#125; &#125; &#125; return true; &#125; 那这些Wrapper是否就是Servlet ? WebXml.java 1private static final StringManager sm = StringManager.getManager(Constants.PACKAGE_NAME); Contants 1public static final String WEB_XML_LOCATION = &quot;/WEB-INF/web.xml&quot;; ContextConfig 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212private void configureContext(WebXml webxml) &#123; // As far as possible, process in alphabetical order so it is easy to // check everything is present // Some validation depends on correct public ID context.setPublicId(webxml.getPublicId()); // Everything else in order context.setEffectiveMajorVersion(webxml.getMajorVersion()); context.setEffectiveMinorVersion(webxml.getMinorVersion()); for (Entry&lt;String, String&gt; entry : webxml.getContextParams().entrySet()) &#123; context.addParameter(entry.getKey(), entry.getValue()); &#125; context.setDenyUncoveredHttpMethods( webxml.getDenyUncoveredHttpMethods()); context.setDisplayName(webxml.getDisplayName()); context.setDistributable(webxml.isDistributable()); for (ContextLocalEjb ejbLocalRef : webxml.getEjbLocalRefs().values()) &#123; context.getNamingResources().addLocalEjb(ejbLocalRef); &#125; for (ContextEjb ejbRef : webxml.getEjbRefs().values()) &#123; context.getNamingResources().addEjb(ejbRef); &#125; for (ContextEnvironment environment : webxml.getEnvEntries().values()) &#123; context.getNamingResources().addEnvironment(environment); &#125; for (ErrorPage errorPage : webxml.getErrorPages().values()) &#123; context.addErrorPage(errorPage); &#125; for (FilterDef filter : webxml.getFilters().values()) &#123; if (filter.getAsyncSupported() == null) &#123; filter.setAsyncSupported(&quot;false&quot;); &#125; context.addFilterDef(filter); &#125; for (FilterMap filterMap : webxml.getFilterMappings()) &#123; context.addFilterMap(filterMap); &#125; context.setJspConfigDescriptor(webxml.getJspConfigDescriptor()); for (String listener : webxml.getListeners()) &#123; context.addApplicationListener(listener); &#125; for (Entry&lt;String, String&gt; entry : webxml.getLocaleEncodingMappings().entrySet()) &#123; context.addLocaleEncodingMappingParameter(entry.getKey(), entry.getValue()); &#125; // Prevents IAE if (webxml.getLoginConfig() != null) &#123; context.setLoginConfig(webxml.getLoginConfig()); &#125; for (MessageDestinationRef mdr : webxml.getMessageDestinationRefs().values()) &#123; context.getNamingResources().addMessageDestinationRef(mdr); &#125; // messageDestinations were ignored in Tomcat 6, so ignore here context.setIgnoreAnnotations(webxml.isMetadataComplete()); for (Entry&lt;String, String&gt; entry : webxml.getMimeMappings().entrySet()) &#123; context.addMimeMapping(entry.getKey(), entry.getValue()); &#125; // Name is just used for ordering for (ContextResourceEnvRef resource : webxml.getResourceEnvRefs().values()) &#123; context.getNamingResources().addResourceEnvRef(resource); &#125; for (ContextResource resource : webxml.getResourceRefs().values()) &#123; context.getNamingResources().addResource(resource); &#125; boolean allAuthenticatedUsersIsAppRole = webxml.getSecurityRoles().contains( SecurityConstraint.ROLE_ALL_AUTHENTICATED_USERS); for (SecurityConstraint constraint : webxml.getSecurityConstraints()) &#123; if (allAuthenticatedUsersIsAppRole) &#123; constraint.treatAllAuthenticatedUsersAsApplicationRole(); &#125; context.addConstraint(constraint); &#125; for (String role : webxml.getSecurityRoles()) &#123; context.addSecurityRole(role); &#125; for (ContextService service : webxml.getServiceRefs().values()) &#123; context.getNamingResources().addService(service); &#125; for (ServletDef servlet : webxml.getServlets().values()) &#123; Wrapper wrapper = context.createWrapper(); // Description is ignored // Display name is ignored // Icons are ignored // jsp-file gets passed to the JSP Servlet as an init-param if (servlet.getLoadOnStartup() != null) &#123; wrapper.setLoadOnStartup(servlet.getLoadOnStartup().intValue()); &#125; if (servlet.getEnabled() != null) &#123; wrapper.setEnabled(servlet.getEnabled().booleanValue()); &#125; wrapper.setName(servlet.getServletName()); Map&lt;String,String&gt; params = servlet.getParameterMap(); for (Entry&lt;String, String&gt; entry : params.entrySet()) &#123; wrapper.addInitParameter(entry.getKey(), entry.getValue()); &#125; wrapper.setRunAs(servlet.getRunAs()); Set&lt;SecurityRoleRef&gt; roleRefs = servlet.getSecurityRoleRefs(); for (SecurityRoleRef roleRef : roleRefs) &#123; wrapper.addSecurityReference( roleRef.getName(), roleRef.getLink()); &#125; wrapper.setServletClass(servlet.getServletClass()); MultipartDef multipartdef = servlet.getMultipartDef(); if (multipartdef != null) &#123; if (multipartdef.getMaxFileSize() != null &amp;&amp; multipartdef.getMaxRequestSize()!= null &amp;&amp; multipartdef.getFileSizeThreshold() != null) &#123; wrapper.setMultipartConfigElement(new MultipartConfigElement( multipartdef.getLocation(), Long.parseLong(multipartdef.getMaxFileSize()), Long.parseLong(multipartdef.getMaxRequestSize()), Integer.parseInt( multipartdef.getFileSizeThreshold()))); &#125; else &#123; wrapper.setMultipartConfigElement(new MultipartConfigElement( multipartdef.getLocation())); &#125; &#125; if (servlet.getAsyncSupported() != null) &#123; wrapper.setAsyncSupported( servlet.getAsyncSupported().booleanValue()); &#125; wrapper.setOverridable(servlet.isOverridable()); context.addChild(wrapper); &#125; for (Entry&lt;String, String&gt; entry : webxml.getServletMappings().entrySet()) &#123; context.addServletMapping(entry.getKey(), entry.getValue()); &#125; SessionConfig sessionConfig = webxml.getSessionConfig(); if (sessionConfig != null) &#123; if (sessionConfig.getSessionTimeout() != null) &#123; context.setSessionTimeout( sessionConfig.getSessionTimeout().intValue()); &#125; SessionCookieConfig scc = context.getServletContext().getSessionCookieConfig(); scc.setName(sessionConfig.getCookieName()); scc.setDomain(sessionConfig.getCookieDomain()); scc.setPath(sessionConfig.getCookiePath()); scc.setComment(sessionConfig.getCookieComment()); if (sessionConfig.getCookieHttpOnly() != null) &#123; scc.setHttpOnly(sessionConfig.getCookieHttpOnly().booleanValue()); &#125; if (sessionConfig.getCookieSecure() != null) &#123; scc.setSecure(sessionConfig.getCookieSecure().booleanValue()); &#125; if (sessionConfig.getCookieMaxAge() != null) &#123; scc.setMaxAge(sessionConfig.getCookieMaxAge().intValue()); &#125; if (sessionConfig.getSessionTrackingModes().size() &gt; 0) &#123; context.getServletContext().setSessionTrackingModes( sessionConfig.getSessionTrackingModes()); &#125; &#125; // Context doesn&#x27;t use version directly for (String welcomeFile : webxml.getWelcomeFiles()) &#123; /* * The following will result in a welcome file of &quot;&quot; so don&#x27;t add * that to the context * &lt;welcome-file-list&gt; * &lt;welcome-file/&gt; * &lt;/welcome-file-list&gt; */ if (welcomeFile != null &amp;&amp; welcomeFile.length() &gt; 0) &#123; context.addWelcomeFile(welcomeFile); &#125; &#125; // Do this last as it depends on servlets for (JspPropertyGroup jspPropertyGroup : webxml.getJspPropertyGroups()) &#123; String jspServletName = context.findServletMapping(&quot;*.jsp&quot;); if (jspServletName == null) &#123; jspServletName = &quot;jsp&quot;; &#125; if (context.findChild(jspServletName) != null) &#123; for (String urlPattern : jspPropertyGroup.getUrlPatterns()) &#123; context.addServletMapping(urlPattern, jspServletName, true); &#125; &#125; else &#123; if(log.isDebugEnabled()) &#123; for (String urlPattern : jspPropertyGroup.getUrlPatterns()) &#123; log.debug(&quot;Skiping &quot; + urlPattern + &quot; , no servlet &quot; + jspServletName); &#125; &#125; &#125; &#125; for (Entry&lt;String, String&gt; entry : webxml.getPostConstructMethods().entrySet()) &#123; context.addPostConstructMethod(entry.getKey(), entry.getValue()); &#125; for (Entry&lt;String, String&gt; entry : webxml.getPreDestroyMethods().entrySet()) &#123; context.addPreDestroyMethod(entry.getKey(), entry.getValue()); &#125; &#125; 2. Tomcat核心架构 每一层级对应的都是xml文件中的标签，以及源码中的实体类，其中有多层的图形表示可以存在多个 Tips: 亿图不充钱限制了组件个数，Context只画了一个！ 2.2 Tomcat组件 XML配置文件结构如下： 1234567891011&lt;Server&gt; &lt;!--顶层类元素：一个配置文件中只能有一个&lt;Server&gt;元素，可包含多个Service。--&gt; &lt;Service&gt; &lt;!--顶层类元素：本身不是容器，可包含一个Engine，多个Connector。--&gt; &lt;Connector/&gt; &lt;!--连接器类元素：代表通信接口。--&gt; &lt;Engine&gt; &lt;!--容器类元素：为特定的Service组件处理所有客户请求，可包含多个Host。--&gt; &lt;Host&gt; &lt;!--容器类元素：为特定的虚拟主机处理所有客户请求，可包含多个Context。--&gt; &lt;Context&gt; &lt;!--容器类元素：为特定的Web应用处理所有客户请求。--&gt; &lt;/Context&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 2.2.1 Server 代表整个Tomcat实例，在JVM中式单例的，它还负责管理包含Service组件的声明周期，下图式对Server组件的一个简单描述： 可以在Server.xml文件对server组件进行配置 配置属性有：name, shutdown, port, command, class name等 shutdown port默认为8005 shutdown command 默认为SHUTDOWN; 处于安全，只能从同一台服务器发出SHUTDOWN命令 提供JNDI的实现，可以放任意对象（如DataSource, 环境变量等）； 2.2.2 Service Service组件代表的式一组请求处理主键，一个Server实例可以包含多个Service实例，每个Service实例与一组Connector实例和单个Engine实例相关联( Service 是 Server 内部的中间组件，它将一个或多个 Connector 绑定到一个Engine 上。) 单Service实例一般够用了，如果需要针对不同的IP或者port使用不同的Service组件来处理，则可以使用多Service实例 2.2.3 Connector Connector组件把Engine从不同的通信协议中隔离出来，如HTTP, HTTPS, AJP等； 可以配置Tomcat的工作模式: Standalone &amp; Conjunction Standalone模式：tomcat可以配置HTTP/HTTPS的connector，它既要处理静态内容，也要委托Engine处理动态内容 Conjunction模式：客户端是Apache或者是IIS之类的WEB Server； 当Web Server决定将请求转交给Tomcat处理时，它通过AJP协议与Tomcat交互；AJP是基于二进制流的比HTTP更高效一些； 关于Connector的几个重要点： 监听的IP和port 处理请求的最大线程数，如果所有的线程都忙，则会丢弃新的请求 所有的Connector接收到请求后，转化成统一的模式，再交给唯一的Engine处理；Engine负责处理请i去并产生响应； Connector将Engine产生的响应按照合适的协议发送到客户端 常见Connector： http/1.1 http/2 ajp(apache jserv protocol) 专用于tomcat前端是apache反向代理的情况下 Tomcat既作为web服务器（解析http协议，响应客户端，静态；非处理动态（委托）），也作为应用程序服务器：请求来自于浏览器。 Tomcat应该考虑工作情形并为相应情形下的请求分别定义好需要的连接器才能正确接收来自于客户端的请求。 此处暂先介绍HTTP/1.1连接器的属性设置。ajp后文再做介绍。 HTTP连接器表示支持HTTP/1.1协议的组件。设置了该连接器就表示catalina启用它的独立web服务功能，当然，肯定也提供它必须的servlets和jsp执行功能。在一个service中可以配置一个或多个连接器，每个连接器都可以将请求转发给它们相关联的engine以处理请求、创建响应。 每个流入的请求都需要一个独立的线程来接收。当并发请求数量超出maxThreads指定的值时，多出的请求将被堆叠在套接字（socket）中，直到超出acceptCount指定的值。超出accpetCount的请求将以&quot;connection refused&quot;错误进行拒绝。 12345678910111213141516171819202122232425262728&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;&lt;!--HTTP连接器的属性实在太多，详细配置方法见官方手册。通常定义HTTP连接器时必须定义的属性只有&quot;port&quot;。 --&gt;&lt;!-- address：指定连接器监听的地址，默认为所有地址，即0.0.0.0。 maxThreads：支持的最大并发连接数，默认为200；如果引用了executor创建的共享线程池，则该属性被忽略。 acceptCount：设置等待队列的最大长度；通常在tomcat所有处理线程均处于繁忙状态时，新发来的请求将被放置于等待队列中； maxConnections：允许建立的最大连接数。acceptCount和maxThreads是接受连接的最大线程数。存在一种情况，maxConnections小于acceptCount时，超出maxConnections的连接请求将被接收，但不会与之建立连接。 port：监听的端口，默认为0，此时表示随机选一个端口，通常都应该显式指定监听端口。 protocol：连接器使用的协议，用于处理对应的请求。默认为HTTP/1.1，此时它会自动在基于Java NIO或APR/native连接器之间进行切换。定义AJP协议时通常为AJP/1.3。 redirectPort：如果某连接器支持的协议是HTTP，当接收客户端发来的HTTPS请求时，则转发至此属性定义的端口。 connectionTimeout：等待客户端发送请求的超时时间，单位为毫秒，默认为60000，即1分钟；注意，这时候连接已经建立。 keepAliveTimeout：长连接状态的超时时间。超出该值时，长连接将关闭。 enableLookups：是否通过request.getRemoteHost()进行DNS查询以获取客户端的主机名；默认为true，应设置为false防止反解客户端主机；compression：是否压缩数据。默认为off。设置为on时表示只压缩text文本，设置为force时表示压缩所有内容。应该在压缩和sendfile之间做个权衡。 useSendfile：该属性为NIO（非阻塞IO）的属性，表示是否启用sendfile的功能。默认为true，启用该属性将会禁止compression属性。当协议指定为HTTP/1.1时，默认会自动在NIO/APR协议处理方式上进行按需切换。如要显式指定协议，方式如下： --&gt;&lt;connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;&gt;&lt;connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;&gt;&lt;connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;&gt;&lt;connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot;&gt;&lt;!-- 其中NIO是C/C++的非阻塞IO复用模型在JAVA中的IO实现，NIO2即AIO是异步NIO，即异步非阻塞IO： NioProtocol ：non blocking Java NIO connector Nio2Protocol：non blocking Java NIO2 connector AprProtocol ：the APR/native connector --&gt; 多个属性的SSL连接服务器 1234&lt;Connector port=&quot;8443&quot; maxThreads=&quot;150&quot; minSpareThreads=&quot;25&quot; maxSpareThreads=&quot;75&quot; enableLookups=&quot;false&quot; acceptCount=&quot;100&quot; debug=&quot;0&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt; 2.2.4 Engine ​ 其实就是Servlet Engine；一个service组件只能包含一个Engine组件；但是一个Engine可以包含多个Host组件；它接受代表请求和相应的对象，然后将工作委托给相应的host组件进行处理；如果没有找到对应的host组件，则委托给default host来处理； ​ Engine代表服务请求处理管道；由于Server可能有多个 Connector 连接器， Engine 负责接收并处理来自这些 Connector 的所有请求，并将响应返回给对应的 Connector，最终返回给客户端。 ​ Engine是service组件中用来分析协议的引擎机器，它从一个或多个connector上接收请求，并将请求交给对应的虚拟主机进行处理，最后返回完整的响应数据给connector，通过connector将响应数据返回给客户端。 只有一个engine元素必须嵌套在每个service中，且engine必须在其所需要关联的connector之后，这样在engine前面的connector都可以被此engine关联，而在engine后面的connector则被忽略，因为一个service中只允许有一个engine。 123456789101112&lt;!--定义--&gt;&lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;&lt;/Engine&gt;&lt;Engine name=&quot;Standalone&quot; defaultHost=&quot;localhost&quot; jvmRoute=&quot;TomcatA&quot;&gt;&lt;/Engine&gt;&lt;!--常用的engine属性有： className：实现engine的类，该类必须实现org.apache.catalina.Engine接口。不给定该属性时将采用默认的标准类org.apache.catalina.core.StandardEngine。 defaultHost：指定处理请求的默认虚拟主机。在Engine中定义的多个虚拟主机的主机名称中至少有一个跟defaultHost定义的主机名称同名。 name：Engine组件的名称，用于记录日志和错误信息，无关紧要的属性，可随意给定。 jvmRoute(session+标识符，记录在服务端)：在启用session粘性时指定使用哪种负载均衡的标识符。所有的tomcat server实例中该标识符必须唯一，它会追加在session标识符的尾部，因此能让前端代理总是将特定的session转发至同一个tomcat实例上。(Session与cookie功能效果相同。Session与Cookie的区别在于Session是记录在服务端的,而Cookie是记录在客户端的。 )注意: jvmRoute同样可以使用jvmRoute的系统属性来设置。如果此处设置了jvmRoute，则覆盖jvmRoute系统属性。关于jvmRoute的使用，在后面tomcat ajp负载均衡的文章中介绍。engine是容器中的顶级子容器，其内可以嵌套一个或多个Host作为虚拟主机，且至少一个host要和engine中的默认虚拟主机名称对应。除了host，还可以嵌套releam和valve组件。--&gt; 2.2.5 Host ​ Host容器用来定义虚拟主机。engine从connector接收到请求进行分析后，会将相关的属性参数传递给对应的(筛选方式是从请求首部的host字段和虚拟主机名称进行匹配)虚拟host进行处理。如果没有合适的虚拟主机，则传递给默认虚拟主机。因此每个容器中必须至少定义一个虚拟主机，且必须有一个虚拟主机和engine容器中定义的默认虚拟主机名称相同; 123456789101112131415&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Alias&gt;www.a.com&lt;/Alias&gt; &lt;!--Alias为Host指定的主机名定义主机别名--&gt;&lt;/Host&gt;&lt;!-- 常用属性说明： className：实现host容器的类，该类必须实现org.apache.catalina.Host接口。不给定该属性时将采用默认的标准类org.apache.catalina.core.StandardHost。 name：虚拟主机的主机名，忽略大小写(初始化时会自动转换为小写)。可以使用前缀星号通配符，如&quot;*.a.com&quot;。使用了星号前缀的虚拟主机的匹配优先级低于精确名称的虚拟主机。 appBase：此Host的webapps目录，即webapp部署在此虚拟主机上时的存放目录。包括非归档的web应用程序目录和归档后的WAR文件的目录。使用相对路径时基于$CATALINA_BASE。 xmlBase：部署在此虚拟主机上的context xml目录。 startStopThreads：启动context容器时的并行线程数。如果使用了自动部署功能，则再次部署或更新时使用相同的线程池。 autoDeploy：在Tomcat处于运行状态时放置于appBase目录中的应用程序文件是否自动进行deploy或自动更新部署状态。这等于同时开启了deployOnStartup属性和reload/redeploy webapp的功能。触发自动更新时将默认重载该webapp。默认为true。 unpackWars：在执行此webapps时是否先对归档格式的WAR文件解压再运行，设置为false时则直接执行WAR文件；默认为true。设置为false时会损耗性能。 workDir：该虚拟主机的工作目录。每个webapp都有自己的临时IO目录，默认该工作目录为$CATALINA_BASE/work。 大多数时候都只需设置虚拟主机名称name和appBase属性即可，其余采用默认，默认时会自动部署webapp--&gt; 两个重要点： domain name: 每个host必须要有一个唯一的domain name; 浏览器发过来的请求里包含有该domain name; domain name在Engine里必须是唯一的 app base folder: 发布到该host里的应用的目录名；可以是相对CATALINE_BASE的相对路径，也可以是文件系统的绝对路径 当host获得一个针对特定host请求时，将会在该Host环境下把请求匹配到对应的Context上；然后把请求交给这个Context来处理 2.2.6 Context ​ 一个Context对应一个web application； 它由多个servlet组成；在创建context时，将根据conf/web.xml和webapps/${context path}/WEB-INFO/web.xml加载servlet并创建映射表 Document Base: 存放war或解压后的context的地方 Context Path：唯一标志一个context;当没有匹配任何一个context时，默认的context将会处理该请求；默认的context的context path为空 Automatic reload: 一旦监测到context有修改，则会自动重启context，只用于开发模式； 2.2.7 Wrapper ​ Wrapper是context的子元素，代表了一个Servlet（或一个jsp被编译后的servlet）；它负责加载servlet、实例化servlet、以及触发生命周期方法的调用，如init()、service()、destory()；另外wrapper也负责调用与servlet相关的Filter。 2.2.8 嵌套组件 Excutor: 执行器，供 Connector 使用的线程池，可配置多个 cnnector自建，executer共享 执行器定义tomcat各组件之间共享的线程池。在以前，每个connector都会独自创建自己的线程池，但现在，可以定义一个线程池，各组件都可以共享该线程池，不过主要是为各connector之间提供共享。注意，executor创建的是共享线程池，如果某个connector不引用executor创建的线程池，那么该connector仍会根据自己指定的属性创建它们自己的线程池。 连接器必须要实现org.apache.catalina.Executor接口（server的classname，必须实现的接口）。它是一个嵌套在service组件中的元素，为了挑选所使用的connector，该元素还必须定义在connector元素之前。 1234567891011121314151617&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot;/&gt;&lt;!-- className（默认）：用于实现此组件的java类的名称，这个类必须实现接口org.apache.catalina.Executor。不 给定该属性时将采用默认的标准类org.apache.catalina.core.StandardThreadExecutor； name：该线程池的名称，其他组件需要使用该名称引用该线程池。 ---------------------------------------------------------------标准类的属性包括：threadPriority：线程优先级，默认值为5。daemon：线程是否以daemon的方式运行，默认值为true。namePrefix：执行器创建每个线程时的名称前缀，最终线程的名称为:namePrefix+threadNumber。maxThreads：线程池激活的最大线程数量。默认值为200。minSpareThreads：线程池中最少空闲的线程数量。默认值为25。maxIdleTime：在空闲线程关闭前的毫秒数。除非激活的线程数量小于或等于minSpareThreads的值，否则会有空闲线程的出现。默认值为60000ms，即空闲线程需要保留1分钟的空闲时间才被杀掉。maxQueueSize：可执行任务的最大队列数，达到队列上限时的连接请求将被拒绝。prestartminSpareThreads：在启动executor时是否立即创建minSpareThreads个线程数，默认为false，即在需要时才创建线程。--&gt; connector中指定所使用的线程 1234&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; Manager： 会话管理器：用于实现http会话管理的功能。 Loader： 类加载器 Valve： 阀门，Tomcat组件层面的过滤器 Resource：资源路径：配置 web 程序的资源信息，如数据库连接信息。 Realm：领域：用于用户的认证和授权。 Listener：监听器：监听已注册组件的生命周期。 Cluster： 集群：专用于配置 Tomcat 集群的元素。 2.2.8 container ​ container不是tomcat的组件，它是一个概念，统称；包含Engine、host、context、wrapper 12345Container(容器:包括以下所有组件)----Engine（分发用户请求）--------Host（主机）----------------Context（应用）--------------------Wrapper（Servlet） 2.2.9 Server.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 2.2 Tomcat请求处理过程 接收到用户HTTP请求： http://localhost:8080/app/login/auth1 请求被发送到本机端后8080，被在那里侦听的coyote HTTP/1.1 Connector获得 Connector把该请求交给它所在得service得Engine来处理，并等待engine得回应 Engine获得请求localhost/app/login/auth1，匹配它所拥有得所有虚拟主机host Engine获得请求到名为localhost得host（即使匹配不到也把请求交给该host处理，因为该host被定义为该Engine得默认主机） 名字为localhost的host主机获的请求/app/login/auth1，匹配它所拥有的所有context host匹配到路径为/app的context(如果匹配不到就把该请求交给路径名为“” 的context去处理) path=“/app”的context获得请求/login/auth1，在它的mapping table中寻找对应的servlet Context匹配到URL PATTERN为/auth1的servlet，对应于servlet类 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用Servlet的doGet或者doPost方法 Context把执行完了的HttpServletResponse对象发回给host Host把HttpServletResponse对象返回给Engine Engine把HttpServletResponse对象返回给Connnector Connector把HttpServletResponse对象返回给客户brower 3. Servlet规范 Java想要进行Web服务功能提供 当Http服务器接收请求后，如何知道调用哪些java类来处理请求呢？ 有些类可能就是用来封装变量的，有些类才是用来处理请求的。为了识别出那些具有处理请求的类，定义了一个接口，这个接口就叫Servlet接口，如果想要让业务类具备处理请求的能力，都必须实现这个接口，实现了接口的业务类叫做Servlet。 对于特定的请求，Http服务器如何知道由哪个Servlet来处理？Servlet又是由谁来实例化呢 于是又有了Servlet容器。Http服务器把请求交给Servlet容器去处理，Servlet容器会将请求转发到具体的Servlet,如果这个Servlet还没创建，就加载并实例化这个Servlet，然后调用这个Servlet的接口方法。 Http服务器不直接调用业务类，而是把请求交给容器来处理，容器通过Servlet接口调用业务类。因此Servlet接口和Servlet容器的出现，使Http服务器和业务类解耦。 Servlet规范：Servlet接口 + Servlet容器。 Tomcat按照Servlet规范的要求实现了Servlet容器，同时它也具有Http服务器的功能。（如果我们要实现新的业务功能，只需要实现一个Servlet，然后把它注册到Tomcat(Servlet容器)中，剩下的事情由Tomcat帮我们来处理）。 3.1 Servlet接口定义了五个方法 1234567891011public interface Servlet&#123; void init(ServletConfig config) throws ServletException; ServletConfig getServletConfig(); void service(ServletRequest req, ServletResponse res）throws ServletException, IOException; String getServletInfo(); void destroy();&#125; init(ServletConfig config)： 和生命周期有关的方法，Servlet容器在加载Servlet类的时候会调用init方法。可能会在init方法里初始化一些资源。比如Springmvc中的DispatcherServlet,在init方法中创建了自己的spring容器。 ServletConfig getServletConfig()： ServletConfig就是封装Servlet的初始化参数。可以在web.xml给Servlet配置参数，然后在程序中通过getServletConfig方法拿到这些参数。 service(ServletRequest req, ServletResponse res) 业务类在这个方法里实现处理逻辑。ServletRequest用来封装请求信息，ServletResponse用来封装响应信息。本质上这两个类是对通信协议的封装。Http协议中的请求和响应就是对应了HttpServletRequest和HttpServletResponse这两个类。我们可以通过HttpServletRequest来获取所有请求相关的信息，包括请求路径，Cookie，Http头，请求参数等。 String getServletInfo() destroy()： 和生命周期有关的方法，Servlet容器在卸载Servlet类的时候会调用destory方法。在destory方法里释放这些资源。 4. Servlet容器 4.1 Servlet容器工作流程 ​ 当客户请求某一个资源时，Http服务器会用一个ServletRequest对象把客户的请求信息封装起来，然后调用Servlet容器的service方法，Servlet容器拿到请求后，根据请求的URL和Servlet的映射关系，找到相应的Servlet，如果Servlet还没有被加载，就用反射机制创建这个Servlet，并调用Servlet的init方法来完成初始化，接着调用Servlet的service方法来处理请求，把ServletResponse对象返回给Http服务器，Http服务器会把响应发送给客户端。 4.2 Web应用 4.2.1 Servlet注册 Servlet容器负责实例化和调用Servlet，那么Servlet是怎么注册到Servlet容器的呢？ 我们一般以Web应用程序的方式来部署Servlet的。根据Servlet规范，Web应用程序有一定的目录结构： 12345| - MyWebApp | - WEB-INF/web.xml -- 配置文件，用来配置 Servlet 等 | - WEB-INF/lib/ -- 存放 Web 应用所需各种 JAR 包 | - WEB-INF/classes/ -- 存放你的应用类，比如 Servlet 类 | - META-INF/ -- 目录存放工程的一些信息 在这个目录下分别放置了Servlet的类文件，配置文件，静态资源文件，Servlet容器通过读取配置文件，就可以找到并加载Servlet。 4.2.2 ServletContext Servlet规范中定义了ServletContext这个接口来对应一个Web应用 Web应用部署好以后，Servlet容器在启动时会加载Web应用，并为每个Web应用创建唯一的ServletContext对象。你可以把ServletContext看成是一个全局对象，一个Web应用可能有多个Servlet，这些Servlet可以通过全局的ServletContext来共享数据，这些数据包括Web应用的初始化参数，Web应用目录下的文件资源等。因为ServletContext持有所有Servlet实例，还可以通过它来实现Servlet请求的转发。 4.2.3 扩展机制：Filter和Listener Filter：过滤器，这个接口允许对请求和响应做一些统一的定制化处理，比如可以根据请求的频率来限制访问，根据国家地区的不同来修改响应的内容。 过滤器原理：Web应用部署完以后，Servlet容器需要实例化Filter并把Filter链接成一个FilterChain。当请求进来时，获取第一个Filter并调用doFilter方法， doFilter方法负责调用 FilterChain的下一个Filter。 Listener：监听器，当Web应用在Servlet容器中运行时，Servlet容器内部会不断发生各种事件，比如Web应用的启动和停止，用户请求到达等。Servlet容器提供了一些默认的监听器来监听这些事件，当事件发生时，Servlet容器会负责调用监听器的方法。自定义监听器需要把监听器配置在web.xml中。比如：Spring就实现了自己的监听器，用来监听ServletContext的启动事件，目的是当Servlet容器启动时，创建并初始化全局的Spring容器。 5. 各种容器 Tomcat在启动时给每个Web应用创建一个全局的上下文环境，这个上下文就是ServletContext，为后面的Spring容器提供宿主环境。 Tomcat在启动过程中触发容器初始化事件，Spring的ContextLoaderListener会监听到这个事件，它的contextInitialized方法会被调用，然后Spring会初始化全局的Spring根容器，这个就是Spring的Ioc容器，Ioc容器初始化完毕后，Spring将其存储到ServletContext中，便于以后获取。 Tomcat启动时还会扫描Servlet，一个Web应用中的Servlet可以有多个，以SpringMvc中的DispatcherServet为例，这个Servlet实际上是一个标准的前端控制器，用来转发，匹配，处理每个Servlet请求。 Servlet一般会延迟加载，当第一个请求到达时，Tomcat发现DispatcherServet还没有被实例化，就调用DispatcherServet的init方法，DispatcherServet在初始化的时候会建立自己的容器，叫做SpringMvc容器，用来持有SpringMvc相关的Bean。同时，SpringMvc还会通过ServletContext拿到Spring根容器，并把Spring根容器设置为SpringMvc容器的父容器，Spring容器可以访问父容器中的Bean，但是父容器不能访问子容器中的Bean（Spring容器不能访问SpringMvc容器里的Bean —&gt;Controller里可以访问Service对象，但是在Service里不可以访问Controller对象）。 web容器中有servlet容器，spring项目部署后存在spring容器和springmvc容器。其中spring控制service层和dao层的bean对象。springmvc容器控制controller层bean对象。servlet容器控制servlet对象。项目启动是，首先 servlet初始化，初始化过程中通过web.xml中spring的配置加载spring配置，初始化spring容器和springmvc容器。待容器加载完成。servlet初始化完成，则完成启动。 HTTP请求到达web容器后，会到达Servlet容器，容器通过分发器分发到具体的spring的Controller层。执行业务操作后返回结果。","categories":[{"name":"tomcat","slug":"tomcat","permalink":"https://xiaoyuge5201.github.io/categories/tomcat/"}],"tags":[{"name":"Apache","slug":"Apache","permalink":"https://xiaoyuge5201.github.io/tags/Apache/"}]},{"title":"Docker安装RabbitMQ集群","slug":"rabbitmq","date":"2022-06-25T08:53:22.000Z","updated":"2022-06-30T06:21:18.312Z","comments":false,"path":"rabbitmq/","link":"","permalink":"https://xiaoyuge5201.github.io/rabbitmq/","excerpt":"","text":"1. 安装 Docker 更新yum源（如果你的网速慢这一步就别做了） 1sudo yum update 添加仓库 1sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 查看最新版本 12#如果之前安装了docker，需要卸载旧版本yum list docker-ce --showduplicates | sort -r 安装Docker CE版本 1yum install docker-ce -y 2. 安装 RabbitMQ 1个磁盘节点+2个内存节点 拉取RabbitMQ镜像（带managment） 1docker pull rabbitmq:3.7.17-management 创建docker网络（让容器可以和主机通信） 1docker network create rabbitmqnet 创建三个容器，端口分别是 5673 5674 5675 ，管理端口是 15673 15674 15675 12345678910#英文引号docker run -d \\ --name=rabbitmq1 \\ -p 5673:5672 \\ -p 15673:15672 \\ -e RABBITMQ_NODENAME=rabbitmq1 \\ -e RABBITMQ_ERLANG_COOKIE=&#x27;GUPAOEDUFORBETTERYOU&#x27; \\ -h rabbitmq1 \\ --net=rabbitmqnet \\ rabbitmq:management 123456789docker run -d \\ --name=rabbitmq2 \\ -p 5674:5672 \\ -p 15674:15672 \\ -e RABBITMQ_NODENAME=rabbitmq1 \\ -e RABBITMQ_ERLANG_COOKIE=&#x27;GUPAOEDUFORBETTERYOU&#x27; \\ -h rabbitmq2 \\ --net=rabbitmqnet \\ rabbitmq:management 123456789docker run -d \\ --name=rabbitmq3 \\ -p 5675:5672 \\ -p 15675:15672 \\ -e RABBITMQ_NODENAME=rabbitmq1 \\ -e RABBITMQ_ERLANG_COOKIE=&#x27;GUPAOEDUFORBETTERYOU&#x27; \\ -h rabbitmq3 \\ --net=rabbitmqnet \\ rabbitmq:management 后两个节点作为内存节点加入集群 12345docker exec -it rabbitmq2 /bin/bash #进入容器内部rabbitmqctl stop_app #停止rabbitmq 服务 rabbitmqctl reset #重置rabbitmq rabbitmqctl join_cluster --ram rabbitmq1@rabbitmq1 #加入集群rabbitmqctl start_app #启动服务 12345docker exec -it rabbitmq3 /bin/bashrabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster --ram rabbitmq1@rabbitmq1rabbitmqctl start_app 访问： http://ip:15673/; guest/guest登录 3. 常见问题 [error] Bad characters in cookie 12到创建容器的时候，docker run -d --name=rabbitmq1 -p 5673:5672 -p 15673:15672 -e RABBITMQ_NODENAME=rabbitmq1 -e RABBITMQ_ERLANG_COOKIE=‘GoodGoodStudyDayDayUp’ -h rabbitmq1 --net=rabbitmqnet rabbitmq:management由于Cookie的引号是中文引号，所以docker ps -a 时看到Status为Exited 解决方法：移除容器，把cookie的引号改为英文引号再执行就可以了","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://xiaoyuge5201.github.io/tags/rabbitMQ/"}]},{"title":"分库分表之 ShardingSphere-JDBC","slug":"sharding-jdbc","date":"2022-06-25T06:52:23.000Z","updated":"2022-06-28T03:09:56.084Z","comments":false,"path":"sharding-jdbc/","link":"","permalink":"https://xiaoyuge5201.github.io/sharding-jdbc/","excerpt":"","text":"1. 动态数据源解决方案 随着业务数据量逐渐增大，带来存储的瓶颈以及查询瓶颈，我们可以将数据存放到多个数据服务中，以达到减轻数据库压力，缩短数据库操作时间； 目前关于动态数据源的解决方案大致包含以下5种，今天主要是学习一下Sharding-jdbc； 关于Mycat请查看 mycat学习 这篇博客。 2. ShardingSphere简介 2018年5月，sharding-jdbc更名为ShardingSphere 2018年11月，Sharding-sphere正式进入Apache基金会孵化器 2020年4月，从Apache孵化器毕业，成为Apache顶级项目Apache ShardingSphere ShardingSphere目前的定位已远超过人们熟知的分库分表的功能了，其拥有自己的⼀套开源的分布式数据库中间件解决⽅案组成的⽣态圈（ShardingSphere-JDBC、ShardingSphere-Proxy，ShardingSphere-sidecar（计划中）） 他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景 官网地址：https://shardingsphere.apache.org/document/current/cn/overview/ 2.1 Apache ShardingSphere 官方定义：Apache ShardingSphere 是一套开源的分布式数据库增强计算引擎，其通过可插拔架构构建基于数据库之上的生态系统，实现包括数据分片、弹性伸缩、加密脱敏等功能为代表的增强能力 定位Apache ShardingSphere 产品定位为Database Plus，旨在构建异构数据库上层的标准和生态。 它关注如何充分合理地利用数据库的计算和存储能力，而并非实现一个全新的数据库 2.2 ShardingSphere-JDBC 定位于轻量级Java框架，在Java的jdbc层提供的额外服务， ShardingSphere-jdbc的主要功能在客户端尽心数据分片和读写分离，通过sharding-jdbc,应用可以使用jdbc访问已经读写分离的多个数据源，而不用关心数据库数量和数据的分布； 可以理解为增强版JDBC驱动，完全兼容JDBC和各种ORM框架 使用于任何给予Java的ORM框架，如：JPA、hibernate、mybatis、Spring JDBC Template或直接使用JDBC 基于任何第三方的数据库连接池，如：DBCP、C3P0、BoneCP、Druid、HikariCP等 支持任意实现JDBC规范的数据库，如Mysql、Oracle、SQLServer、PostgreSQL 源码：https://github.com/apache/shardingsphere/tree/master/shardingsphere-jdbc 2.3 ShardingSphere-Proxy 定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。 目前提供 MySQL 和 PostgreSQL（兼容 openGauss 等基于 PostgreSQL 的数据库）版本，它可以使用任何兼容 MySQL/PostgreSQL 协议的访问客户端（如：MySQL Command Client, MySQL Workbench, Navicat 等）操作数据，对 DBA 更加友好 向应用程序完全透明，可直接当做 MySQL/PostgreSQL 使用； 适用于任何兼容 MySQL/PostgreSQL 协议的的客户端。 源码：https://github.com/apache/shardingsphere/tree/master/shardingsphere-proxy 2.4 ShardingSphere-sidecar（TODO） 定位为 Kubernetes 的云原生数据库代理，以 Sidecar 的形式代理所有对数据库的访问。 通过无中心、零侵入的方案提供与数据库交互的啮合层，即 Database Mesh，又可称数据库网格。 3. 分片的核心概念 主要概念 由原来的一个数据库(表)拆分为真实存在的三个数据库(表) 逻辑表会在 SQL 解析和路由时被替换成真实的表名，分片键就是拆分的逻辑；sharding-jdbc可以选择多个分片键； 动态表 表名会变化，比如订单表，按照月份进行分表 绑定表 与Mycat的ER表对应，存在关联关系的两张表，他们的分片规则必须相同 广播表 与Mycat的全局表对应，所有节点的数据内容一致 4. Sharding-JDBC Demo演示 Apache ShardingSphere-JDBC 可以通过 Java，YAML，Spring 命名空间 和 Spring Boot Starter 这 4 种方式进行配置，开发者可根据场景选择适合的配置方式。 目前仅支持Java语言且java JRE 8或更高版本 下面使用SSM框架来集成shardingsphere-jdbc，操作数据库，由于资源有限，在一个数据库instance里面创建两个数据库db0、db1来模拟分库分表； 创建数据库db0,db1，以及创建下面的数据表 12345678910111213141516171819202122232425262728293031323334353637-- 用户表 CREATE TABLE `user_info` ( `user_id` bigint(128) NOT NULL, `user_name` varchar(45) DEFAULT NULL, `account` varchar(45) NOT NULL, `password` varchar(45) DEFAULT NULL, PRIMARY KEY (`user_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; -- 订单表 CREATE TABLE `t_order` ( `order_id` int(11) NOT NULL, `user_id` int(11) NOT NULL, PRIMARY KEY (`order_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; -- 订单明细表 CREATE TABLE `t_order_item` ( `item_id` int(11) NOT NULL, `order_id` int(11) NOT NULL, `user_id` int(11) NOT NULL, PRIMARY KEY (`item_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; -- 参数配置表 CREATE TABLE `t_config` ( `config_id` int(16) NOT NULL AUTO_INCREMENT, `para_name` varchar(255) DEFAULT NULL, `para_value` varchar(255) DEFAULT NULL, `para_desc` varchar(255) DEFAULT NULL, PRIMARY KEY (`config_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; truncate table user_info; truncate table t_order; truncate table t_order_item; truncate table t_config; 创建项目并引入依赖 1234567891011 &lt;!-- https://mvnrepository.com/artifact/org.apache.shardingsphere/shardingsphere-jdbc-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-jdbc-core&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.1.1&lt;/version&gt; &lt;/dependency&gt; 使用mybatisPlus逆向工程生成entity、mapper、service等相关代码，这里就不贴业务代码了。 编辑application.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051mybatis: mapper-locations: classpath:mapper/*.xml config-location: classpath:mybatis-config.xmlspring: shardingsphere: props: sql: show: true #打印sql语句 datasource: #数据源配置 names: db0,db1 db0: #数据源1 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/db1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: xiaoyuge db1: #数据源2 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/db1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8 username: root password: xiaoyuge sharding: #分片 default-database-strategy: #数据库分片策略 inline: sharding-column: user_id #分片键 algorithm-expression: db$&#123;user_id % 2&#125; #分片算法 tables: #表分片策略 user_info: actual-data-nodes: db$-&gt;&#123;0..1&#125;.user_info #真实存储数据的节点，可以使用行内表达式,$-&gt;&#123;&#125; 是标准语法 databaseStrategy: inline: shardingColumn: user_id algorithm-expression: db$&#123;user_id % 2&#125; #分片算法 key-generator: column: user_id type: SNOWFLAKE #主键策略：SNOWFLAKE 、 UUID，如果设置了主键策略，那么插入的时候就不用指定主键的值 t_order: databaseStrategy: inline: shardingColumn: order_id algorithm-expression: db$&#123;order_id % 2&#125; #分片算法 actual-data-nodes: db$-&gt;&#123;0..1&#125;.t_order t_order_item: databaseStrategy: inline: shardingColumn: order_id algorithm-expression: db$&#123;order_id % 2&#125; #分片算法 actual-data-nodes: db$-&gt;&#123;0..1&#125;.t_order_item binding-tables[0]: t_order,t_order_item #绑定表配置 broadcast-tables: t_config #广播表配置 测试简单分库user_info 1234567891011121314151617181920212223242526272829303132333435363738394041import com.ygb.entity.UserInfo;import com.ygb.service.UserService;import org.junit.Test;import org.junit.runner.RunWith;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import javax.annotation.Resource;import java.util.ArrayList;import java.util.List;@RunWith(SpringRunner.class)@SpringBootTest@MapperScan(basePackages = &quot;com.ygb.mapper&quot;)public class UserShardingTest &#123; @Resource UserService userService; @Test public void insert() &#123; //随机生成100条数据,插入到数据库中 for (int i = 1; i &lt;= 100; i++) &#123; UserInfo userInfo = new UserInfo(); userInfo.setAccount(&quot;account&quot; + i); userInfo.setPassword(&quot;password&quot; + i); userInfo.setUserName(&quot;name&quot; + i); userInfo.setUserId(i); userService.insert(userInfo); &#125; &#125; @Test public void select() &#123; UserInfo userInfo1 = userService.getUserInfoByUserId(1L); System.out.println(&quot;------userInfo1:&quot; + userInfo1); UserInfo userInfo2 = userService.getUserInfoByUserId(2L); System.out.println(&quot;------userInfo2:&quot; + userInfo2); &#125;&#125; 执行 insert方法后，结果如下图所示: 根据上面yaml配置user_info表按照分片键(sharding-column)user_id取模分片到不同数据库;user_id % 2 为偶数落下db0, 奇数落在db1 执行 select 方法，查询user_id为1 的数据，可以看到逻辑sql语句以及真实的sql语句路由到哪个节点上。 同理，查询user_id 为 2 的数据，根据表的分库规则，user_id % 2 == 0数据落在db0节点上； 测试绑定表t_order,t_order_item 12345678910111213141516@Testpublic void insert()&#123; for (int i = 1; i &lt;= 100; i++) &#123; //订单表 Order order = new Order(); order.setOrderId(i); order.setUserId(i); orderService.insert(order); //订单明细表 OrderItem orderItem = new OrderItem(); orderItem.setItemId(i); orderItem.setOrderId(i); orderItem.setUserId(i); orderItemService.insert(orderItem); &#125;&#125; 执行insert方法后，数据库表结果如下图所示： t_order表和t_order_item 使用相同的分片规则db$&#123;order_id % 2&#125;,相同的order_id分布在同一个节点上； 测试广播表t_config 1234567891011@Testpublic void insert()&#123; for (int i = 1; i &lt;= 10; i++) &#123; Config config = new Config(); config.setConfigId(i); config.setParaName(&quot;name&quot;+i); config.setParaValue(&quot;value&quot;+i); config.setParaDesc(&quot;desc&quot;+i); configService.insert(config); &#125;&#125; 执行insert方法后，查看执行日志，可以看到它向db0、db1两个节点分别发送了插入语句； 5. ShardingSphere分库分表原理剖析 基于上面的测试代码来分析ShardingSphere分库分表原理； 5.1 ShardingSphere-JDBC工作流程 1SQL 解析(解析引擎) =&gt; 执行器优化 =&gt; SQL 路由(路由引擎) =&gt; SQL 改写(改写引擎) =&gt; SQL 执行(执行引擎) =&gt; 结果归并(归并引擎) SQL解析 SQL 解析主要是词法和语法的解析。目前常见的 SQL 解析器主要有fdb，jsqlparser 和 Druid。Sharding-JDBC1.4.x之前的版本使用Druid作为SQL解析器。从 1.5.x 版本 开始，Sharding-JDBC采用完全自研的SQL解析引擎 SQL 路由 SQL 路由是根据分片规则配置以及解析上下文中的分片条件，将 SQL 定位至真正的 数据源。它又分为直接路由、标准路由和笛卡尔积路由 直接路由: 使用 Hint 方式。 标准路由：Binding 表是指使用同样的分片键和分片规则的一组表，也就是说任何情况下， Binding 表的分片结果应与主表一致。例如：order 表和 order_item 表，都根据 order_id 分片，结果应是 order_1 与 order_item_1 成对出现。这样的关联查询和单表查询复杂度 和性能相当。如果分片条件不是等于，而是 BETWEEN 或 IN，则路由结果不一定落入单 库（表），因此一条逻辑 SQL 最终可能拆分为多条 SQL 语句。 笛卡尔积路由：笛卡尔积查询最为复杂，因为无法根据 Binding 关系定位分片规则的一致性，所以 非 Binding 表的关联查询需要拆解为笛卡尔积组合执行。查询性能较低，而且数据库连 接数较高，需谨慎使用。 SQL改写 将逻辑表名称改成真实表名称，优化分页查询等 SQL执行 因为可能链接到多个真实数据源， Sharding -JDBC 将采用多线程并发执行 SQL SQL归并 如数据的组装、分页、排序等等。 下面我跟着源码学习一下完整的执行过程。 5.2 配置加载过程 首先由于我们引入sharding-jdbc-spring-boot-starter依赖，在依赖包中可以看到shardingSphere支持springboot,那么它肯定会有一个类似于SpringBoot自动装配类 SpringBootConfiguration这样的配置类； 查看一下源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/** * Spring boot starter configuration. */@Configuration@ComponentScan(&quot;org.apache.shardingsphere.spring.boot.converter&quot;)@EnableConfigurationProperties(&#123; SpringBootShardingRuleConfigurationProperties.class, SpringBootMasterSlaveRuleConfigurationProperties.class, SpringBootEncryptRuleConfigurationProperties.class, SpringBootPropertiesConfigurationProperties.class, SpringBootShadowRuleConfigurationProperties.class&#125;)@ConditionalOnProperty(prefix = &quot;spring.shardingsphere&quot;, name = &quot;enabled&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)@AutoConfigureBefore(DataSourceAutoConfiguration.class) //@AutoConfigureBefore自动装配在DataSourceAutoConfiguration装配类之前完成，也就是说Shardingsphere创建得数据源就是全局得数据源，项目只要涉及到对数据库得任何操作都会经过ShardingDataSource得这一层处理@RequiredArgsConstructorpublic class SpringBootConfiguration implements EnvironmentAware &#123; //将之前配置得规则映射到此配置文件中，为创建数据源得过程提供配置信息 private final SpringBootShardingRuleConfigurationProperties shardingRule; private final SpringBootMasterSlaveRuleConfigurationProperties masterSlaveRule; private final SpringBootEncryptRuleConfigurationProperties encryptRule; private final SpringBootShadowRuleConfigurationProperties shadowRule; private final SpringBootPropertiesConfigurationProperties props; //对象存放得是配置得所有数据源映射信息，为后面获取数据库连接以及数据分片提供基础能力 private final Map&lt;String, DataSource&gt; dataSourceMap = new LinkedHashMap&lt;&gt;(); private final String jndiName = &quot;jndi-name&quot;; /** * 上面的测试代码基于分片的 策略配置，所以只有 ShardingRuleCondition 才满足装配条件。 * ShardingDataSourceFactory工厂类来创建 ShardingDataSource数据源， * Get sharding data source bean. * 条件注入不同的数据源 * @return data source bean * @throws SQLException SQL exception */ @Bean @Conditional(ShardingRuleCondition.class) public DataSource shardingDataSource() throws SQLException &#123; //配置转换过程， return ShardingDataSourceFactory.createDataSource(dataSourceMap, new ShardingRuleConfigurationYamlSwapper().swap(shardingRule), props.getProps()); &#125; /** * Get master-slave data source bean. * 条件注入不同的数据源 * @return data source bean * @throws SQLException SQL exception */ @Bean @Conditional(MasterSlaveRuleCondition.class) public DataSource masterSlaveDataSource() throws SQLException &#123; return MasterSlaveDataSourceFactory.createDataSource(dataSourceMap, new MasterSlaveRuleConfigurationYamlSwapper().swap(masterSlaveRule), props.getProps()); &#125; /** * Get encrypt data source bean. *条件注入不同的数据源 * @return data source bean * @throws SQLException SQL exception */ @Bean @Conditional(EncryptRuleCondition.class) public DataSource encryptDataSource() throws SQLException &#123; return EncryptDataSourceFactory.createDataSource(dataSourceMap.values().iterator().next(), new EncryptRuleConfigurationYamlSwapper().swap(encryptRule), props.getProps()); &#125; /** * Get shadow data source bean. * 条件注入不同的数据源 * @return data source bean * @throws SQLException SQL exception */ @Bean @Conditional(ShadowRuleCondition.class) public DataSource shadowDataSource() throws SQLException &#123; return ShadowDataSourceFactory.createDataSource(dataSourceMap, new ShadowRuleConfigurationYamlSwapper().swap(shadowRule), props.getProps()); &#125; /** * Create sharding transaction type scanner * * @return sharding transaction type scanner */ @Bean public ShardingTransactionTypeScanner shardingTransactionTypeScanner() &#123; return new ShardingTransactionTypeScanner(); &#125; @Override public final void setEnvironment(final Environment environment) &#123; String prefix = &quot;spring.shardingsphere.datasource.&quot;; for (String each : getDataSourceNames(environment, prefix)) &#123; try &#123; //遍历环境变量，将数据源保存到 dataSourceMap dataSourceMap.put(each, getDataSource(environment, prefix, each)); &#125; catch (final ReflectiveOperationException ex) &#123; throw new ShardingSphereException(&quot;Can&#x27;t find datasource type!&quot;, ex); &#125; catch (final NamingException namingEx) &#123; throw new ShardingSphereException(&quot;Can&#x27;t find JNDI datasource!&quot;, namingEx); &#125; &#125; &#125; //----------------------------省略------------------------------&#125; ShardingDataSourceFactory工厂类创建ShardingDataSource数据源 1234567891011121314151617181920public class ShardingDataSource extends AbstractDataSourceAdapter &#123; private final ShardingRuntimeContext runtimeContext; static &#123; //初始化路由装饰器（路由引擎，SPI方式） NewInstanceServiceLoader.register(RouteDecorator.class); //创建SQL改写上下文装饰器（改写引擎，SPI方式） NewInstanceServiceLoader.register(SQLRewriteContextDecorator.class); // 创建结果处理引擎（归并引擎，用于对查询结果合并处理，同上） NewInstanceServiceLoader.register(ResultProcessEngine.class); &#125; public ShardingDataSource(Map&lt;String, DataSource&gt; dataSourceMap, ShardingRule shardingRule, Properties props) throws SQLException &#123; super(dataSourceMap); this.checkDataSourceType(dataSourceMap); //创建运行时上下文（全局分片运行时上下文，用于保存分片所需得相关配置） this.runtimeContext = new ShardingRuntimeContext(dataSourceMap, shardingRule, props, this.getDatabaseType()); &#125; //----------------------------省略------------------------------&#125; ShardingRule配置规则解析类 配置转换过程。会将分表规则、分库规则、分表算法、分库算法等都解析到对应得 ShardingRuleConfiguration 通用分片配置类中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public ShardingRuleConfiguration swap(YamlShardingRuleConfiguration yamlConfiguration) &#123; ShardingRuleConfiguration result = new ShardingRuleConfiguration(); Iterator var3 = yamlConfiguration.getTables().entrySet().iterator(); while(var3.hasNext()) &#123; //将我们配置得分库、分表策略、分库算法、分表算法解析到TableRuleConfiguration中，每一张表都会对应一个配置类 Entry&lt;String, YamlTableRuleConfiguration&gt; entry = (Entry)var3.next(); YamlTableRuleConfiguration tableRuleConfig = (YamlTableRuleConfiguration)entry.getValue(); tableRuleConfig.setLogicTable((String)entry.getKey()); result.getTableRuleConfigs().add(this.tableRuleConfigurationYamlSwapper.swap(tableRuleConfig)); &#125; result.setDefaultDataSourceName(yamlConfiguration.getDefaultDataSourceName()); //绑定表 result.getBindingTableGroups().addAll(yamlConfiguration.getBindingTables()); //广播表 result.getBroadcastTables().addAll(yamlConfiguration.getBroadcastTables()); if (null != yamlConfiguration.getDefaultDatabaseStrategy()) &#123; result.setDefaultDatabaseShardingStrategyConfig(this.shardingStrategyConfigurationYamlSwapper.swap(yamlConfiguration.getDefaultDatabaseStrategy())); &#125; if (null != yamlConfiguration.getDefaultTableStrategy()) &#123; result.setDefaultTableShardingStrategyConfig(this.shardingStrategyConfigurationYamlSwapper.swap(yamlConfiguration.getDefaultTableStrategy())); &#125; if (null != yamlConfiguration.getDefaultKeyGenerator()) &#123; result.setDefaultKeyGeneratorConfig(this.keyGeneratorConfigurationYamlSwapper.swap(yamlConfiguration.getDefaultKeyGenerator())); &#125; Collection&lt;MasterSlaveRuleConfiguration&gt; masterSlaveRuleConfigs = new LinkedList(); Iterator var9 = yamlConfiguration.getMasterSlaveRules().entrySet().iterator(); while(var9.hasNext()) &#123; Entry&lt;String, YamlMasterSlaveRuleConfiguration&gt; entry = (Entry)var9.next(); YamlMasterSlaveRuleConfiguration each = (YamlMasterSlaveRuleConfiguration)entry.getValue(); each.setName((String)entry.getKey()); masterSlaveRuleConfigs.add(this.masterSlaveRuleConfigurationYamlSwapper.swap((YamlMasterSlaveRuleConfiguration)entry.getValue())); &#125; result.setMasterSlaveRuleConfigs(masterSlaveRuleConfigs); if (null != yamlConfiguration.getEncryptRule()) &#123; result.setEncryptRuleConfig(this.encryptRuleConfigurationYamlSwapper.swap(yamlConfiguration.getEncryptRule())); &#125; return result;&#125; 1SpringBootConfiguration -&gt; ShardingDataSourceFactory -&gt; ShardingRule -&gt; ShardingDataSource -&gt; ShardingRuntimeContext 5.3 分片运行时上下文创建过程 创建数据源的时候会在构造器中将运行时上下文ShardingRuntimeContext一同创建出来，ShardingRuntimeContext得构造器如下图 123456789101112public final class ShardingRuntimeContext extends MultipleDataSourcesRuntimeContext&lt;ShardingRule&gt; &#123; private final CachedDatabaseMetaData cachedDatabaseMetaData; private final ShardingTransactionManagerEngine shardingTransactionManagerEngine; public ShardingRuntimeContext(Map&lt;String, DataSource&gt; dataSourceMap, ShardingRule shardingRule, Properties props, DatabaseType databaseType) throws SQLException &#123; super(dataSourceMap, shardingRule, props, databaseType); this.cachedDatabaseMetaData = this.createCachedDatabaseMetaData(dataSourceMap); this.shardingTransactionManagerEngine = new ShardingTransactionManagerEngine(); this.shardingTransactionManagerEngine.init(databaseType, dataSourceMap); &#125; //----------------- 省略------------&#125; 类关系图如下： 发现运行时上下文进行了抽象，分片运行时上下文继承了MultipleDataSourcesRuntimeContext 多数据源运行时上下文，而多数据源运行时上下文又继承了 AbstractRuntimeContext 抽象上下文。而创建 ShardingRuntimeContext 分片运行时上下文得时候会同时将分片规则保存在抽象类中 123456789101112131415161718192021public abstract class AbstractRuntimeContext&lt;T extends BaseRule&gt; implements RuntimeContext&lt;T&gt; &#123; private final T rule; private final ConfigurationProperties properties; private final DatabaseType databaseType; private final ExecutorEngine executorEngine; private final SQLParserEngine sqlParserEngine; protected AbstractRuntimeContext(T rule, Properties props, DatabaseType databaseType) &#123; this.rule = rule; //1. 缓存整个分片规则，为后续的分片操作提供依据 this.properties = new ConfigurationProperties(null == props ? new Properties() : props); this.databaseType = databaseType; //2. 缓存数据库类型，用于后续执行的时候加载对应的数据库元数据 //3.创建执行引擎，根据当前执行连接是否持有事物来决定是否异步执行，根据配置的executor.size 参数决定创建多少个线程的线程池，默认不配置得话，使用 cachepool，配置了就使用固定线程数得线程池 this.executorEngine = new ExecutorEngine((Integer)this.properties.getValue(ConfigurationPropertyKey.EXECUTOR_SIZE)); //解析引擎，用于解析SQL为抽象语法树，解析过程分为词法解析和语法解析。从3.0之后解析会全面替换为 ANTLR this.sqlParserEngine = SQLParserEngineFactory.getSQLParserEngine(DatabaseTypes.getTrunkDatabaseTypeName(databaseType)); ConfigurationLogger.log(rule.getRuleConfiguration()); ConfigurationLogger.log(props); &#125; //----------------- 省略------------&#125; 1ShardingRuntimeContext-&gt; MultipleDataSourcesRuntimeContext -&gt; AbstractRuntimeContext-&gt; ExecutorEngine-&gt; SQLParserEngine 5.4 分片处理过程 由于测试代码使用的是Mybatis层，这里只是对Mybatis处理流程进行分析。 当一个查询sql执行时，首先经过Mybatis层 调用org.apache.ibatis.executor.BaseExecutor # queryFromDatabase方法 123456789101112131415private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; this.localCache.putObject(key, ExecutionPlaceholder.EXECUTION_PLACEHOLDER); List list; try &#123; list = this.doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; this.localCache.removeObject(key); &#125; this.localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; this.localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; 通过模板抽象方法org.apache.ibatis.executor.BaseExecutor#doQuery查找具体实现（如果没有特殊配置，此处是SimpleExecutor）,并且将查询结果放入一级缓存中。 1234567891011121314 public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; List var9; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this.wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = this.prepareStatement(handler, ms.getStatementLog()); var9 = handler.query(stmt, resultHandler); &#125; finally &#123; this.closeStatement(stmt); &#125; return var9;&#125; 在org.apache.ibatis.executor.SimpleExecutor#doQuery方法中会创建一个Statement，而此实例就是ShardingPreparedStatement 经过Mybatis预编译SQL处理器，然后在org.apache.ibatis.executor.statement.PreparedStatementHandler#query方法中执行了PreparedStatement的execute方法 12345public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement)statement; ps.execute(); return this.resultSetHandler.handleResultSets(ps);&#125; 在前面知道此处的PreparedStatement是ShardingPreparedStatement，所以这里调用的是ShardingPreparedStatement的execute方法 123456789101112131415public boolean execute() throws SQLException &#123; boolean var1; try &#123; //1. 首先清理本地 PreparedStatementExecutor 中缓存的sql相关信息（创建执行单元的时候会将sql相关信息缓存到本地） this.clearPrevious(); //2. ② 然后执行prepare方法，此方法中有两个很关键的操作： this.prepare(); this.initPreparedStatementExecutor(); var1 = this.preparedStatementExecutor.execute(); &#125; finally &#123; this.clearBatch(); &#125; return var1;&#125; this.prepare()执行路由策略和SQL改写策略（这两步是分片的核心，另外也都是可供使用者扩展的） 1234567891011public ExecutionContext prepare(String sql, List&lt;Object&gt; parameters) &#123; List&lt;Object&gt; clonedParameters = this.cloneParameters(parameters); RouteContext routeContext = this.executeRoute(sql, clonedParameters); ExecutionContext result = new ExecutionContext(routeContext.getSqlStatementContext()); result.getExecutionUnits().addAll(this.executeRewrite(sql, clonedParameters, routeContext)); if ((Boolean)this.properties.getValue(ConfigurationPropertyKey.SQL_SHOW)) &#123; SQLLogger.logSQL(sql, (Boolean)this.properties.getValue(ConfigurationPropertyKey.SQL_SIMPLE), result.getSqlStatementContext(), result.getExecutionUnits()); &#125; return result;&#125; org.apache.shardingsphere.underlying.pluggble.prepare.BasePrepareEngine#executeRoute方法，注册路由装饰器。 1234private RouteContext executeRoute(String sql, List&lt;Object&gt; clonedParameters) &#123; this.registerRouteDecorator(); return this.route(this.router, sql, clonedParameters);&#125; 获取已经注册的RouteDecorator类实例，过滤掉泛型是BaseRule类型的（ShardingRule是其子类，所以重新的时候覆写 getType方法时，一定要是BaseRule类型的） 实例化路由装饰器 调用模板方法 route，最终会调用到DataNodeRouter的 executeRoute 方法 123456789101112 private RouteContext executeRoute(String sql, List&lt;Object&gt; parameters, boolean useCache) &#123; //1. 解析引擎： 通过 SQLParserEngine 解析SQL（并且此处默认是会将解析后的语句缓存起来，也就证实了前面会什么会先清理缓存），然后通过调用parse0方法解析SQL并缓存 RouteContext result = this.createRouteContext(sql, parameters, useCache); Entry entry; //2. 循环执行注册了的路由装饰器 for(Iterator var5 = this.decorators.entrySet().iterator(); var5.hasNext(); result = ((RouteDecorator)entry.getValue()).decorate(result, this.metaData, (BaseRule)entry.getKey(), this.properties)) &#123; entry = (Entry)var5.next(); &#125; return result;&#125; 然后开始分片路由装饰器org.apache.shardingsphere.sharding.route.engine.ShardingRouteDecorator#decorate ① 获取分片条件：根据不同的语句创建不同的 条件解析引擎来构造分片条件（获取的分片条件用于在执行路由判断时决定使用哪种分片策略） ② 通过工厂创建出 ShardingRouteEngine 实例，一般情况下 会创建出来 ShardingStandardRoutingEngine（没有配置什么骚操作的情况下），然后调用 标准路由执行引擎的 路由方法 12345678910111213141516171819202122 public RouteResult route(ShardingRule shardingRule) &#123; if (this.isDMLForModify(this.sqlStatementContext) &amp;&amp; 1 != ((TableAvailable)this.sqlStatementContext).getAllTables().size()) &#123; throw new ShardingSphereException(&quot;Cannot support Multiple-Table for &#x27;%s&#x27;.&quot;, new Object[]&#123;this.sqlStatementContext.getSqlStatement()&#125;); &#125; else &#123; //根据路由节点生成路由结果 RouteResult return this.generateRouteResult(this.getDataNodes(shardingRule, shardingRule.getTableRule(this.logicTableName))); &#125; &#125;/** * 获取数据节点：此处获取的就是真实的SQL路由情况（比如：ds0.table_0）， * 首先判断是否使用直接路由(强制路由)，若使用则走强制路由的分片算法去计算分片；然后再判断是否根据分片条件去路由， * 若有的话，则根据配置的分片算法（内联）根据分片值计算出来具体分到哪个库哪张表；若都没有的话，则直接走混合路由的处理逻辑 * */ private Collection&lt;DataNode&gt; getDataNodes(ShardingRule shardingRule, TableRule tableRule) &#123; if (this.isRoutingByHint(shardingRule, tableRule)) &#123; return this.routeByHint(shardingRule, tableRule); &#125; else &#123; return this.isRoutingByShardingConditions(shardingRule, tableRule) ? this.routeByShardingConditions(shardingRule, tableRule) : this.routeByMixedConditions(shardingRule, tableRule); &#125; &#125; 找到了路由节点 前面一直在讲prepare方法 回到ShardingPreparedStatement#execute方法中，调用initPreparedStatementExecutor() 初始化PreparedStatementExecutor实例 并将解析出来的执行上下文中的相关SQL语句组设置到缓存中,然后调用执行器的执行方法 12345678//此处会获取到需要执行的SQL集合，主要是通过maxConnectionsSizePerQuery每次执行时最大连接数来判断sql执行单元应该分成几组，maxConnectionsSizePerQuery的值默认是1。则表示，// 如果真实的sql有10条，那么每组拆分10条，总共拆分成1组，// 此时会判断 maxConnectionsSizePerQuery 是否大于10，小于的话则会选择当前批次执行的是连接限制模式（只允许占用一个库的一个连接），相反则是内存限制模式，不会限制创建的连接数 private void initPreparedStatementExecutor() throws SQLException &#123; this.preparedStatementExecutor.init(this.executionContext); this.setParametersForStatements(); this.replayMethodForStatements(); &#125; ShardingPreparedStatement#executeQuery方法中最后调用执行器的执行方法this.preparedStatementExecutor.execute() 12345678public boolean execute() throws SQLException &#123; //1. 获取sql执行回调类（真正操作数据库） boolean isExceptionThrown = ExecutorExceptionHandler.isExceptionThrown(); //2. 调用 executeCallback方法，此方法继承自父类AbstractStatementExecutor SQLExecuteCallback&lt;Boolean&gt; executeCallback = SQLExecuteCallbackFactory.getPreparedSQLExecuteCallback(this.getDatabaseType(), isExceptionThrown); List&lt;Boolean&gt; result = this.executeCallback(executeCallback); return null != result &amp;&amp; !result.isEmpty() &amp;&amp; null != result.get(0) ? (Boolean)result.get(0) : false;&#125; 进入父类org.apache.shardingsphere.shardingjdbc.executor.AbstractStatementExecutor#executeCallback，SQL执行模板SQLExecuteTemplate类通过委派其成员ExecutorEngine执行引擎来执行真正的操作 12345protected final &lt;T&gt; List&lt;T&gt; executeCallback(SQLExecuteCallback&lt;T&gt; executeCallback) throws SQLException &#123; List&lt;T&gt; result = this.sqlExecuteTemplate.execute(this.inputGroups, executeCallback); this.refreshMetaDataIfNeeded(this.connection.getRuntimeContext(), this.sqlStatementContext); return result;&#125; 执行引擎对拆分的SQL执行单元执行处理，如图： ① 并发执行（是否是并发执行通过 是否持有事务来判断的，例如 本地事务但是你修改为非自动提交事务，那么此时就是持有事务状态，则此时就是同步执行语句） ② 迭代出SQL执行组的第一个，其余的SQL异步执行 ③ 同步执行第一个SQL执行组（方便与后面的执行组进行合并起来） ④ 通过其内置的线程池来异步执行SQL 此时一条查询语句到这里就执行完了，接下来我们接着分析对查询结果进行处理的操作 回到Mybatis中，最后对查询的结果集进行处理( resultSetHandler. handleResultSets(ps)，此处是org.apache.ibatis.executor.resultset.DefaultResultSetHandler结果集处理器 ),如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException &#123; ErrorContext.instance().activity(&quot;handling results&quot;).object(this.mappedStatement.getId()); List&lt;Object&gt; multipleResults = new ArrayList(); int resultSetCount = 0; //1. 首先调用getFirstResultSet去获取第一个结果集，此处的 Statement 实例是 ShardingPreparedStatement ResultSetWrapper rsw = this.getFirstResultSet(stmt); List&lt;ResultMap&gt; resultMaps = this.mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); this.validateResultMapsCount(rsw, resultMapCount); while(rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) &#123; ResultMap resultMap = (ResultMap)resultMaps.get(resultSetCount); this.handleResultSet(rsw, resultMap, multipleResults, (ResultMapping)null); rsw = this.getNextResultSet(stmt); this.cleanUpAfterHandlingResultSet(); ++resultSetCount; &#125; String[] resultSets = this.mappedStatement.getResultSets(); if (resultSets != null) &#123; while(rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) &#123; ResultMapping parentMapping = (ResultMapping)this.nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) &#123; String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = this.configuration.getResultMap(nestedResultMapId); this.handleResultSet(rsw, resultMap, (List)null, parentMapping); &#125; rsw = this.getNextResultSet(stmt); this.cleanUpAfterHandlingResultSet(); ++resultSetCount; &#125; &#125; return this.collapseSingleResultList(multipleResults);&#125;//这里的Statement ShardingPreparedStatementprivate ResultSetWrapper getFirstResultSet(Statement stmt) throws SQLException &#123; ResultSet rs = stmt.getResultSet(); while(rs == null) &#123; if (stmt.getMoreResults()) &#123; rs = stmt.getResultSet(); &#125; else if (stmt.getUpdateCount() == -1) &#123; break; &#125; &#125; return rs != null ? new ResultSetWrapper(rs, this.configuration) : null;&#125; 调用了getResultSet()方法； 进入到org.apache.shardingsphere.shardingjdbc.jdbc.core.statement.ShardingPreparedStatement# getResultSet 将查询返回的结果集进行合并处理，Shardingsphere 的归并引擎功能上划分：遍历归并、排序归并（SQL中存在ORDER BY语句）、分组归并（SQL中有GroupBy子句）、聚合归并（含有聚合函数）、分页归并（含有Limit关键字） 12345678910111213public ResultSet getResultSet() throws SQLException &#123; if (null != this.currentResultSet) &#123; return this.currentResultSet; &#125; else &#123; if (this.executionContext.getSqlStatementContext() instanceof SelectStatementContext || this.executionContext.getSqlStatementContext().getSqlStatement() instanceof DALStatement) &#123; List&lt;ResultSet&gt; resultSets = this.getResultSets(); // ① MergedResult mergedResult = this.mergeQuery(this.getQueryResults(resultSets)); // ② this.currentResultSet = new ShardingResultSet(resultSets, mergedResult, this, this.executionContext); &#125; return this.currentResultSet; &#125;&#125; ① 获取所有Statement对应的结果集，此处是拿到真正数据源所对应的Statement实例，比如：我现在的数据源是 HikariDateSource，那么拿到的就是 HikariProxyPreparedStatement ② 执行合并逻辑：首先将结果集封装成流式查询结果对象StreamQueryResult，接着创建合并引擎org.apache.shardingsphere.underlying.pluggble.merge.MergeEngine#merge，然后调用合并引擎的合并方法 1234public MergedResult merge(List&lt;QueryResult&gt; queryResults, SQLStatementContext sqlStatementContext) throws SQLException &#123; this.registerMergeDecorator(); // ③ return this.merger.process(queryResults, sqlStatementContext); // ④ &#125; ③ 实例化合并引擎处理器ResultProcessEngine ④ 调用MergeEntry的 process 方法，委派来进行合并逻辑。 ⑤ ⑥ 中，判断若是ResultMergerEngine类型的合并引擎，则调用其merge方法执行真正的合并逻辑 显然满足类型判断，则此处会调用ShardingResultMergerEngine#newInstance 方法来实例化真正用于合并数据流的引擎 1234567public ResultMerger newInstance(DatabaseType databaseType, ShardingRule shardingRule, ConfigurationProperties properties, SQLStatementContext sqlStatementContext) &#123; if (sqlStatementContext instanceof SelectStatementContext) &#123; return new ShardingDQLResultMerger(databaseType); &#125; else &#123; return (ResultMerger)(sqlStatementContext.getSqlStatement() instanceof DALStatement ? new ShardingDALResultMerger(shardingRule) : new TransparentResultMerger()); &#125;&#125; 显然此处是查询语句，那么最终用于合并的引擎就是 ShardingDQLResultMerger，然后执行其merge方法 ⑦ 中判断sql中包含哪些关键字，然后创建对应的合并结果，如果条件都不满足，那么默认会使用 遍历流式归并方式合并数据。假设 我们此处SQL中带有 order by关键字，那么创建得合并结果对象就是OrderByStreamMergedResult ⑧ 对创建出来的排序合并结果进行装饰操作（就是判断有没有别的关键字，例如：Limit，如果有就会创建LimitDecoratorMergedResult 装饰器对象，在之前的排序合并基础上又多一个 Limit功能），再回到 ShardingPreparedStatement中，会创建一个 ShardingResultSet对象设置到当前的成员变量currentResultSet中，并返回。 此时如果是批量的场景，返回的结果集中实际上已经包含了所有的结果集（前面存放在OrderByStreamMergedResult的 orderByValuesQueue 队列中） 排序归并流程： 调用合并结果的 next方法时会执行如图 最后流程又回到Mybatis 结果集处理上了，将结果返回给请求调用方 6. 分片策略 策略包括了算法，算法是策略的一个属性。 Sharding-JDBC 中的分片策略有两个维度：分库（数据源分片）策略和分表策略；（mycat只支持要么分库或者要么分表） 跟 Mycat 不一样，Sharding-JDBC 没有提供内置的分片算法，而是通过实现接口ShardingStrategy， 让开发者自行实现，这样可以根据业务实际情况灵活地实现分片。 6.1 行表达式分片策略 InlineShardingStrategy 算法：行内表达式 $-&gt;{} 文档路径：https://shardingsphere.apache.org/document/current/cn/features/sharding/concept/inline-expression/ 只支持单分片键，提供对=和IN 操作的支持。行内表达式的配置比较简单。 例如： begin..end表示范围区间，如：db{begin..end} 表示范围区间，如：dbbegin..end表示范围区间，如：db-&gt;{0…1}表示db0, db1 [unit1,unit2,unitx]表示枚举值，如：{[unit1, unit2, unit_x]} 表示枚举值，如 ：[unit1,unit2,unitx​]表示枚举值，如：{[‘db0’, ‘db1’]} t_user_$-&gt;{u_id % 8} 表示 t_user 表根据 u_id 模 8，而分成 8 张表，表名称为 t_user_0 到 t_user_7。 行表达式中如果出现连续多个expression或{ expression }或expression或-&gt;{ expression }表达式，整个表达式最终的结果将会根据每个子表达式的结果进行笛卡尔组合。 例如，以下行表达式： [′db1′,′db2′]table{[&#x27;db1&#x27;, &#x27;db2&#x27;]}_table[′db1′,′db2′]t​able{1…3} 最终会解析为： db1_table1, db1_table2, db1_table3, db2_table1, db2_table2, db2_table3 6.2 标准分片策略 StandardShardingStrategy 标准分片策略只支持但分片键，提供了两个分片算法，分别对应了IN、BETWEEN 和 =；如果要是用标准分片策略，必须要实现PreciseShardingAlgorithm,用来处理=和IN的分片 RangeShardingAlgorithm是可选的，如果没有实现，SQL语句会发送到所有节点上执行。 算法：范围分片RangeShardingAlgorithm 和 精确分片PreciseShardingAlgorithm两种算法 123456789101112131415161718192021/** * 自定义分库策略 * 数据库分库的策略，根据分片键，返回数据库名称 */public class DBShardAlgo implements PreciseShardingAlgorithm&lt;Long&gt; &#123; @Override public String doSharding(Collection&lt;String&gt; collection, PreciseShardingValue&lt;Long&gt; preciseShardingValue) &#123; String db_name=&quot;ds&quot;; Long num= preciseShardingValue.getValue()%2; db_name=db_name + num; System.out.println(&quot;----------------db_name:&quot; + db_name); for (String each : collection) &#123; System.out.println(&quot;ds:&quot; + each); if (each.equals(db_name)) &#123; return each; &#125; &#125; throw new IllegalArgumentException(); &#125;&#125; 123456789101112131415161718/** * 自定义分表策略 * 等值查询使用的分片算法，包括in */public class TblPreShardAlgo implements PreciseShardingAlgorithm&lt;Long&gt; &#123; @Override public String doSharding(Collection&lt;String&gt; availableTargetNames, PreciseShardingValue&lt;Long&gt; shardingColumn) &#123; // 不分表 System.out.println(&quot;-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-availableTargetNames:&quot; + availableTargetNames); for (String tbname : availableTargetNames) &#123; //如果这里要分表可以根据 shardingColumn.getValue() % 2 //也可以根据月份分表，user_info_202201这种，只需要在这里拼接表名即可 System.out.println(shardingColumn.getValue() % 2+&quot;-------&quot;+ tbname); return tbname; &#125; throw new IllegalArgumentException(); &#125;&#125; 那么在配置文件中只需要指定分配规则 123##为了缩减篇幅，这里改成properties的格式spring.shardingsphere.sharding.tables.t_order.databaseStrategy.standard.shardingColumn=order_idspring.shardingsphere.sharding.tables.t_order.databaseStrategy.standard.precise-algorithm-class-name=com.ygb.config.TblPreShardAlgo 范围分片： 123456789101112131415161718192021/** * 范围查询所使用的分片算法 */public class TblRangeShardAlgo implements RangeShardingAlgorithm&lt;Long&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, RangeShardingValue&lt;Long&gt; rangeShardingValue) &#123; System.out.println(&quot;范围-*-*-*-*-*-*-*-*-*-*-*---------------&quot;+availableTargetNames); System.out.println(&quot;范围-*-*-*-*-*-*-*-*-*-*-*---------------&quot;+rangeShardingValue); Collection&lt;String&gt; collect = new LinkedHashSet&lt;&gt;(); Range&lt;Long&gt; valueRange = rangeShardingValue.getValueRange(); for (Long i = valueRange.lowerEndpoint(); i &lt;= valueRange.upperEndpoint(); i++) &#123; for (String each : availableTargetNames) &#123; if (each.endsWith(i % availableTargetNames.size() + &quot;&quot;)) &#123; collect.add(each); &#125; &#125; &#125; return collect; &#125;&#125; 查看数据库db0、db1，可以看到只有db0有数据； 6.3 复合分片策略 ComplexShardingStrategy 复合分片策略支持多分片键 算法：ComplexKeysShardingAlgorithm 场景：根据日期和ID两个字段分片，每个月3张表，先根据日期，然后在根据ID取模分片 6.4 Hint分片策略 HintShardingStrategy 通过 Hint 而非 SQL 解析的方式分片的策略 算法：HintShardingAlgorithm 6.5 不分片策略 NoneShardingStrategy 只在一个节点存储 算法：无 与Mycat对比 ShardingSphere-JDBC Mycat 工作层面 JDBC协议 Mysql协议/JDBC协议 运行方式 Jar包，客户端 独立服务，服务端 开发方式 代码/配置改动 连接地址修改（数据源） 运维方式 无 管理独立服务，运维成本高 性能 多线程并发操作，性能高 独立服务+网络开销，存在性能损失风险 功能范围 协议层面 包括分布式事务、数据迁移等 适用操作 OLTP OLTP+OLAP 支持数据库 基于JDBC协议的数据库 MySQL 和其他支持 JDBC 协议的数据库 支持语言 Java 支持 JDBC 协议的语言 从易用性和功能完善的角度来说，Mycat 似乎比 Sharding-JDBC 要好，因为有现成 的分片规则，也提供了4种ID生成方式，通过注解可以支持高级功能，比如跨库关联查询。 建议：小型项目可以用 Sharding-JDBC。大型项目，可以用 Mycat。","categories":[{"name":"ShardingSphere-jdbc","slug":"ShardingSphere-jdbc","permalink":"https://xiaoyuge5201.github.io/categories/ShardingSphere-jdbc/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://xiaoyuge5201.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"kafka常用命令","slug":"kafka-command","date":"2022-06-23T06:57:03.000Z","updated":"2022-06-30T07:29:54.684Z","comments":false,"path":"kafka-command/","link":"","permalink":"https://xiaoyuge5201.github.io/kafka-command/","excerpt":"","text":"1. 脚本概览 bin目录下的脚本作用 脚本 作用 connect-distributed.sh 用于启动多节点的Distributed模式的Kafka Connect组件 connect-standalone.sh 用于启动单节点的Standalone模式的Kafka Connect组件 kafka-acls.sh 用于设置Kafka权限，比如设置哪些用户可以访问Kafka的哪些TOPIC的权限 kafka-broker-api-versions.sh 主要用于验证不同Kafka版本之间服务器和客户端的适配性 kafka-configs.sh 配置管理脚本 kafka-console-consumer.sh kafka消费者控制台 kafka-console-producer.sh kafka生产者控制台 kafka-consumer-groups.sh kafka消费者组相关信息 kafka-consumer-perf-test.sh kafka消费者性能测试脚本 kafka-delegation-tokens.sh 用于管理Delegation Token。基于Delegation Token的认证是一种轻量级的认证机制，是对SASL认证机制的补充。 kafka-delete-records.sh 用于删除Kafka的分区消息 kafka-dump-log.sh 用于查看Kafka消息文件的内容 kafka-log-dirs.sh 用于查询各个Broker上的各个日志路径的磁盘占用情况 kafka-mirror-maker.sh 用于在Kafka集群间实现数据镜像 kafka-preferred-replica-election.sh 用于执行Preferred Leader选举，可以为指定的主题执行更换Leader的操作 kafka-producer-perf-test.sh kafka生产者性能测试脚本 kafka-reassign-partitions.sh 用于执行分区副本迁移以及副本文件路径迁移。 kafka-replica-verification.sh 复制进度验证脚本 kafka-run-class.sh 用于执行任何带main方法的Kafka类 kafka-server-start.sh 启动kafka服务 kafka-server-stop.sh 停止kafka服务 kafka-streams-application-reset.sh 用于给Kafka Streams应用程序重设位移，以便重新消费数据 kafka-topics.sh topic管理脚本 kafka-verifiable-consumer.sh 可检验的kafka消费者 kafka-verifiable-producer.sh 可检验的kafka生产者 trogdor.sh Kafka的测试框架，用于执行各种基准测试和负载测试 zookeeper-server-start.sh 启动zk服务 zookeeper-server-stop.sh 停止zk服务 zookeeper-shell.sh zk客户端 2. Broker服务 1、启动服务 1./kafka-server-start.sh ../config/server.properties 2、后台启动 1./kafka-server-start.sh -daemon ../config/server.properties 3、停止服务 1./kafka-server-stop.sh ../config/server.properties 3. 元数据 1、创建topic 1./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic my-test-topic 2、查看所有topic 1./kafka-topics.sh --bootstrap-server localhost:9092 --list 从Kafka 2.2版本开始，Kafka社区推荐用–bootstrap-server参数替换–zookeeper参数用于指定Kafka Broker。集群的多个IP端口用逗号,隔开 3、查看topic详细信息 1kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic_name 4、给topic增加分区（只能增加不能减少） 1./kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-test-topic --partitions 10 5、删除topic（标记删除） 1./kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-test-topic 6、永久删除需要修改配置文件： 1delete.topic.enable=true 7、强制删除TOPIC的方法： 手动删除ZooKeeper节点/admin/delete_topics下以待删除TOPIC为名的znode。 手动删除TOPIC在磁盘上的分区目录。 在ZooKeeper中执行rmr /controller，触发Controller重选举，刷新Controller缓存。可能会造成大面积的分区Leader重选举。可以不执行，只是Controller缓存中没有清空待删除TOPIC，不影响使用。 8、修改partition副本数： 先配置一个reassign.json文件，内容： 例如my-test-topic有3个分区，原来只有一个副本，增加到2个副本 12345&#123;&quot;version&quot;:1, &quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;my-test-topic&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1]&#125;,&#123;&quot;topic&quot;:&quot;my-test-topic&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1,2]&#125;,&#123;&quot;topic&quot;:&quot;my-test-topic&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[2,0]&#125;]&#125; 执行kafka-reassign-partitions脚本： 1./kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file reassign.json --execute 4. 生产者 1、发送消息 1./kafka-console-producer.sh --broker-list localhost:9092 --topic my-test-topic 5. 消费者 1、消费消息 1./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-test-topic 2、查看消费者组提交的位移数据: 1./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; --from-beginning","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://xiaoyuge5201.github.io/tags/kafka/"}]},{"title":"CentOS安装kafka 3.2.0单机版","slug":"kafka-install","date":"2022-06-23T06:19:35.000Z","updated":"2022-07-03T13:46:45.355Z","comments":false,"path":"kafka-install/","link":"","permalink":"https://xiaoyuge5201.github.io/kafka-install/","excerpt":"","text":"1. JDK依赖 请参考这篇博客：Linux安装JDK以及配置 2. 下载解压Kafka 下载地址：https://kafka.apache.org/downloads， 点击相应的版本，下载Binary 二进制版本而不是源码 我这里下载的是3.2.0版本（https://www.apache.org/dyn/closer.cgi?path=/kafka/3.2.0/kafka_2.12-3.2.0.tgz） 1234cd /usr/local/toolswget https://dlcdn.apache.org/kafka/3.2.0/kafka_2.12-3.2.0.tgztar -xzvf kafka_2.12-3.2.0.tgzcd kafka_2.12-3.2.0 3. 启动zookeeper(默认端口2181) kafka需要依赖ZK，安装包中已经自带了一个ZK，也可以改成指定已运行的ZK。 如果改成指定的ZK需要修改修改 kafka 安装目录下的 config/server.properties 文件中的 zookeeper.connect 。这里使用自带的ZK。 后台启动zk 1nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt;&gt; zookeeper.nohup &amp; 检查zookeeper是否启动成功： 1ps -ef|grep zookeeper 4. 启动kafka（默认端口9092） 修改相关配置 1vim config/server.properties 123456broker.id=1 #Broker ID启动以后就不能改了listeners=PLAINTEXT://192.168.44.160:9092 #取消注释，改成本机IP：num.partitions=1 #num.partitions后面增加2行。auto.create.topics.enable=true #发送到不存在topic自动创建delete.topic.enable=true #允许永久删除topic 后台启动kafka 12345 nohup ./bin/kafka-server-start.sh ./config/server.properties &amp;#或者./bin/kafka-server-start.sh -daemon ./config/server.properties 5. 创建Topic 创建一个名为gptest的topic，只有一个副本，一个分区： 1sh bin/kafka-topics.sh --create --bootstrap-server localhost:2181 --replication-factor 1 --partitions 1 --topic gptest 查看已经创建的 topic： 1sh bin/kafka-topics.sh -list -bootstrap-server localhost:2181 从Kafka 2.2版本开始，Kafka社区推荐用–bootstrap-server参数替换–zookeeper参数用于指定Kafka Broker。集群的多个IP端口用逗号,隔开 5. 启动Producer 打开一个窗口，在kafka解压目录下： 1sh bin/kafka-console-producer.sh --broker-list localhost:9092 --topic gptest 6. 启动Consumer 在一个新的远程窗口中： 1sh bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic gptest --from-beginning 7. Producer窗口发送消息 输入hello world 回车 消费者收到了消息： 8. 删除kafka全部数据 1、停止每台机器上的kafka； 2、删除kafka存储目录（server.properties文件log.dirs配置，默认为“/tmp/kafka-logs”）全部topic的数据目录； 3、删除zookeeper上与kafka相关的znode节点；除了/zookeeper 4、重启kafka。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://xiaoyuge5201.github.io/tags/kafka/"}]},{"title":"VMWare创建虚拟机并设置静态IP","slug":"static-ip-setting","date":"2022-06-12T01:06:54.000Z","updated":"2022-06-30T01:58:55.722Z","comments":false,"path":"static-ip-setting/","link":"","permalink":"https://xiaoyuge5201.github.io/static-ip-setting/","excerpt":"","text":"1. VMware+Centos7 静态IP设置 1.1 VMware设置 省略windows安装VMWare的过程。 查看虚拟网卡信息 虚拟机安装好以后，当前的系统会多出来两个虚拟网卡，一般情况下这两个网卡的命名是 12VMware Virtual Ethernet Adapter for VMnet1VMware Virtual Ethernet Adapter for VMnet8 我们可以把虚拟机中的系统的静态IP绑定到VMnet8上，所以下一步我们看一下VMnet8的ip地址 查看虚拟网卡IP 在当前操作系统中，输入ipconfig -all显示网卡的IP信息如下 记住当前VMnet8网卡的网段，如图所示，网段为:192.168.8 虚拟机设置 打开VMware，进入编辑 -&gt; 虚拟机网络编辑器 选中VMnet8这个网卡，点击NAT设置 在NAT设置中，可以看到子网IP、网关IP等信息。这里我们需要把网关IP记录下来： 192.168.8.2 设置虚拟机的网络连接方式 选中创建好的虚拟机，右键设置进入虚拟机设置面板。 将网络社配置设置为自定义，选中VMnet8这个网卡保存 1.2 Centos7中的静态ip设置 前置工作完成之后，就开始进入虚拟机的设置环节了 找到网卡信息配置 1ifconfig 找到网卡名称ens33，输入命令 1vi /etc/sysconfig/network-scripts/ifcfg-ens33 修改配置 这个配置需要修改两个地方 设置BOOTPROTO=“static” 添加IPADDR/NETMASK/DNS1/GATEWAY这几个配置 配置说明 IPADDR 就是当前虚拟机要设置的固定ip地址，网段要一致，我这边的案例是在8网段(这个网段是VMnet8对应的子网网段，不是真实机上的网段）。 NETMASK 子网掩码 用VMnet8对应的子网掩码值就行 DNS1 在真实机器上通过ipconfig，获得真实机器的网卡对应的DNS地址，填在这个位置 GATEWAY 网关地址，用前面第二个步骤中找到的网关地址： 192.168.8.2 重启网络服务 1service network restart 1.3 可能会遇到的问题 VMnet8的网段和真实机器上的网段不一样 真实机器的网段是8， 而VMnet8的网段是136. 由于网段不一致，就会存在网络不通的问题。所以第一步，应该是把VMnet8这个网卡的网段重新设置， 进入VMware， 找到 编辑 -&gt;虚拟网络编辑器 点击更改设置 修改子网IP，原本的网段是136， 改成8网段。 保存以后，改网卡会自动重启 真实机器无法Ping通虚拟机 原因1： 虚拟机的网段设置不正确，这个网段不是真实机器的网段，而是VMnet8 NAT模式对应的网段，本案例中的网段是8. 原因2：虚拟机迁移过，原本设置的网段在新的网络中无效，可以在VMware这个工具的如下菜单处 编辑 -&gt; 虚拟网络编辑器 还原默认设置，这个还原操作会重建虚拟网卡， 重建之后，VMware NAT模式的子网地址的网段会发生变化。后续的配置采用这个网段就行 2. Mac用VMWare创建虚拟机并设置静态IP 参考博客：https://blog.51cto.com/u_15298624/3033418","categories":[{"name":"经验分享","slug":"经验分享","permalink":"https://xiaoyuge5201.github.io/categories/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"}],"tags":[{"name":"ip","slug":"ip","permalink":"https://xiaoyuge5201.github.io/tags/ip/"}]},{"title":"Vue学习","slug":"vue-1","date":"2022-06-11T14:12:58.000Z","updated":"2022-06-27T08:47:38.757Z","comments":false,"path":"vue-1/","link":"","permalink":"https://xiaoyuge5201.github.io/vue-1/","excerpt":"","text":"1. 什么是vue vue 官网：https://cn.vuejs.org/ 渐进式框架， 2.安装 安装 npm npm 全称为 Node Package Manager，是一个基于Node.js的包管理器，也是整个Node.js社区最流行、支持的第三方模块最多的包管理器。 1npm -v 由于网络原因 安装 cnpm 12345#旧版，cnpm官方公告将在2022年6月30日停止老域名解析npm install -g cnpm --registry=https://registry.npm.taobao.org #新版npm install -g cnpm --registry=https://registry.npmmirror.com 安装 vue-cli 1cnpm install -g @vue/cli 安装 webpack webpack 是 JavaScript 打包器(module bundler) 1cnpm install -g webpack 3 Vue练习 3.1 Vue实例 1234567891011121314151617181920&lt;div id=&quot;app&quot;&gt; &#123;&#123; message &#125;&#125; &#123;&#123; name &#125;&#125;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt; var data = &#123; message: &#x27;hello world&#x27;, name: &#x27;xiaoyuge&#x27; &#125;; //view model 数据模型 vm var vm = new Vue(&#123; el: &#x27;#app&#x27;, //如果要某一个属性声明式响应，必须在new vue的时候声明 data: data &#125;); //vm.$data.message = data.message == vm.message; //实例创建之后，可以通过 vm.$data 访问原始数据对象。Vue 实例也代理了 data 对象上所有的 property，因此访问 vm.message 等价于访问 vm.$data.message vm.$watch(&#x27;message&#x27;, function(newVal, oldVal) &#123; console.log(newVal, oldVal); &#125;) //修改值必须放到后面， vm.$data.message = &quot;test....&quot;&lt;/script&gt; 3.2 数据和方法 当一个 Vue 实例被创建时，它将 data 对象中的所有的 property 加入到 Vue 的响应式系统中。当这些 property 的值发生改变时，视图将会产生“响应”，即匹配更新为新的值 12345678910111213141516171819// 我们的数据对象var data = &#123; a: 1 &#125;// 该对象被加入到一个 Vue 实例中var vm = new Vue(&#123; data: data&#125;)// 获得这个实例上的 property// 返回源数据中对应的字段vm.a == data.a // =&gt; true// 设置 property 也会影响到原始数据vm.a = 2data.a // =&gt; 2// ……反之亦然data.a = 3vm.a // =&gt; 3 当这些数据改变时，视图会进行重渲染。值得注意的是只有当实例被创建时就已经存在于 data 中的 property 才是响应式的。也就是说如果你添加一个新的 property，比如 1vm.b = &#x27;hi&#x27; 那么对 b 的改动将不会触发任何视图的更新。如果你知道你会在晚些时候需要一个 property，但是一开始它为空或不存在，那么你仅需要设置一些初始值。比如： 1234567data: &#123; newTodoText: &#x27;&#x27;, visitCount: 0, hideCompletedTodos: false, todos: [], error: null&#125; 这里唯一的例外是使用 Object.freeze()，这会阻止修改现有的 property，也意味着响应系统无法再追踪变化 1234567891011121314151617&lt;div id=&quot;app&quot;&gt; &lt;p&gt;&#123;&#123; foo &#125;&#125;&lt;/p&gt; &lt;!-- 这里的 `foo` 不会更新！ --&gt; &lt;button v-on:click=&quot;foo = &#x27;baz&#x27;&quot;&gt;Change it&lt;/button&gt;&lt;/div&gt;&lt;script&gt;var obj = &#123; foo: &#x27;bar&#x27;&#125;Object.freeze(obj)new Vue(&#123; el: &#x27;#app&#x27;, data: obj&#125;)&lt;/script&gt; 除了数据 property，Vue 实例还暴露了一些有用的实例 property 与方法。它们都有前缀 $，以便与用户定义的 property 区分开来。例如： 12345678910111213var data = &#123; a: 1 &#125;var vm = new Vue(&#123; el: &#x27;#example&#x27;, data: data&#125;)vm.$data === data // =&gt; truevm.$el === document.getElementById(&#x27;example&#x27;) // =&gt; true// $watch 是一个实例方法vm.$watch(&#x27;a&#x27;, function (newValue, oldValue) &#123; // 这个回调将在 `vm.a` 改变后调用&#125;) 2.3 生命周期钩子 Vue 实例从创建到销毁的过程，就是生命周期。也就是从开始创建、初始化数据、编译模板、挂载Dom→渲染、更新→渲染、卸载等一系列过程，我们称这是 Vue 的生命周期 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;div id=&quot;app&quot;&gt; &#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt; var vm = new Vue(&#123; el: &quot;#app&quot;, data: &#123; msg: &quot;hi vue&quot;, &#125;, //在实例初始化之后，数据观测 (data observer) 和 event/watcher 事件配置之前被调用。 beforeCreate: function() &#123; console.log(&#x27;beforeCreate&#x27;); &#125;, //在实例创建完成后被立即调用。 // 在这一步，实例已完成以下的配置：数据观测 (data observer)，属性和方法的运算，watch/event 事件回调。 // 然而，挂载阶段还没开始，$el 属性目前不可见 created: function() &#123; console.log(&#x27;created&#x27;); &#125;, //在挂载开始之前被调用：相关的渲染函数首次被调用 beforeMount: function() &#123; console.log(&#x27;beforeMount&#x27;); &#125;, //el 被新创建的 vm.$el 替换, 挂在成功 mounted: function() &#123; console.log(&#x27;mounted&#x27;); &#125;, //数据更新时调用 beforeUpdate: function() &#123; console.log(&#x27;beforeUpdate&#x27;); &#125;, //组件 DOM 已经更新, 组件更新完毕 updated: function() &#123; console.log(&#x27;updated&#x27;); &#125;, beforeDestroy() &#123; console.log(&quot;=========&quot; + &quot;beforeDestroy：销毁之前&quot; + &quot;========&quot;); console.log(this.$el); console.log(this.$data); &#125;, destroyed() &#123; console.log(&quot;==========&quot; + &quot;destroyed：销毁之后&quot; + &quot;===========&quot;); console.log(this.$el); &#125;, activated() &#123; console.log(&quot;&quot;); &#125;, deactivated() &#123; console.log(&quot;&quot;); &#125; &#125;); //3秒后修改值，触发beforeUpdate, updated事件 setTimeout(function() &#123; vm.msg = &quot;change ......&quot;; &#125;, 3000);&lt;/script&gt; 控制台依次打印： beforeCreate created beforeMount mounted beforeUpdate updated 注意事项： 123不要在选项 property 或回调上使用箭头函数，比如 created: () =&gt; console.log(this.a) 或 vm.$watch(&#x27;a&#x27;, newValue =&gt; this.myMethod())。因为箭头函数并没有 this，this 会作为变量一直向上级词法作用域查找，直至找到为止，经常导致 Uncaught TypeError: Cannot read property of undefined 或 Uncaught TypeError: this.myMethod is not a function 之类的错误。 3.3 条件与循环 v-if: 控制切换一个元素是否显示 1234567891011121314&lt;div id=&quot;vue-app&quot;&gt; &lt;p v-if=&quot;seen&quot;&gt;v-if: 如果为false，Dom将不渲染该元素&lt;/p&gt; &lt;p v-show=&quot;seen&quot;&gt;show：Dom渲染，只是通过css控制display属性是否显示&lt;/p&gt; &lt;p&gt;show: 渲染时开销大；v-if：渲染时开销小；具体场景根据实际情况选定&lt;/p&gt;&lt;/div&gt;&lt;script&gt; var vm = new Vue(&#123; el: &#x27;#vue-app&#x27;, data: &#123; seen: true &#125; &#125;) vm.seen = false;&lt;/script&gt; 当改变seen 的值为false的时候，v-if绑定的元素Dom元素不渲染 v-for: 绑定数组的数据来渲染一个项目列表 123456789101112131415161718192021222324252627282930313233343536 &lt;div id=&quot;vue-app&quot;&gt; &lt;!--遍历输出list--&gt; &lt;p&gt;遍历输出list&lt;/p&gt; &lt;ol&gt; &lt;li v-for=&quot;item in list&quot;&gt; &#123;&#123; item.name &#125;&#125; &lt;/li&gt; &lt;/ol&gt; &lt;br&gt; &lt;p&gt;遍历输出map key value-&lt;/p&gt; &lt;ul&gt; &lt;li v-for=&quot;value, key in object&quot;&gt; &#123;&#123;key&#125;&#125; : &#123;&#123; value &#125;&#125; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script&gt; var vm = new Vue(&#123; el: &#x27;#vue-app&#x27;, data:&#123; list:[ &#123;name: &#x27;张三&#x27;&#125;, &#123;name: &#x27;李四&#x27;&#125;, &#123;name: &#x27;王五&#x27;&#125; ], object: &#123;truetruetitle: &#x27;How to do lists in Vue&#x27;,truetrueauthor: &#x27;Jane Doe&#x27;,truetruepublishedAt: &#x27;2016-04-10&#x27; &#125; &#125; &#125;) //往数组里面添加元素，页面上响应式渲染 vm.list.push(&#123;name:&#x27;赵六&#x27;&#125;); &lt;/script&gt; 3.4 处理用户输入 v-on: 事件监听器 1234567891011121314151617181920212223242526272829303132333435&lt;div id=&quot;app&quot;&gt; &lt;div id=&quot;example-1&quot;&gt; &lt;!-- 单击事件：计算器加一 --&gt; &lt;button v-on:click=&quot;counter += 1&quot;&gt; 数值 : &#123;&#123; counter &#125;&#125; &lt;/button&gt;&lt;br /&gt; &lt;!-- 双击事件 --&gt; &lt;button v-on:dblclick=&quot;greet(&#x27;abc&#x27;, $event)&quot;&gt;Greet&lt;/button&gt; &lt;/div&gt; &lt;div id=&quot;example-2&quot;&gt; &lt;p&gt;&#123;&#123; message &#125;&#125;&lt;/p&gt; &lt;!-- 单击 --&gt; &lt;button v-on:click=&quot;reverseMessage&quot;&gt;反转消息&lt;/button&gt; &lt;/div&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt; var vm = new Vue(&#123; el: &quot;#app&quot;, data: &#123; counter: 0, name: &quot;vue&quot;, message: &#x27;hello world&#x27; &#125;, methods: &#123; greet: function(str, e) &#123; alert(str); &#125;, reverseMessage: function() &#123; //更新了应用的状态，但没有触碰 DOM。所有的 DOM 操作都由 Vue 来处理，这样我们只需要关注逻辑层面即可 //this 表示vue实例对象，可以获取相关的数据信息 this.message = this.message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125; &#125; &#125;);&lt;/script&gt; v-model: 表单输入和应用状态之间的双向绑定 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;div id=&quot;app&quot;&gt; &lt;div id=&quot;example-1&quot;&gt; &lt;input v-model=&quot;message&quot; placeholder=&quot;edit me&quot;&gt; &lt;p&gt;Message is: &#123;&#123; message &#125;&#125;&lt;/p&gt; &lt;textarea v-model=&quot;message2&quot; placeholder=&quot;add multiple lines&quot;&gt;&lt;/textarea&gt; &lt;p style=&quot;white-space: pre-line;&quot;&gt;&#123;&#123; message2 &#125;&#125;&lt;/p&gt; &lt;br /&gt; &lt;div style=&quot;margin-top:20px;&quot;&gt; &lt;input type=&quot;checkbox&quot; id=&quot;jack&quot; value=&quot;Jack&quot; v-model=&quot;checkedNames&quot;&gt; &lt;label for=&quot;jack&quot;&gt;Jack&lt;/label&gt; &lt;input type=&quot;checkbox&quot; id=&quot;john&quot; value=&quot;John&quot; v-model=&quot;checkedNames&quot;&gt; &lt;label for=&quot;john&quot;&gt;John&lt;/label&gt; &lt;input type=&quot;checkbox&quot; id=&quot;mike&quot; value=&quot;Mike&quot; v-model=&quot;checkedNames&quot;&gt; &lt;label for=&quot;mike&quot;&gt;Mike&lt;/label&gt; &lt;br&gt; &lt;span&gt;Checked names: &#123;&#123; checkedNames &#125;&#125;&lt;/span&gt; &lt;/div&gt; &lt;br&gt; &lt;div style=&quot;margin-top:20px;&quot;&gt; &lt;input type=&quot;radio&quot; id=&quot;one&quot; value=&quot;One&quot; v-model=&quot;picked&quot;&gt; &lt;label for=&quot;one&quot;&gt;One&lt;/label&gt; &lt;br&gt; &lt;input type=&quot;radio&quot; id=&quot;two&quot; value=&quot;Two&quot; v-model=&quot;picked&quot;&gt; &lt;label for=&quot;two&quot;&gt;Two&lt;/label&gt; &lt;br&gt; &lt;span&gt;Picked: &#123;&#123; picked &#125;&#125;&lt;/span&gt; &lt;/div&gt; &lt;button type=&quot;button&quot; @click=&quot;submit&quot;&gt;提交&lt;/button&gt; &lt;/div&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt; var vm = new Vue(&#123; el: &quot;#app&quot;, data: &#123; //这里可以设置初始值，也可以设置为&#x27;&#x27; 空值 message: &quot;test&quot;, message2: &quot;hi&quot;, checkedNames: [&#x27;Jack&#x27;, &#x27;John&#x27;], //多选框，值是数组格式 picked: &quot;Two&quot; &#125;, methods: &#123; submit: function() &#123; //this代表的是vue实例对象，可以通过this获取表单数据，如下 var params = &#123; message: this.message, message2: this.message2, checkedNames: this.checkedNames, picked: this.picked &#125; console.log(params); &#125; &#125; &#125;);&lt;/script&gt;","categories":[{"name":"vue","slug":"vue","permalink":"https://xiaoyuge5201.github.io/categories/vue/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://xiaoyuge5201.github.io/tags/vue/"}]},{"title":"SpringBoot参数校验","slug":"springboot-validate-params","date":"2022-06-06T03:02:20.000Z","updated":"2022-06-06T07:36:56.711Z","comments":false,"path":"springboot-validate-params/","link":"","permalink":"https://xiaoyuge5201.github.io/springboot-validate-params/","excerpt":"","text":"1. 前言 在控制器类的方法里自己写校验逻辑代码也可以，只是不够优美，业界有更好的处理方法，主要有以下几种。 2. PathVariable校验 1234567/** * 使用正则表达式限制group 只能是a-zA-Z0-9_ */@GetMapping(&quot;/path/&#123;group:[a-zA-Z0-9_]+&#125;/&#123;userid&#125;&quot;)public String path(@PathVariable(&quot;group&quot;) String group, @PathVariable(&quot;userid&quot;) Integer userid) &#123; return group + &quot;:&quot; + userid;&#125; 当请求URI不满足正则表达式时，客户端将收到404错误码，不方便的是，不能通过捕获异常的方式，向前端返回统一的、自定义格式的响应参数 3. 方法参数校验 1234567@GetMapping(&quot;/validate&quot;)@ResponseBodypublic String validate1( @Size(min = 1, max = 10, message = &quot;姓名长度必须为1到10&quot;) @RequestParam(&quot;name&quot;) String name, @Min(value = 10, message = &quot;年龄最小为10&quot;) @Max(value = 100, message = &quot;年龄最大为100&quot;) @RequestParam(&quot;age&quot;) Integer age) &#123; return name + &quot;:&quot; + age;&#125; 使用@Size 、@Min、@Max等校验注解进行参数校验 如果前端传递的参数不满足规则，则跑出异常，上面代码中@size、@Min、@Max注解来源于validation-api包中。 更多注解参 参数校验注解 小节。 4.表单对象/VO对象校验 当参数是VO时，可以在VO类的属性上添加校验注解。 123456789101112131415public class User &#123; @Size(min = 1,max = 10,message = &quot;姓名长度必须为1到10&quot;) private String name; @NotEmpty private String firstName; @Min(value = 10,message = &quot;年龄最小为10&quot;)@Max(value = 100,message = &quot;年龄最大为100&quot;) private Integer age; @Future @JSONField(format=&quot;yyyy-MM-dd HH:mm:ss&quot;) private Date birth; //。。。&#125; 其中，@Future注解要求必须是相对当前时间来讲“未来的”某个时间。@Past表示过去的某个时间 12345@PostMapping(&quot;/validate2&quot;)@ResponseBodypublic User validate2(@Valid @RequestBody User user)&#123; return user;&#125; 5.自定义校验规则 5.1 自定义注解校验 需要自定义一个注解类和一个校验类。 12345678910111213141516171819import javax.validation.Constraint;import javax.validation.Payload;import java.lang.annotation.*;@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.PARAMETER,ElementType.FIELD&#125;)@Constraint(validatedBy = FlagValidatorClass.class)public @interface FlagValidator &#123; // flag的有效值，多个使用,隔开 String values(); // flag无效时的提示内容 String message() default &quot;flag必须是预定义的那几个值，不能随便写&quot;; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 1234567891011121314151617181920212223242526272829303132333435import javax.validation.ConstraintValidator;import javax.validation.ConstraintValidatorContext;public class FlagValidatorClass implements ConstraintValidator&lt;FlagValidator,Object&gt; &#123; /** * FlagValidator注解规定的那些有效值 */ private String values; @Override public void initialize(FlagValidator flagValidator) &#123; this.values = flagValidator.values(); &#125; /** * 用户输入的值，必须是FlagValidator注解规定的那些值其中之一。 * 否则，校验不通过。 * @param value 用户输入的值，如从前端传入的某个值 */ @Override public boolean isValid(Object value, ConstraintValidatorContext constraintValidatorContext) &#123; // 切割获取值 String[] value_array = values.split(&quot;,&quot;); Boolean isFlag = false; for (int i = 0; i &lt; value_array.length; i++)&#123; // 存在一致就跳出循环 if (value_array[i] .equals(value))&#123; isFlag = true; break; &#125; &#125; return isFlag; &#125;&#125; 使用我们自定义的注解： 123456public class User &#123; // 前端传入的flag值必须是1或2或3，否则校验失败 @FlagValidator(values = &quot;1,2,3&quot;) private String flag ; //。。。&#125; 5.2 分组校验 123456789101112131415161718192021222324import org.hibernate.validator.constraints.Length;import javax.validation.constraints.Min;import javax.validation.constraints.NotNull;public class Resume &#123; public interface Default &#123; &#125; public interface Update &#123; &#125; @NotNull(message = &quot;id不能为空&quot;, groups = Update.class) private Long id; @NotNull(message = &quot;名字不能为空&quot;, groups = Default.class) @Length(min = 4, max = 10, message = &quot;name 长度必须在 &#123;min&#125; - &#123;max&#125; 之间&quot;, groups = Default.class) private String name; @NotNull(message = &quot;年龄不能为空&quot;, groups = Default.class) @Min(value = 18, message = &quot;年龄不能小于18岁&quot;, groups = Default.class) private Integer age; //。。。&#125; 12345678910111213141516171819/** * 使用Defaul分组进行验证 * @param resume * @return */@PostMapping(&quot;/validate5&quot;)public String addUser(@Validated(value = Resume.Default.class) @RequestBody Resume resume) &#123; return &quot;validate5&quot;;&#125;/** * 使用Default、Update分组进行验证 * @param resume * @return */@PutMapping(&quot;/validate6&quot;)public String updateUser(@Validated(value = &#123;Resume.Update.class, Resume.Default.class&#125;) @RequestBody Resume resume) &#123; return &quot;validate6&quot;;&#125; 建立了两个分组，名称分别为Default、Update。POST方法提交时使用Defaut分组的校验规则，PUT方法提交时同时使用两个分组规则。 6. 异常拦截器 通过设置全局异常处理器，统一向前端返回校验失败信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import com.scj.springbootdemo.WebResult;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.util.CollectionUtils;import org.springframework.validation.ObjectError;import org.springframework.web.bind.MethodArgumentNotValidException;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;import javax.validation.ConstraintViolation;import javax.validation.ConstraintViolationException;import java.util.List;import java.util.Set;/** * 全局异常处理器 */@ControllerAdvicepublic class GlobalExceptionHandler &#123; private Logger logger = LoggerFactory.getLogger(GlobalExceptionHandler.class); /** * 用来处理bean validation异常 * @param ex 异常信息 * @return 结果 */ @ExceptionHandler(ConstraintViolationException.class) @ResponseBody public WebResult resolveConstraintViolationException(ConstraintViolationException ex)&#123; WebResult errorWebResult = new WebResult(WebResult.FAILED); Set&lt;ConstraintViolation&lt;?&gt;&gt; constraintViolations = ex.getConstraintViolations(); if(!CollectionUtils.isEmpty(constraintViolations))&#123; StringBuilder msgBuilder = new StringBuilder(); for(ConstraintViolation constraintViolation :constraintViolations)&#123; msgBuilder.append(constraintViolation.getMessage()).append(&quot;,&quot;); &#125; String errorMessage = msgBuilder.toString(); if(errorMessage.length()&gt;1)&#123; errorMessage = errorMessage.substring(0,errorMessage.length()-1); &#125; errorWebResult.setInfo(errorMessage); return errorWebResult; &#125; errorWebResult.setInfo(ex.getMessage()); return errorWebResult; &#125; @ExceptionHandler(MethodArgumentNotValidException.class) @ResponseBody public WebResult resolveMethodArgumentNotValidException(MethodArgumentNotValidException ex)&#123; WebResult errorWebResult = new WebResult(WebResult.FAILED); List&lt;ObjectError&gt; objectErrors = ex.getBindingResult().getAllErrors(); if(!CollectionUtils.isEmpty(objectErrors)) &#123; StringBuilder msgBuilder = new StringBuilder(); for (ObjectError objectError : objectErrors) &#123; msgBuilder.append(objectError.getDefaultMessage()).append(&quot;,&quot;); &#125; String errorMessage = msgBuilder.toString(); if (errorMessage.length() &gt; 1) &#123; errorMessage = errorMessage.substring(0, errorMessage.length() - 1); &#125; errorWebResult.setInfo(errorMessage); return errorWebResult; &#125; errorWebResult.setInfo(ex.getMessage()); return errorWebResult; &#125;&#125; 7.参数校验注解 Java中参数校验的注解来自三个方面，分别是 javax.validation:validation-api，对应包javax.validation.constraints org.hibernate:hibernate-validator，对应包org.hibernate.validator.constraints org.springframework:spring-context，对应包org.springframework.validation JSR 303 是Bean验证的规范 ，Hibernate Validator 是该规范的参考实现，它除了实现规范要求的注解外，还额外实现了一些注解。 7.1 validation-api中的注解： 配置项 说明 适用类型 @AssertFalse 限制必须是false boolean Boolean：not null时才校验 @AssertTrue 限制必须是true boolean Boolean：not null时才校验 @Max(value) 限制必须为一个小于等于value指定值的整数，value是long型 byte/short/int/long/float/double及其对应的包装类；包装类对象not null时才校验 @Min(value) 限制必须为一个大于等于value指定值的整数，value是long型 byte/short/int/long/float/double及其对应的包装类；包装类对象not null时才校验 @DecimalMax(value) 限制必须小于等于value指定的值，value是long型 byte/short/int/long/float/double及其对应的包装类；包装类对象not null时才校验 @DecimalMin(value) 限制必须大于等于value指定的值，value是字符串类型 byte/short/int/long/float/double及其对应的包装类；包装类对象not null时才校验 @Digits(integer, fraction) 限制必须为一个小数（其实整数也可以），且整数部分的位数不能超过integer，小数部分的位数不能超过fraction。integer和fraction可以是0。 byte/short/int/long/float/double及其对应的包装类；包装类对象not null时才校验 @Null 限制只能为null 任意对象类型（比如基本数据类型对应的包装类、String、枚举类、自定义类等）；不能是8种基本数据类型 @NotNull 限制必须不为null 任意类型（包括8种基本数据类型及其包装类、String、枚举类、自定义类等）；但是对于基本数据类型，没有意义 @Size(min, max) 限制Collection类型或String的长度必须在min到max之间，包含min和max 1.Collection类型（List/Set） 2.String @Pattern(regexp) 限制必须符合regexp指定的正则表达式 String @Future 限制必须是一个将来的日期 Date/Calendar @Past 限制必须是一个过去的日期 Date/Calendar @Valid 校验任何非原子类型，标记一个对象，表示校验对象中被注解标记的对象（不支持分组功能） 需要校验成员变量的对象，比如@ModelAttribute标记的接口入参 7.2 hibernate-validator中的注解： 下面列举的注解是hibernate-validator-5.3.6版本的。 配置项 说明 适用类型 @Length(min,max) 限制String类型长度必须在min和max之间，包含min和max String, not null时才校验 @NotBlank 验证注解的元素值不是空白（即不是null，且包含非空白字符） String @NotEmpty 验证注解的元素值不为null且不为空（即字符串非null且长度不为0、集合类型大小不为0） 1.Collection类型（List/Set） 2.String @Range(min,max) 验证注解的元素值在最小值和最大值之间 1. String(数字类型的字符串)，非null时才校验 2. byte/short/int/long/float/double及其包装类，包装类非null时才校验 @Email(regexp) 验证注解的字符串符合邮箱的正则表达式，可以使用regexp自定义正则表达式 String @CreditCardNumber 验证银行借记卡、信用卡的卡号 String（不能包含空格等特殊字符） 7.3 spring-context中的注解： 配置项 说明 适用类型 @Validated 校验非原子类型对象，或启用类中原子类型参数的校验（支持分组校验；只校验包含指定分组的注解参数） 1. Controller类 2. @ModelAttribue标记的查询条件对象类 3. @RequestBody标记的请求体对象类 7.4 注解的启用 方法中对象参数中成员变量校验注解的生效条件 @ModelAttribute标记的查询条件类参数，需要同时用@Valid或@Validated标记，类中的注解校验才会生效 @RequestBody标记的请求体对象参数，需要同时用@Valid或@Validated标记，类中的注解校验才会生效 @Valid或@Validated标记在方法或方法所属类上无效 方法中原子类型参数校验注解的生效条件 @Validated标记在方法所属类上 按照分组启用 在注解中使用groups添加启用注解的分组 在@Validated中指定启用的分组 博客参考地址：https://mp.weixin.qq.com/s/0VX6lLS133CA4NFCVOHhhw","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://xiaoyuge5201.github.io/tags/springboot/"}]},{"title":"CentOS安装Maven 3.8.6","slug":"maven-install","date":"2022-06-04T01:10:10.000Z","updated":"2022-11-19T09:14:16.087Z","comments":false,"path":"maven-install/","link":"","permalink":"https://xiaoyuge5201.github.io/maven-install/","excerpt":"","text":"1. 下载 maven官网地址：https://maven.apache.org/download.cgi ， 右键复制链接地址，wget下载，或者下载到本地再上传到Centos 可以从镜像仓库下载：https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.8.6/binaries/ ， 12cd /usr/local/toolswget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.8.6/binaries/apache-maven-3.8.6-bin.tar.gz 2. 解压 1tar -zxvf apache-maven-3.8.6-bin.tar.gz 3. 配置环境变量 1vim /etc/profile 在末尾增加两行 12export MAVEN_HOME=/usr/local/tools/apache-maven-3.8.6export PATH=$PATH:$MAVEN_HOME/bin 编译生效 1source /etc/profile 4. 验证是否配置成功 1mvn -v 如果出现版本信息则配置成功 5. 配置本地仓库和镜像仓库 12cd /usr/local/tools/apache-maven-3.8.6/confvim setting.xml 在相应注释位置添加如下两行： 1&lt;localRepository&gt;/home/mavenRepository/&lt;/localRepository&gt; 123456&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;&lt;/mirror&gt;","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://xiaoyuge5201.github.io/tags/maven/"}]},{"title":"Linux安装gitlab","slug":"gitlab","date":"2022-05-28T01:56:42.000Z","updated":"2022-05-30T01:26:49.312Z","comments":true,"path":"gitlab/","link":"","permalink":"https://xiaoyuge5201.github.io/gitlab/","excerpt":"","text":"1. 前言 以前在自己服务器使用的是Gitblit,官网地址：http://gitblit.github.io/gitblit, 这个只需要在服务器上启动一个tomcat,然后将下载的Gitblit的war包放置在tomcat容器里面运行即可访问。 但是由于gitblit没有CI/CD的功能，于是自己就在网上找了一些博客搭建gitblit，在这里记录一下搭建的过程。 2. 安装步骤 配置yum源 1vim /etc/yum.repos.d/gitlab-ce.repo 增加一下配置 12345[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1 更新本地yum缓存 1yum makecache 安装GitLab社区版 123yum install gitlab-ce #自动安装最新版本 sudo yum install gitlab-ce-x.x.x #安装指定版本 更改默认端口配置(默认为80端口) 1sudo vim /etc/gitlab/gitlab.rb 修改如下配置： 123external_url &#x27;http://ip:8888&#x27; #填写自己的主机ippuma[&#x27;port&#x27;] = 8888 #如果gitlab是13版本之前请求修改 union[&#x27;port&#x27;]=8888nginx[&#x27;listen_port&#x27;] = 8888 配置gitlab-http.conf 1sudo vim /var/opt/gitlab/nginx/conf/gitlab-http.conf 修改如下： 1234server &#123; listen *:8888; #和上面保持一致 server_name ip #填写自己的ip&#125; 放开端口 12345#开放8888端口sudo firewall-cmd --add-port=8888/tcp --permanent#重新加载防火墙sudo firewall-cmd --reload 修改配置后重新加载配置文件 1sudo gitlab-ctl reconfigure 重新gitlab 1sudo gitlab-ctl restart 修改管理员登录密码 进入gitlab-rails控制台 1sudo gitlab-rails console 查找root账号(默认只有一个root用户) 1u=User.where(id:1).first 修改密码1u.password=&#x27;xiaoyuge123&#x27; 再次确认密码1u.password_confirmation=&#x27;xiaoyuge123&#x27; 保存 1u.save! 浏览器访问：http://ip:8888 至此，Gitlab搭建完毕！ 3. GitLab常用命令 123456789sudo gitlab-ctl start # 启动所有 gitlab 组件；sudo gitlab-ctl stop # 停止所有 gitlab 组件；sudo gitlab-ctl restart # 重启所有 gitlab 组件；sudo gitlab-ctl status # 查看服务状态；sudo gitlab-ctl reconfigure # 启动服务；sudo vim /etc/gitlab/gitlab.rb # 修改默认的配置文件；gitlab-rake gitlab:check SANITIZE=true --trace # 检查gitlab；sudo gitlab-ctl tail # 查看日志；gitlab-ctl show-config #查看gitlab配置信息 4. 邮件配置 修改配置 1sudo vim /etc/gitlab/gitlab.rb 新增以下内容 1234567891011gitlab_rails[&#x27;smtp_enable&#x27;] = truegitlab_rails[&#x27;smtp_address&#x27;] = &quot;mail.midea.com&quot;gitlab_rails[&#x27;smtp_port&#x27;] = 994gitlab_rails[&#x27;smtp_user_name&#x27;] = &quot;发信邮箱&quot;gitlab_rails[&#x27;smtp_password&#x27;] = &quot;发信邮箱密码&quot;gitlab_rails[&#x27;smtp_domain&#x27;] = &quot;xxx.com&quot;gitlab_rails[&#x27;smtp_authentication&#x27;] = &quot;login&quot;gitlab_rails[&#x27;smtp_enable_starttls_auto&#x27;] = truegitlab_rails[&#x27;smtp_tls&#x27;] = trueuser[&#x27;git_user_email&#x27;] = &quot;发信邮箱&quot;gitlab_rails[&#x27;gitlab_email_from&#x27;] = &#x27;发信邮箱&#x27; 测试邮件配置是否生效 12345#重新加载配置文件sudo gitlab-ctl reconfigure #查看consolesudo gitlab-rails console 1234567891011121314151617181920212223242526--------------------------------------------------------------------------------Ruby: ruby 2.7.2p137 (2020-10-01 revision 5445e04352) [x86_64-linux]GitLab: 13.7.1 (c97c8073a0e) FOSSGitLab Shell: 13.14.0PostgreSQL: 12.4--------------------------------------------------------------------------------Loading production environment (Rails 6.0.3.3)irb(main):001:0&gt; Notify.test_email(&#x27;xxxx@midea.com&#x27;,&#x27;test&#x27;,&#x27;test&#x27;).deliver_nowNotify#test_email: processed outbound mail in 1.4msDelivered mail 5ff2cb5082e2b_e45eb53d484754@devops.mail (673.8ms)Date: Mon, 04 Jan 2021 08:01:20 +0000From: GitLab &lt;xxx@midea.com&gt;Reply-To: GitLab &lt;noreply@ip&gt;To: xxxx@midea.comMessage-ID: &lt;5ff2cb5082e2b_e45eb53d484754@devops.mail&gt;Subject: testMime-Version: 1.0Content-Type: text/html;charset=UTF-8Content-Transfer-Encoding: 7bitAuto-Submitted: auto-generatedX-Auto-Response-Suppress: All&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/REC-html40/loose.dtd&quot;&gt;&lt;html&gt;&lt;body&gt;&lt;p&gt;test&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;=&gt; #&lt;Mail::Message:199260, Multipart: false, Headers: &lt;Date: Mon, 04 Jan 2021 08:01:20 +0000&gt;, &lt;From: GitLab &lt;xxx@midea.com&gt;&gt;, &lt;Reply-To: GitLab &lt;noreply@ip&gt;&gt;, &lt;To: xxxx@midea.com&gt;, &lt;Message-ID: &lt;5ff2cb5082e2b_e45eb53d484754@devops.mail&gt;&gt;, &lt;Subject: test&gt;, &lt;Mime-Version: 1.0&gt;, &lt;Content-Type: text/html; charset=UTF-8&gt;, &lt;Content-Transfer-Encoding: 7bit&gt;, &lt;Auto-Submitted: auto-generated&gt;, &lt;X-Auto-Response-Suppress: All&gt;&gt;出现以上信息说明配置成功。 5. 性能调优 1sudo vim /etc/gitlab/gitlab.rb 新增以下内容并保存退出： 1234567unicorn[&#x27;worker_processes&#x27;] = 2 #官方建议值为CPU核数+1（服务器只部署gitLab的情况下），可提高服务器响应速度，此参数最小值为2，设为1服务器可能卡死unicorn[&#x27;work_timeout&#x27;] = 60 #设置超时时间unicorn[&#x27;worker_memory_limit_min&#x27;] = &quot;200 * 1 &lt;&lt; 20&quot; #减少最小内存unicorn[&#x27;worker_memory_limit_max&#x27;] = &quot;300 * 1 &lt;&lt; 20&quot; #减少最大内存postgresql[&#x27;shared_buffers&#x27;] = &quot;128MB&quot; #减少数据库缓存postgresql[&#x27;max_worker_processes&#x27;] = 6 #减少数据库并发数sidekiq[&#x27;concurrency&#x27;] = 15 #减少sidekiq并发数 12345#每次修改了配置，都需要重新加载sudo gitlab-ctl reconfigure#重启sudo gitlab-ctl restart 6. GitLab使用 6.1 创建Project 安装Git工具 1yum install git 生成密钥文件：使用ssh-keygen生成密钥文件 .ssh/id_rsa.pub 1ssh-keygen 在Gitlab上创建一个project 添加ssh key导入步骤2中生成的密钥文件内容 ssh key添加完成： 6.2 配置git 配置Git仓库人员 1git config --global user.name &quot;xiaoyuge&quot; local（默认，高级优先）：只影响本地仓库 global(中优先级)：只影响所有当前用户的git仓库 system（低优先级）：影响到全系统的git仓库 配置Git仓库人员email 1git config --global user.email &quot;xiaoyuge0318@qq.com&quot; 克隆项目 1git clone git@fase11h12dsa24fdv3Q:root/test.git 6.3 git常用命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445#查看某个命令文档git help &lt;command&gt;git &lt;command&gt; -hgit &lt;command&gt; --help#初始化仓库git init #添加文件内容到暂存区（同时文件被跟踪）git add#添加所有文件git add .truegit rm --cached #仅从暂存区删除git rm #从暂存区与工作目录同时删除git rm $(git ls-files --deleted) #删除所有被跟踪，但是在工作目录被删除的文件git -commit -m &#x27;first commit&#x27; #从暂存区提交 -m：注释git commit -a -m &#x27;full commit&#x27; #从工作区提交git log #查看提交历史记录git log --onlinegit log --color --graphgit diff #工作区与暂存区的差异git diff --cached [&lt;reference&gt;] #暂存区与某次提交的差异，默认为HEADgit diff [&lt;reference&gt;] #工作区与某次提交的差异，默认为HEADgit checkout -- &lt;file&gt; #将文件内容从暂存区复制到工作目录#撤销暂存区内容git reset HEAD &lt;file&gt; #将文件内容从上次提交复制到缓存区git checkout HEAD -- &lt;file&gt; #将内容从上次提交复制到工作目录#对状态的跟踪:git中有两个状态：内容状态和文件状态，#内容状态标示内容文件的改变，有三个区域：工作目录，暂存区和提交区#文件状态有两个状态：已跟踪和未跟踪git status 分支操作： 12345678910111213git branch &lt;branchName&gt; #创建一个分支git branch -d &lt;branchName&gt; #删除一个分支git branch -v #显示所有分支信息git checkout &lt;branchName&gt; #通过移动HEAD检出版本，可用于切换分支git checkout -b &lt;branchName&gt; #创件一个分支并切换git checkout &lt;reference&gt; #将其移动到一个引用git checkout - #恢复到上一个分支git reset #将当前分支回退到历史某个版本git reset --mixed &lt;commit&gt; #(默认)git reset --soft&lt;commit&gt; git reset --hard &lt;commit&gt; 7. 常见问题 gitlab本身采用gitlab.example.com:80端口，如安装前服务器有启用80，安装完访问会报错。需更改gitlab的默认端口。 修改vim /etc/gitlab/gitlab.rb：external_url 'http://localhost:8888 如果就想用80端口，那没问题。如果更改了端口，后边可以自行调整nginx配置文件进行nginx反向代理设置。 日志位置：/var/log/gitlab 可以进去查看访问日志以及报错日志等，供访问查看以及异常排查。 gitlab内存消耗过大，频繁出现502： http://www.360doc.com/content/22/0130/08/65839659_1015422932.shtml gitlab-ctl tail #查看所有日志 gitlab-ctl tail nginx/gitlab_access.log #查看nginx访问日 参考博客：https://blog.csdn.net/yzd524850313/article/details/113118193 参考博客：https://zhuanlan.zhihu.com/p/338882906","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://xiaoyuge5201.github.io/tags/gitlab/"}]},{"title":"常见的接口测试工具","slug":"swagger","date":"2022-04-17T09:10:15.000Z","updated":"2022-05-23T05:14:16.803Z","comments":true,"path":"swagger/","link":"","permalink":"https://xiaoyuge5201.github.io/swagger/","excerpt":"","text":"1. Swagger Swagger 是一个规范且完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。 Swagger 的目标是对 REST API 定义一个标准且和语言无关的接口，可以让人和计算机拥有无须访问源码、文档或网络流量监测就可以发现和理解服务的能力。 静态的swagger跟不上频繁变更的代码，容易出现以下问题 “为什么改了这个没告诉我” “实际功能和文档上说的不一样啊” 这样会带来的问题是： Swagger，postman，MockJS只能完成软件研发流程中某个环节的功能，造成完成接口设计，文档编写，调试，测试验证等工作需要使用好几个工具； 更麻烦的是这些工具数据格式不互通，无法互相导入，造成用Swagger定义和编写完成接口后，在Postman，MockJS，Jmeter等工具还要再去手动填写一遍才能开始工作，增加了无意义的工作量。 沟通成本总是被忽略不计，但实际上不仅占据了很大时间，各种沟通不及时、沟通不到位还非常让人心累。 老板的需求来得急，老板的需求变得快，各种代码修改和变更难以及时通知和同步到团队成员手中。 2. 常见的可视化RestFul风格的服务 springfox-swagger2 springdoc Apifox（接口测试工具，非集成在项目中postman加强升级版） 3. 各个工具的使用以及风格 使用Springboot项目分别集成各个组件，看下具体的实现效果； 3.1 springfox-swagger2 引入依赖 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.10.5&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.8&lt;/version&gt;&lt;/dependency&gt; 编写配置类 SwaggerConfiguration类 12345678910111213141516171819202122232425262728293031@Configuration@EnableSwagger2WebMvc@EnableKnife4jpublic class SwaggerConfiguration &#123; @Value(&quot;$&#123;spring.application.name&#125;&quot;) private String applicationName; @Bean(value = &quot;defaultApi&quot;) public Docket defaultApi2() &#123; //设置处理请求的包，我的controller类都在com.yugb.controller中 Predicate&lt;RequestHandler&gt; apiPackage = RequestHandlerSelectors.basePackage(&quot;com.yugb.controller&quot;); Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(new ApiInfoBuilder() .version(&quot;1.0&quot;) .contact(new Contact(&quot;xiaoyuge&quot;,&quot;123&quot;, &quot;12342qq.com&quot;)) .title(applicationName + &quot; 文档中心&quot;) .description(&quot;&lt;div style=&#x27;font-size:15px;&#x27;&gt;&quot; + applicationName + &quot; RESTful APIs&lt;/div&gt;&quot;) .build()) //分组名称 .groupName(&quot;2.X版本&quot;) .select() //这里指定Controller扫描包路径 .apis(apiPackage) .paths(PathSelectors.any()) .build(); return docket; &#125;&#125; SwaggerWebMvcConfigurer 类 12345678@Configurationpublic class SwaggerWebMvcConfigurer implements WebMvcConfigurer &#123; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;doc.html&quot;).addResourceLocations(&quot;classpath:/META-INF/resources/&quot;); registry.addResourceHandler(&quot;/webjars/**&quot;).addResourceLocations(&quot;classpath:/META-INF/resources/webjars/&quot;); &#125;&#125; 添加注解 我们接口文档的直接描述主要就是在Controller这一层，比如这个接口的功能，参数的名称，返回值的名称等。这些值我们都需要在Controller上通过给方法上，请求参数和返回参数上添加对应的注解，swagger才能帮我们生成相应的接口文档。 JavaBean: @ApiModel注解和 @@ApiModelProperty 注解定义了实体的名称和字段的名称 12345678910111213141516@Data@ApiModel(&quot;创建Swagger响应结果&quot;)public class SwaggerResVO &#123; @ApiModelProperty(&quot;id&quot;) private Integer id; @ApiModelProperty(&quot;姓名&quot;) private String name; @ApiModelProperty(&quot;性别&quot;) private Integer gender; @ApiModelProperty(&quot;啥啥&quot;) private String what;&#125; controller: @Api注解和 @ApiOperation注解分别标注了接口组名和接口的名称 1234567891011121314151617@RestController@RequestMapping(&quot;/swagger&quot;)@Api(value = &quot;用户接口&quot;, tags = &#123;&quot;用户接口&quot;&#125;)public class SwaggerController &#123; @ApiOperation(&quot;新增用户&quot;) @PostMapping(&quot;save&quot;) public String save(@RequestBody SwaggerReqVO req) &#123; return &quot;success&quot;; &#125; @GetMapping(&quot;getById&quot;) @ApiOperation(&quot;根据条件查询用户&quot;) public SwaggerResVO getById(@RequestBody SwaggerResVO req) &#123; return new SwaggerResVO(); &#125;&#125; 启动项目 访问 http://localhost:8080/doc.html 查看springfox-swagger2的文档中心 查看GET请求的界面 优缺点 优点：界面美观，集成方便，不同类型的接口按照controller分组，可以导出所有的接口文档！！！！！ 缺点：暂时没有遇到 3.2 springdoc 引入依赖 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt; &lt;version&gt;1.5.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-webmvc-core&lt;/artifactId&gt; &lt;version&gt;1.5.8&lt;/version&gt; &lt;/dependency&gt; 配置yml /yaml /properties 1234567891011121314springdoc: api-docs: enabled: true groups: enabled: true path: /api-docs cache: disabled: true swagger-ui: groups-order: asc # 自定义的文档界面访问路径。默认访问路径是/swagger-ui.html path: /springdoc/docs.html # 布尔值。实现OpenApi规范的打印。 writer-with-default-pretty-printer: true 编写配置类 SpringdocOpenapiConfiguration 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788@Configurationpublic class SpringdocOpenapiConfiguration implements WebMvcConfigurer &#123; private final SwaggerProperties swaggerProperties; public SpringdocOpenapiConfiguration(SwaggerProperties swaggerProperties) &#123; this.swaggerProperties = swaggerProperties; &#125; @Bean public OpenAPI springDocOpenAPI() &#123; //配置认证、请求头参数 Components components = new Components();// Map&lt;String, Object&gt; myHeader2extensions = new HashMap&lt;&gt;(2);// myHeader2extensions.put(&quot;name&quot;, &quot;myHeader2&quot;);// components// .addSecuritySchemes(&quot;bearer-key&quot;, new SecurityScheme().type(SecurityScheme.Type.HTTP).scheme(&quot;bearer&quot;).bearerFormat(&quot;JWT&quot;))// .addSecuritySchemes(&quot;basicScheme&quot;, new SecurityScheme().type(SecurityScheme.Type.HTTP).scheme(&quot;basic&quot;))// .addHeaders(&quot;myHeader2&quot;, new Header().description(&quot;myHeader2 header&quot;).schema(new StringSchema()).extensions(myHeader2extensions))// .addParameters(&quot;myGlobalHeader&quot;, new HeaderParameter().required(true).name(&quot;My-Global-Header&quot;).description(&quot;My Global Header&quot;).schema(new StringSchema()).required(false))// ; // 接口调试路径 Server tryServer = new Server(); tryServer.setUrl(swaggerProperties.getTryHost()); return new OpenAPI() .components(components) .servers(Collections.singletonList(tryServer)) .info(new Info() .title(swaggerProperties.getApplicationName() + &quot; Api Doc&quot;) .description(swaggerProperties.getApplicationDescription()) .version(&quot;Application Version: &quot; + swaggerProperties.getApplicationVersion() + &quot;\\n Spring Boot Version: &quot; + SpringBootVersion.getVersion()) .license(new License().name(&quot;Apache 2.0&quot;).url(&quot;https://www.apache.org/licenses/LICENSE-2.0.html&quot;)) ) .externalDocs(new ExternalDocumentation() .description(&quot;SpringDoc Full Documentation&quot;) .url(&quot;https://springdoc.org/&quot;) ); &#125; /** * 添加全局的请求头参数 */// @Bean// public OpenApiCustomiser customerGlobalHeaderOpenApiCustomiser() &#123;// return openApi -&gt; openApi.getPaths().values().stream().flatMap(pathItem -&gt; pathItem.readOperations().stream())// .forEach(operation -&gt; &#123;// operation.addParametersItem(new HeaderParameter().$ref(&quot;#/components/parameters/myGlobalHeader&quot;));// &#125;);// &#125; /** * 通用拦截器排除设置，所有拦截器都会自动加springdoc-opapi相关的资源排除信息，不用在应用程序自身拦截器定义的地方去添加，算是良心解耦实现。 */ @SuppressWarnings(&quot;unchecked&quot;) @Override public void addInterceptors(InterceptorRegistry registry) &#123; try &#123; Field registrationsField = FieldUtils.getField(InterceptorRegistry.class, &quot;registrations&quot;, true); List&lt;InterceptorRegistration&gt; registrations = (List&lt;InterceptorRegistration&gt;) ReflectionUtils.getField(registrationsField, registry); if (registrations != null) &#123; for (InterceptorRegistration interceptorRegistration : registrations) &#123; interceptorRegistration.excludePathPatterns(&quot;/springdoc**/**&quot;); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; // 服务器支持跨域 @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/**&quot;) .allowedOrigins(&quot;*&quot;) .allowedMethods(&quot;GET&quot;, &quot;POST&quot;, &quot;OPTIONS&quot;) .allowedHeaders(&quot;*&quot;) .exposedHeaders(&quot;Access-Control-Allow-Headers&quot;, &quot;Access-Control-Allow-Methods&quot;, &quot;Access-Control-Allow-Origin&quot;, &quot;Access-Control-Max-Age&quot;, &quot;X-Frame-Options&quot;) .allowCredentials(false) .maxAge(3600); &#125;&#125; SwaggerProperties 12345678910111213141516171819202122@Getter@Setter@Component@ConfigurationProperties(&quot;swagger&quot;)public class SwaggerProperties &#123;/*** 项目应用名*/private String applicationName; /** * 项目版本信息 */ private String applicationVersion; /** * 项目描述信息 */ private String applicationDescription; /** * 接口调试地址 */ private String tryHost;&#125; 编写接口方法 在controller上添加@Tag注解 在接口方法上添加@Operation 注解 在接口参数添加@Parameter 或@Parameters 注解 12345678910111213141516171819202122@Tags(&#123; @Tag(name = &quot;ExpirationWarningController&quot;, description = &quot;设备寿命到期预警&quot;),&#125;)@RestController@RequestMapping(&quot;/test&quot;)public class ExpirationWarningController &#123; //需要使用@Operation竹节 @PostMapping(&quot;/getOne/&#123;id&#125;/&#123;type&#125;&quot;) @Operation(summary = &quot;按ID查询&quot;, description = &quot;按ID查询&quot;) public ResponseResult getOne(@Parameter(description = &quot;主键ID&quot;) @PathVariable Integer id, @Parameter(description = &quot;类型&quot;) @PathVariable String type) &#123; return ResponseResult.success(expirationWarningVO); &#125; @PostMapping(&quot;/save&quot;) @ResponseBody @Operation(summary = &quot;保存&quot;, description = &quot;保存&quot;) public ResponseResult save(@RequestBody ExpirationWarning expirationWarning) &#123; return null; &#125; &#125; 在springboot启动类上加上以下配置 12345678910111213141516171819202122232425@OpenAPIDefinition( info = @Info( title = &quot;测试springdoc&quot;, version = &quot;1.0&quot; ), externalDocs = @ExternalDocumentation(description = &quot;swagger-api参考文档&quot;, url = &quot;https://github.com/swagger-api/swagger-core/wiki/Swagger-2.X---Annotations&quot; ), servers = &#123; @Server( url = &quot;http://localhost:8123/app&quot;, description = &quot;本地地址&quot; ), @Server( url = &quot;http://www.xiaoyuge.vip/app&quot;, description = &quot;公网测试环境&quot; ) &#125;)public class ResolutionApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ResolutionApplication.class, args); logger.info(&quot;============= Start Success =============&quot;); &#125;&#125; 启动项目 访问 http://localhost:8123/app/springdoc/swagger-ui/index.html 查看springdox的文档中心 优缺点 优点：不好说 缺点：界面没有按照每个controller分组，不直观！； 3.3 Apifox 一款研发全流程，接口全周期的生产力工具，这款软件真正完成了数据流的打通，在一个软件上就能实现接口设计–接口文档–接口调试–接口修改–接口mock–接口测试–接口自动化–接口迭代的工作流闭环； 3.3.1 Apifox上的协作流程 后端在Apifox可视化接口设计界面上定义好项目各个接口及对应参数同时编写接口文档说明 前后端一起评审，修改完善接口并在同一界面顺手更新接口文档 后端使用接口调试功能调试接口 前端使用零配置高仿真mock功能对前端页面进行调试，无需手写mock规则 后端使用代码生成功能直接生成接口代码 测试在接口管理页面一键生成接口参数测试用例,并依据业务场景生成自动化测试用例，一键运行接口用例并生成接口测试报告并分享给相关人员。 前后端 都开发完，前端从Mock 数据切换到正式数据，进行联调，由于使用同一个接口数据源，且遵循了接口规范，联调顺利 由于bug修复或需求变更，接口发生了变化，后端修改提交后，前端和测试实时同步到了修改后的数据 项目经理通过权限设置给研发,产品,测试,外部合作人员分配编辑,只读等各种操作权限，维护了项目安全 项目经理通过各个接口的状态开发中,测试中,已发布来跟进项目的进度情况，把控项目风险。 3.3.2 Apifox做的增速提效优化 接口设计：从代码生成界面到可视化接口设计界面 Apifox 接口文档遵循 OpenApi 3.0 (原 Swagger)、JSON Schema 规范，可生成在线文档；零学习成本即可编写出符合RESTful风格的接口文档，新人上手快；所见即所得，不易出错 文档维护：从接口与文档分离到接口与文档合并 Apifox的接口设计界面提供了Markdown格式的文档说明区，修改完接口就如同commit代码时添加变更说明般 数据复用：从各自为政到定义一次、多次复用 接口数据复用：Swagger，Postman，MockJS，Jmeter等软件彼此之间数据不互通，数据格式不一致，接口导入非常耗时麻烦。 而Apifox能身兼多职，包揽上述软件功能，在Apifox中定义一次接口，能被后端直接用来调试，前端直接用来mock界面，测试直接执行接口自动化。 数据模型复用：可复用的数据结构，定义接口返回数据结构及请求参数数据结构（仅 JSON 和 XML 模式）时可直接引用。 同步更新，高效沟通:从沟通滞后到数据变更即时同步 Apifox为此提供了同步功能，一旦接口数据有更新发生，就会即时同步更新并通知到项目内所有成员。 Apihub 内置企业微信开放API，抖音开放API等第三方接口开放项目，接口可以直接在Apifox中调试，不需要到处找接口文档和手工填写接口 3.3.3 下载地址 官网地址： http://www.apifox.cn/?utm_medium=WCSA&amp;utm_source=xxzsq","categories":[{"name":"swagger","slug":"swagger","permalink":"https://xiaoyuge5201.github.io/categories/swagger/"}],"tags":[{"name":"swagger","slug":"swagger","permalink":"https://xiaoyuge5201.github.io/tags/swagger/"}]},{"title":"基于Springboot导出数据库表结构文档","slug":"export-database-file","date":"2022-04-15T03:46:03.000Z","updated":"2022-04-17T10:55:29.500Z","comments":true,"path":"export-database-file/","link":"","permalink":"https://xiaoyuge5201.github.io/export-database-file/","excerpt":"","text":"在项目中经常会需要查询数据库所有的表以及表字段，然后可能还需要导出到Excel中，然后自己写了一个工具类，目前支持sqlserver、mysql、oracle、Postgre；如果有问题请留言！！！ 1. 引入依赖包 123456 &lt;!-- 请尽量用最新版本 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoyuge5201&lt;/groupId&gt; &lt;artifactId&gt;datasource-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt;&lt;/dependency&gt; 2. 编写Java代码 通过MyDataSourceProperties类所有本项目的数据库连接信息，导出当前连接库的数据库结构 数据库配置 yml 12345678spring: datasource: type: com.alibaba.druid.pool.DruidDataSource url: jdbc:mysql://localhost:3306/dbname?serverTimezone=GMT%2B8&amp;useSSL=false username: root password: xiaoyuge driver-class-name: com.mysql.jdbc.Driver database: dbname ##需要配置数据库名称 导出方法 123456789101112131415161718192021222324import com.github.xiaoyuge5201.config.MyDataSourceProperties;import com.github.xiaoyuge5201.util.ExportDatabaseDocument;import org.apache.catalina.servlet4preview.http.HttpServletRequest;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletResponse;@Controller@RequestMapping(&quot;/export&quot;)public class TestController &#123; @Autowired MyDataSourceProperties properties; /** * 注意：需要在yaml /yml 配置文件中配置spring.datasource.database 属性 */ @GetMapping(&quot;/index&quot;) public void index(HttpServletResponse response, HttpServletRequest request) &#123; ExportDatabaseDocument.export(response, request, properties); &#125;&#125; 自定义导出某个数据库的表结构信息 12345@GetMapping(&quot;/index&quot;)public void index(HttpServletResponse response, HttpServletRequest request) &#123; //手动传参 ExportDatabaseDocument.export(response, request, DatabaseDriverEnum.MYSQL.getDriver(), &quot;127.0.0.1:3306&quot;, &quot;root&quot;, &quot;xiaoyuge&quot;, &quot;dbname&quot;);&#125; 3. 导出文档 执行请求：localhost:8080/export/index 即可；导出的内容如下： 包括数据库表名、描述以及各个字段的类型、长度、默认值、描述等。。。； 另外sheet的名称为表名(表中文名)+ 4位随机值，受限于excel的sheet； 4. 数据库操作类 DataSourceClient DataSourceClient类中根据MyDataSourceProperties操作数据库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/*** 查询所有的表结构信息** @return 表结构列表*/public List&lt;String&gt; findAllTables() &#123; return QuerySqlUtil.findAllTables(properties.getDriverClassName(), properties.getUrl(), properties.getUsername(), properties.getPassword(), properties.getDatabase());&#125;/** * 查詢數據庫表的字段信息 * * @param table 数据表 * @return 表字段列表 */public List&lt;ColumnEntity&gt; queryTableFieldsEntity(String table) &#123; return QuerySqlUtil.queryTableFieldsToColumnEntity(properties.getDriverClassName(), properties.getUrl(), properties.getUsername(), properties.getPassword(), properties.getDatabase(), table);&#125;/** * 查詢數據庫表的字段信息 * * @param table 数据表 * @return 表字段列表 */public List&lt;String&gt; queryTableFields(String table) &#123; return QuerySqlUtil.queryTableFields(properties.getDriverClassName(), properties.getUrl(), properties.getUsername(), properties.getPassword(), properties.getDatabase(), table);&#125;/** * 查询对应库下所有字段 信息 * * @return 结果 */public List&lt;ColumnEntity&gt; listColumnsByDatasourceParams() &#123; return QuerySqlUtil.listColumnsByDatasourceParams(properties.getDriverClassName(), properties.getUrl(), properties.getUsername(), properties.getPassword(), properties.getDatabase());&#125;/** * 分页查询数据表数据 * * @param table 数据表 * @param pageNo 页码 * @param limit 页容量 * @param columns 字段列表 * @throws Exception 异常信息 * @return 结果 */public JSONArray queryPageData(String table, List&lt;String&gt; columns, Integer pageNo, Integer limit) throws Exception &#123; return QuerySqlUtil.queryPageData(properties.getDriverClassName(), properties.getDatabase(), table, properties.getUrl(), properties.getUsername(), properties.getPassword(), columns, pageNo, limit);&#125;/** * 导出数据库设计文档 * * @param response 返回对象 * @param request 请求对象 */public void exportDatabaseDocument(HttpServletResponse response, HttpServletRequest request) &#123; ExportDatabaseDocument.export(response, request, properties.getDriverClassName(), properties.getUrl(), properties.getUsername(), properties.getPassword(), properties.getDatabase());&#125; 5. 数据库驱动枚举类 DatabaseDriverEnum 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 数驱动的常量 * * @author yugb */public enum DatabaseDriverEnum &#123; /** * mysql数据库 */ MYSQL(1, &quot;com.mysql.jdbc.Driver&quot;, &quot;mysql数据库&quot;), /** * Sql Server数据库 */ SQL_SERVER(2, &quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;, &quot;Sql Server数据库&quot;), /** * oracle数据库 */ ORACLE(3, &quot;oracle.jdbc.driver.OracleDriver&quot;, &quot;oracle数据库&quot;), /** * postgre sql数据库 */ POSTGRE_SQL(4, &quot;org.postgresql.Driver&quot;, &quot;postgre sql数据库&quot;), /** * 达梦数据库 */ DM(5, &quot;dm.jdbc.driver.DmDriver&quot;, &quot;达梦数据库&quot;); /** * 数据库驱动类型 */ private final Integer type; /** * 数据库驱动连接 */ private final String driver; /** * 名称 */ private final String name; public Integer getType() &#123; return type; &#125; public String getDriver() &#123; return driver; &#125; public String getName() &#123; return name; &#125; DatabaseDriverEnum(Integer type, String driver, String name) &#123; this.type = type; this.driver = driver; this.name = name; &#125; /** * 根据数据库类型获取数据库驱动 * @param type 数据库类型 * @return 驱动 */ public static String getValue(Integer type) &#123; DatabaseDriverEnum[] enums = values(); for (DatabaseDriverEnum driverEnum : enums) &#123; if (driverEnum.type.equals(type)) &#123; return driverEnum.getDriver(); &#125; &#125; return null; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]},{"title":"java8的lambda表达式语法","slug":"lambda","date":"2022-04-13T12:32:44.000Z","updated":"2022-04-24T02:43:30.253Z","comments":true,"path":"lambda/","link":"","permalink":"https://xiaoyuge5201.github.io/lambda/","excerpt":"","text":"记录一下用到的一些java8的lambda表达式语法 1 list集合根据某个字段分组后求多个字段的和 12345678910111213 List&lt;SafeSystemVO&gt; list = new ArrayList&lt;&gt;(16);//....省略添加元素的代码//分组字段 driver_idlist.stream().collect(Collectors.groupingBy(SafeSystemVO::getDriver_id)).values().stream().map(d -&gt; &#123; SafeSystemVO vo = d.get(0); //求和1 vo.setAg_total(d.stream().map(s -&gt; BigDecimal.valueOf(s.getAg_total())).reduce(BigDecimal.ZERO, BigDecimal::add).doubleValue()); // 求和2 vo.setScore(d.stream().map(s -&gt; BigDecimal.valueOf(s.getScore())).reduce(BigDecimal.ZERO, BigDecimal::add).doubleValue()); vo.setLkj_score(d.stream().map(s -&gt; BigDecimal.valueOf(s.getLkj_score())).reduce(BigDecimal.ZERO, BigDecimal::add).doubleValue()); vo.setTotalScore(d.stream().map(s -&gt; BigDecimal.valueOf(s.getTotalScore())).reduce(BigDecimal.ZERO, BigDecimal::add).doubleValue()); return vo;&#125;).collect(Collectors.toList()); 2. list 根据某个字段分组后求单个字段的平均值，并按照分组字段排序 1234567891011121314151617181920212223242526List&lt;SafeSystemVO&gt; list = new ArrayList&lt;&gt;(16);//....省略添加元素的代码Map&lt;String, Double&gt; monthAvg = list1.stream().collect(Collectors.groupingBy(SafeSystemVO::getMonth, Collectors.averagingDouble(SafeSystemVO::getTotalScore)));// 根据Map 对象的key排序// 我的分组字段是日期，就用了下面的monthAvg.entrySet().stream().sorted((o1, o2) -&gt; &#123; try &#123; Date d1 = DateUtils.convertStringToDate(o1.getKey(), DateUtils.FM2); Date d2 = DateUtils.convertStringToDate(o2.getKey(), DateUtils.FM2); assert d1 != null; return d1.compareTo(d2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return 0;&#125;).collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, (oldVal, newVal) -&gt; oldVal, LinkedHashMap::new));//根据Map 对象的value排序//monthResult = workShopAvg.entrySet().stream().sorted((p1, p2) -&gt; p2.getValue().compareTo(p1.getValue())).collect(Collectors.toList());//方法一：//list1.sort((o1, o2) -&gt; o1.getAge().compareTo(o2.getTotalScore())); //正序//list1.sort((o1, o2) -&gt; o2.getAge().compareTo(o1.getTotalScore())); //倒序//方法二//list1.sort(Comparator.comparing(Person::getTotalScore)); // 正序//list1.sort(Comparator.comparing(Person::getTotalScore).reversed()); // 倒序 3. list 根据字段分组求和后取 前/后10名 12345678//list对象接上面的//根据driver_id分组，求平均值Map&lt;String, Double&gt; driverScores = list3.stream() .collect(Collectors.groupingBy(SafeSystemVO::getDriver_id, Collectors.averagingDouble(SafeSystemVO::getTotalScore)));//排序后获取后10 名， 前10名的话修改sorted逻辑为：sorted((p1, p2) -&gt; p2.getValue().compareTo(p1.getValue()))List&lt;Map.Entry&lt;String, Double&gt;&gt; driverScoresTop10 = driverScores.entrySet().stream().sorted((p1, p2) -&gt; p1.getValue().compareTo(p2.getValue())).limit(10).collect(Collectors.toList()); 4. 其他 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public static void main(String[] args) &#123; //Id, name , age Person p1 = new Person(1,&quot;麻子&quot;, 31); Person p2 = new Person(2,&quot;李四&quot;, 20); Person p3 = new Person(3,&quot;王五&quot;, 26); Person p4 = new Person(3,&quot;王五&quot;, 26); List&lt;Person&gt; personList = new ArrayList&lt;Person&gt;(); personList.add(p1); personList.add(p2); personList.add(p3); personList.add(p4); //java8遍历 personList.forEach(p -&gt; System.out.println(p.getAge())); //按照person的 age进行排序 //方法一 personList.sort((o1, o2) -&gt; o1.getAge().compareTo(o2.getAge())); //正序 personList.sort((o1, o2) -&gt; o2.getAge().compareTo(o1.getAge())); //倒序 //方法二 personList.sort(Comparator.comparing(Person::getAge)); // 正序 personList.sort(Comparator.comparing(Person::getAge).reversed()); // 倒序 //多个字段排序 personList.sort(Comparator.comparing(User::getId).thenComparing(Person::getAge)); //注：若选择排序字段为null值，正序可personList.sort(Comparator.comparing(Person::getAge,Comparator.nullsFirst(Comparator.naturalOrder()))) System.out.println(&quot;========================================&quot;); //获取年龄最大的Person Person maxAgePerson = personList.stream().max(Comparator.comparing(Person::getAge)).get(); System.out.println(maxAgePerson.getAge()); System.out.println(&quot;========================================&quot;); //获取年龄最小的Person Person minAgePerson = personList.stream().min(Comparator.comparing(Person::getAge)).get(); System.out.println(minAgePerson.getAge()); //过滤出年龄是20的person，想过滤出什么条件的均可以 List&lt;Person&gt; personList1 = personList.stream().filter(person -&gt; person.getAge() == 20).collect(Collectors.toList()); //过滤-- 统计出年龄等于20的个数 long count = personList.stream().filter(person -&gt; person.getAge() == 20).count(); //过滤出年龄大约20的人 List&lt;Person&gt; personList2 = personList.stream().filter(t -&gt; t.getAge().equals(20)).collect(Collectors.toList()); //得到年龄的平均值 double asDouble = personList.stream().mapToInt(person -&gt; person.getAge()).average().getAsDouble(); //得到年龄的求和--基本类型 int sum = personList.stream().mapToInt(person -&gt; person.getAge()).sum(); //得到年龄的求和--包装类型,其中，若bigDecimal对象为null，可filter()过滤掉空指针. BigDecimal totalAge = personList.stream().map(User::getAge).reduce(BigDecimal.ZERO, BigDecimal::add); （其中，若bigDecimal对象为null，可filter()过滤掉空指针.） //去重 List&lt;Person&gt; personList3 = personList.stream().distinct().collect(Collectors.toList()); //list转map. //（其中，若集合对象key有重，可根据(k1,k2)-&gt;k1设置&lt;保留k1，舍弃k2&gt;.） Map&lt;Long, Person&gt; personMap = personList.stream().collect(Collectors.toMap(User::getId, t -&gt; t,(k1,k2)-&gt;k1)); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]},{"title":"分布式消息中间件设计","slug":"message-oriented-middleware","date":"2022-03-22T08:56:31.000Z","updated":"2022-03-27T14:06:03.404Z","comments":true,"path":"message-oriented-middleware/","link":"","permalink":"https://xiaoyuge5201.github.io/message-oriented-middleware/","excerpt":"","text":"1. 消息中间件概述 什么是分布式消息中间件 利用高效可靠的消息传递机制进行平台无关的数据交流； 并基于数据通信来进行分布式系统的集成； 通过提供消息和消息排队模型，它可以在分布式环境下扩展进城间的通信。 消息中间件的应用场景 跨系统数据传递、高并发流量削峰、数据异步处理… 常用的消息中间件 ActiveMQ(太老)、RabbitMQ、Kafka、 RocketMQ 本质 一种具备接受请求、保存数据、发送数据等功能的网络应用。和一般的网络应用程序的区别是它主要负责数据的接收和传递，所以性能一般高于普通程序 5大核心组成 协议 持久性机制 消息分布机制 高可用设计 高可靠设计 1.1 协议 协议是计算机之间通信时共同遵守的一组约定，确保计算机之间能够相互交流；是对数据格式和计算机之间交换数据时必须遵守的规则的正式描述 三大要素： 语法：即数据和控制信息的结构或格式 语义：即需要发出何种控制信息，完成何种动作以及作出何种响应 时序：即时间实现顺序的详细说明 消息中间件常用协议：openWire、AMQP、MQTT（物流网，快，不能持久化）、Kafka、OpenMessage等； 不能用http协议的原因是：http每次请求必须要有响应，性能不高； 1.1 AMQP协议 AMQP（Advanced Message Queuing Protocol）是高级消息队列协议；04年JPMorgan Chase(摩根大通集团)联合其他公司共同设计 特性：事物支持、持久化支持，出生金融行业，在可靠性消息处理上具备天然的优势 优秀产品 RabbitMQ、 Apache ACTIVEMQ 1.2 MQTT协议 MQTT（Message Queuing Telemetry Transport）消息队列遥测传输 是IBM开发的一个即时通讯协议，物联网系统架构中的重要组成部分； 特性：轻量、结构简单、传输快、没有事务支持、没有持久化相关设计 应用场景：适用于计算能力有限、低宽带、网络不稳定的场景 优秀产品：RabbitMQ、 Apache ACTIVEMQ 1.3 Open Message协议 OpenMessaging 是近几年有阿里发起，与雅虎、滴滴出行、Streamlio等公司共同参数传里的分布式消息中间件、流处理领域的开发应用标准。 是国内首个在全球范围内发起的分布式消息领域国际标准 特性：结构简单、解析快、有事务设计、有持久化设计 优秀产品：Apache RocketMQ 1.4 Kafka协议 Kafka协议是基于TCP的二进制协议。消息内部是通过长度来分割，由一些基本数据类型组成 特性：结构简单、解析快、无事务设计、有持久化设计 优秀产品：Apache Kafka 1.55 OpenWire协议 开放链接，ActiveMQ自定义的一种协议，ActiveMQ默认链接方式，它提供一种高效率的二进制格式来使消息高速传输 特性：结构简单、解析快、无事务设计、有持久化设计 优秀产品：Apache ActiveMQ 1.2 持久化 简单来说就是将数据存入磁盘，而不是存在内存中岁服务重启而消失，使数据能够永久保存叫做持久化 ActiveMQ RabbitMQ Kafka RocketMQ 文件系统 支持 支持 支持 支持 数据库 支持 - - - 1.3 消息分发 ActiveMQ RabbitMQ Kafka RocketMQ 发布订阅 支持 支持 支持 支持 轮询分发 支持 支持 支持 - 公平分发 - 支持 支持 - 重发 支持 支持 - 支持 消息拉取 - 支持 支持 支持 1.4 高可用 高可用性是指产品在规定的条件和规定的时刻或时间区间内处于可执行规定功能状态的能力； 当业务量大时，一台消息中间件服务器可能无法满足需求，所以需要消息中间件能够集群部署，来达到高可用的目的。 1.4.1 Master-Slave主从共享数据的部署方式 当Master收到客户端的消息后，放到共享的文件系统/数据库； 客户端访问的是Master节点，Slave节点只做备份； 1.4.2 Master-Slave主从同步部署方式 当Master收到客户端的消息后，发给其他broker同步。 1.4.3 Broker-Cluster多主集群同步部署方式 一部分消息放在broker1 ,一部分放在broker2 1.4.4 Broker-Cluster多主集群转发部署方式 转发数据或转发请求 1.4.5 Master-slave与Broker-Cluster结合 1.5 高可靠 高可靠性是指系统可以无故障地持续运行。比如一个系统从来不崩溃、报错，或者崩溃、报错的几率较低，那就是高可靠。 保证消息中间件的高可靠行，可以从一下几方面考虑 消息传输可靠： 通过协议来保证系统件数据解析的正确性 消息存储可靠： 通过持久化来保证消息存储可靠性","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://xiaoyuge5201.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"MinIO简介以及Linux安装MinIO","slug":"linux-minio","date":"2022-03-21T05:39:15.000Z","updated":"2022-03-27T12:52:29.493Z","comments":true,"path":"linux-minio/","link":"","permalink":"https://xiaoyuge5201.github.io/linux-minio/","excerpt":"","text":"1. 什么是对象存储 对象存储服务OSS（Object Storage Service）是一种海量、安全、低成本、高可用的云存储服务，适合存放任意类型的文件。容量和处理能力弹性扩展，多种存储类型提供选择，全面优化存储成本。 最大的优势：可以存储大量的非结构话数据，例如：图片、视频、日志文件、备份数据和容器/虚拟机镜像等。 2. MinIO MinIO 是个基于Golang编写的开源对象存储套件，基于Apache License V2.0开源协议，虽然轻量，却拥有不错的性能，兼容亚马逊S3云存储服务接口。可以很简单的和其他应用结合使用，例如：NodeJS、Redis、mysql等 中文文档： http://docs.minio.org.cn/docs/master/minio-monitoring-guide 2.1 MinIO应用场景 可以作为私有云的对象存储服务来使用，也可以作为云对象存储的网关层，无缝对接Amazon S3 或者 MicroSoft Azure 。 2.2 MinIO特点 高性能 作为一款高性能存储，在标准硬件条件下，其读写速率分别可以达到55Gb/s和 35Gb/s。并且MinIO支持一个对象文件是任意大小（几KB到最大5T不等） 可扩展 不同MinIO集群可以组成联邦，并形成一个全局的命名空间，并且支持跨越多个数据中心 云原生 容器化、基于K8S的编排、多租户支持 Amazon S3兼容 使用Amazon S3 V2/V4 API。可以使用Minio SDK，Minio Client，AWS SDK 和 AWS CLI 访问Minio服务器。 可对接多种后端存储 除了Minio自己的文件系统，还支持 DAS、 JBODs、NAS、Google云存储和 Azure Blob存储。 SDK支持 GO SDK： https://github.com/minio/minio-go JavaSDK： https://github.com/minio/minio-java PythonSDK： https://github.com/minio/minio-py Lambda计算 Minio服务器通过其兼容AWS SNS / SQS的事件通知服务触发Lambda功能。支持的目标是消息队列，如Kafka，NATS，AMQP，MQTT，Webhooks以及Elasticsearch，Redis，Postgres和MySQL等数据库 图形化界面 有操作页面 功能简单 不容易出错，快速启动 支持纠删码 MinIO使用纠删码、Checksum来防止硬件错误和静默数据污染。在最高冗余度配置下，即使丢失1/2的磁盘也能恢复数据 2.3 存储机制 MinIO 使用纠删码erasure code、校验和checksum。 即使丢一半数据（N/2）的鹰派，仍然可以恢复数据。 校验和checksum 保护数据免受硬件故障和无声数据损坏 纠删码erasure code 纠删码是一种恢复丢失和损坏数据的数据算法，目前纠删码技术在分布式存储系统中的应用主要有三类：阵列纠删码（Array Code : RAID5、RAID6等）、RS（Reed-Solomon）里德-所罗门类纠删码和LDPC（LowDensity Parity Check Code） 低密度奇偶校验纠删码。 Erasure code 是一种编码技术，他可以将N份原始数据，增加m份数据，并通过n+m 份中的任意n份数据，还原为原始数据。即如果有任意小于等于m份的数据失效，仍然能通过剩下的数据还原出来。 MinIO 采用Reed-Solomon code将对象拆分成N/2数据和N/2奇偶校验快，这就意味着如果是12块盘，一个对象会分成6个数据块、6个奇偶校验块；可以丢失任意6块盘（不管是存放的数据块还是奇偶校验块），仍可以通过剩下的盘进行数据恢复 3. 安装和使用MinIO 3.1 Linux安装MinIO 下载（https://min.io/download#/linux） 1wget https://dl.min.io/server/minio/release/linux-amd64/minio 运行 12345678910 chmod +x minio ./minio server /usr/software/minio/data #将/usr/software/minio/data 替换为您希望 MinIO 存储数据的驱动器或目录的路径。#或者指定账号密码启动MINIO_ACCESS_KEY=minioadmin MINIO_SECRET_KEY=minioadmin ./minio server --config-dir /usr/software/minio/config /usr/software/minio/data #后台启动nohup ./minio server /usr/software/minio/data &gt; /usr/software/minio/minio.log 2&gt;&amp;1 &amp;##或者指定账号密码启动MINIO_ACCESS_KEY=minioadmin MINIO_SECRET_KEY=minioadmin nohup ./minio server --config-dir /usr/software/minio/config /usr/software/minio/data&gt; /usr/software/minio/minio.log 2&gt;&amp;1 &amp;# 设置启动脚本（建议） 123touch minio.sh vi minio.sh 在sh文件中添加以下内容 123456#指定登录用户名export MINIO_ACCESS_KEY=username#指定登录密码export MINIO_SECRET_KEY=password#指定端口以及存储文件夹，并启动服务 9000访问端口， 9001 控制台界面访问端口, 这里0.0.0.0可以设置为具体的服务器IPnohup ./minio server --address &#x27;0.0.0.0:9000&#x27; --console-address &#x27;0.0.0.0:9001&#x27; ./miniodata &gt; ./miniodata/minio.log 2&gt;&amp;1&amp; 给当前用户加上执行权限 1234chmod u+x *.sh #启动sh minio.sh 3.2 安装客户端(可选) 安装 123wget https://dl.min.io/client/mc/release/linux-amd64/mcchmod +x mc./mc --help 使用命令给客户端添加一个服务端 1./mc alias set minio http://172.21.0.7:9000 minioadmin minioadmin 创建bucket，并查询所有bucket 123456[root@ww xiaoyuge]# ./mc ls minio[root@ww xiaoyuge]# ./mc mb minio/mybucketBucket created successfully `minio/mybucket`[root@ww xiaoyuge]# ./mc ls minio[2020-09-02 03:02:36 CST] 0B mybucket/[root@ww xiaoyuge]# 页面查询bucket 创建用户 1./mc admin user add minio root rootroot 给用户赋予权限 1./mc admin policy set minio readwrite user=root 3.3 使用MinIO 启动 在浏览器输入： http://localhost:9000 在输入控制打印的默认的AccessKey和SecretKey： AccessKey: minioadmin SecretKey（默认）: minioadmin 使用AccessKey 和 SecretKey 登录后台。 进入系统后，我们先要点击右上角的“+”按钮，创建一个文件桶（输入名称后，回车即可），在上传文件到这个文件桶中。Create bucket（创建文件桶），然后输入bucket名称为 test, 创建成功后再Upload file（上传文件）。 现在我们去服务器，我们启动时指定的目录去看看，可以看到一个新建的test文件目录（文件桶相当于文件目录），这里没有使用纠删码的模式，所以直接就是源文件了。当我们线上运行的项目已经有源文件了，在使用minio的时候，可以直接指定该目录为minio的文件目录就行了。 分享文件，也可以设置文件分享有效日期 访问连接会出现如下界面： 3.4 mioIO常见启动问题 启动报错“WARNING: Console endpoint is listening on a dynamic port…” 错误提示很明显，需要to choose a static port。 写了一个shell启动MinIO，在shell中使用–console-address ‘部署minio的ip:希望通过什么端口打开minio console页面’ 1234 export MINIO_ACCESS_KEY=username#指定登录密码 export MINIO_SECRET_KEY=password nohup ./minio server --address &#x27;0.0.0.0:9000&#x27; --console-address &#x27;0.0.0.0:9001&#x27; ./miniodata &gt; ./miniodata/minio.log 2&gt;&amp;1&amp; 4. SpringBoot 集成minIO 项目源代码地址：https://gitee.com/xiaoyuge520/minio-demo， 下面是应用主要功能截图展示： 在minIO的控制台界面选择对应的bucket可以查看到刚提交的内容 同理，删除也是一样！！！","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/tags/Linux/"}]},{"title":"Linux系统下查找文件命令总结","slug":"linux-search-file","date":"2022-03-19T05:52:39.000Z","updated":"2022-05-24T14:05:05.489Z","comments":true,"path":"linux-search-file/","link":"","permalink":"https://xiaoyuge5201.github.io/linux-search-file/","excerpt":"","text":"1. which查命令绝对路径 which 从环境变量PATH中定位/返回与指定名字相匹配的可执行文件所在的路径 原理：执行which命令时，which会在当前环境变量PATH中依次寻找能够匹配所找命令名字的可执行文件名，不加 - a选项，返回第一个匹配的可执行文件路径， 否则依次返回满足条件的所有可执行文件的路径名 适用场合： 一般用于查找命令/可执行文件所在的路径。有时候可能在多个路径下存在相同的命令，该命令可用于查找当前所执行的命令到底是哪一个位置处的命令。 2. whereis查找特定文件 whereis 命令用来定位指令的二进制程序、源代码文件和man手册页等相关文件的路径， 该命令只能用于程序名的搜索 - b #定位可执行文件 - m #定位帮助文件 - s 定位源代码文件 - u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 - B 指定搜索可执行文件的路径。 - M 指定搜索帮助文件的路径。 - S 指定搜索源代码文件的路径 原理： whereis命令首先会去掉filename中的前缀空格和以.开头的任何字符，然后再在数据库（var/lib/slocate/slocate.db）中查找与上述处理后的filename相匹配的二进制文件、源文件和帮助手册文件,使用之前可以使用updatedb命令手动更新数据库。 适用场合： 二进制文件、源文件和帮助手册文件路径的查找。 和find 相比，Whereis 查找的速度非常快，这是因为Linux系统会将系统内的所有文件都记录在一个数据库文件中，当使用whereis (或者locate) 会从数据库查找数据，而不是像find命令那样，通过遍历硬盘来查找文件，效率更高！ 3. locate缓存查找文件 locate 搜素一个数据库（/var/lib/mlocate/mlocate.db）,这个数据库中国呢包含本地所有文件信息，Linux系统自动创建这个数据库，并且每天更新依次，所以使用locate命令查不到最新变动过的文件，为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库，updatedb命令会根据/etc/updatedb.conf来更新文件。 原理： 默认情况下(当filename中不包含通配符*)，locate会给出所有与 * filename*相匹配的文件的路径。 适用场合： 没有文件类型性质的模糊查找（你只记得某个文件的部分名称）。 4. find 遍历文件查找 语法： -name #按文件名查找(find /etc/ -name “???” 查找/etc目录下，开头是6个任意字符的文件， *.log以log结尾的文件；&quot;[1-3].txt&quot;指定范围以txt结尾的文件（包括 1.txt,2.txt,3.txt）) -size #按大小查找（find /etc/ -size +1M 查询大于1M的文件(find /etc/ -size -10K)，注意：如果没有+ -， 则是精确到1M,加上+ - 表示范围； find /etc/ -size +1k -a -size -10k 查找1-10K的文件） -user #按属主查找（find /opt/ -user xiaoyuge 查找/opt属于xiaoyuge用户的文件；注意，系统要存在该用户，否则会报错） -perm #按权限查找（find /opt/ -perm 0644 查找/opt目录权限是644文件） -type #按类型查找（find /usr/bin/ -type f 查找/usr/bin下类型是二进制文件） -time #按天查找 atime n #将n*24小时内访问过的文件列出(access) ctime n #将n*24小时内状态发生改变的文件列出（change） find /etc/ -ctime +7 在7天之前,属性被修改过的文件 mtime n #将n*24小时内被修改过的文件列出(modify) newer file #把比file还要心的文件列出 amin n #将n 分钟内访问过的文件列出(access) find /etc/ -mmin -120 在120分钟内，内容被修改的文件 cmin n #将n 分钟内状态发生改变的文件列出（change） mmin n #将n 分钟内被修改过的文件列出(modify) -inum #按i节点查找 有一些文件的硬链接数量很多，有相同的i节点，查找其中一个文件的i节点号，一次性删除。 -exec #查找后执行命令 原理： 遍历当前工作目录及其子目录，find命令是在硬盘上遍历查找，非常耗硬盘资源，查找效率相比whereis和locate较低。 适用场合： 能用which、whereis和locate的时候尽量不要用find. 5. 4种命令对比","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/tags/Linux/"}]},{"title":"docker安装nginx","slug":"docker-nginx","date":"2021-12-09T13:47:19.000Z","updated":"2022-10-30T10:55:55.862Z","comments":true,"path":"docker-nginx/","link":"","permalink":"https://xiaoyuge5201.github.io/docker-nginx/","excerpt":"","text":"1.查看所有的镜像 1docker search nginx 2.拉取最新版本的镜像 1234docker pull nginx#或者指定最新版本docker pull nginx:latest 3.使用命令查看本地镜像，确定nginx镜像已下载到本地 1docker images 4. 创建挂载目录 1mkdir -p /data/nginx/&#123;conf,conf.d,html,logs&#125; 5. 创建配置文件 1touch nginx.cnf 6. Nginx详情配置请参考：https://xiaoyuge.work/2021/12/05/nginx-02/ 7. 查看容器 1234docker ps -a# docker stop xxx 停止某个容器运行# docker rm xxx 删除容器 8.启动容器，挂载配置文件 1docker run --name mynginx -d -p 80:80 -v /data/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /data/nginx/logs:/var/log/nginx -d docker.io/nginx 可以通过命令docker exec -it nginx-test bash进入容器内容修改配置 9.安装完毕，访问地址 http://localhost:8080，出现如下内容，安装成功！！！ 10.域名解析配置 我买的是阿里云的服务器以及域名，上面操作后，忘记在阿里云控制台中去配置 11.配置多个二级域名 在第8步的时候将docker容器中的nginx配置映射到了目录/data/nginx/conf下面； 修改nginx.conf 123456789101112131415161718192021222324user nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; #引入conf.d下面所有的配置文件 include /etc/nginx/conf.d/*.conf;&#125; 然后在conf.d目录下面创建了两个子域名反向代理配置文件,其他的域名代理相同，只要改server_name和proxy_pass代理端口，配置文件需以.conf结尾 note.xiaoyuge520.vip.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243######## Nginx的main(全局配置)文件#指定nginx运行的用户及用户组,默认为nobody#user nobody;#开启的线程数，一般跟逻辑CPU核数一致worker_processes 1;events &#123;#设置工作模式为epoll,除此之外还有select,poll,kqueue,rtsig和/dev/poll模式#use epoll; #定义每个进程的最大连接数,受系统进程的最大打开文件数量限制。 worker_connections 1024;&#125;#######Nginx的Http服务器配置,Gzip配置http &#123; include mime.types; #核心模块指令，智力默认设置为二进制流，也就是当文件类型未定义时使用这种方式 default_type application/octet-stream; #开启高效文件传输模式 sendfile on; keepalive_timeout 65; ########Nginx的server虚拟主机配置 server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name note.xiaoyuge520.vip; #设置访问的语言编码 #charset koi8-r; #设置虚拟主机访问日志的存放路径及日志的格式为main #access_log logs/host.access.log main; #设置虚拟主机的基本信息 location / &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://47.101.130.163:8086/note; # 代理ip:端口 &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; record.xiaoyuge520.vip.conf 1234567891011121314151617181920212223242526worker_processes 1;events &#123; worker_connections 1024;&#125;#######Nginx的Http服务器配置,Gzip配置http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name record.xiaoyuge520.vip; #access_log logs/host.access.log main; location / &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://47.101.130.163:8888/record; # 代理ip:端口 &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 如果挂载之后容器运行正常却依然不能通过域名访问可尝试以下操作 12345678910#查看所有容器,获取nginx的container 名称docker ps -a#向名称为nginx的容器发送脚本命令, mynginx 为容器名称docker exec -it mynginx /bin/bash#重新加载配置命令cd /etc/nginx/conf.dservice nginx reload#检查配置文件路径是否正确 每一次更改配置文件都需要重启容器 12345678# 重启nginx容器docker restart nginx #查看容器状态docker ps #如果挂载失败，查看nginx容器log,显示错误信息，根据错误信息 更改配置文件等docker logs -t nginx 以上配置完成之后能够通过域名访问网站，但是css样式却被nginx解析成text/plain，打开控制台可看到warn信息 解决nginx将css文件解析为text/plain 方法一： ngin.conf中http添加： 12include /etc/nginx/mime.types;default_type application/octet-stream; 注：此办法并不能使我网站的css正确解析，因为在拷贝nginx镜像中的原配置文件时，就已经添加mime.types了。却依然不能正确解析。 方法二：解析成功，原因未知 1将index.html中&lt;!DOCTYPE html&gt;去掉。 通过域名访问：成功！！","categories":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/categories/nginx/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/tags/Docker/"}]},{"title":"docker安装mysql","slug":"docker-mysql","date":"2021-12-09T13:32:36.000Z","updated":"2022-10-30T10:56:03.551Z","comments":true,"path":"docker-mysql/","link":"","permalink":"https://xiaoyuge5201.github.io/docker-mysql/","excerpt":"","text":"1.查看所有的镜像 1docker search mysql 2.拉取最新版本的镜像 1234docker pull mysql#或者指定版本docker pull mysql:8.0.16 3.创建数据目录和配置文件 123mkdir -p /usr/mysql/conf /usr/mysql/datachmod -R 777 /usr/mysql/ 4.创建配置文件 在上面创建的配置文件目录/usr/mysql/conf下创建MySQL的配置文件my.cnf 123touch my.cnf;vim /usr/mysql/conf/my.cnf; 添加以下内容到上述创建的配置文件中 123456789101112131415161718[client]#socket = /usr/mysql/mysqld.sockdefault-character-set = utf8mb4[mysqld]#pid-file = /var/run/mysqld/mysqld.pid#socket = /var/run/mysqld/mysqld.sock#datadir = /var/lib/mysql#socket = /usr/mysql/mysqld.sock#pid-file = /usr/mysql/mysqld.piddatadir = /usr/mysql/datacharacter_set_server = utf8mb4collation_server = utf8mb4_binsecure-file-priv= NULL# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Custom config should go here!includedir /etc/mysql/conf.d/ 5.启动创建容器 1docker run --restart=unless-stopped -d --name mysql -v /usr/mysql/conf/my.cnf:/etc/mysql/my.cnf -v /usr/mysql/data:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=xiaoyuge mysql 参数解释： 123456–name mysql5.7 容器别名-p 3307:3306 映射容器端口号和宿主机端口号（本机3307端口映射容器3306端口）-v /data/mysql/datadir:/var/lib/mysql 目录映射（挂载宿主机目录和 docker容器中的目录，前面是宿主机目录，后面是容器内部目录）-v /data/mysql/conf.d:/etc/mysql/conf.d 目录映射（mysql配置目录）-d 后台运行-e 环境参数，MYSQL_ROOT_PASSWORD设置root用户的密码 执行上述命令后，执行查询容器的命令就可以看到创建的mysql容器 1docker ps -a 常见问题 1.远程无法链接 上述虽然安装好了mysql，但是使用远程的Navicat连接时提示错误，不能正确连接mysql，此时需要修改按照下面说的步骤修改一下mysql的密码模式以及主机等内容才可以。 修改mysql密码以及可访问主机 进入容器内部 1docker exec -it mysql /bin/bash 连接mysql 1mysql -uroot -p 使用mysql库 1use mysql; 修改访问主机以及密码等，设置为所有主机可访问 123ALTER USER &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;;#注意： mysql_native_password，mysql8.x版本必须使用这种模式，否则navicate无法正确连接 刷新 123flush privileges;exit; 远程使用Navicat连接数据库 2.docker启动mysql容器报错 1docker run --restart=unless-stopped -d --name mysql -v /usr/mysql/conf/my.cnf:/etc/mysql/my.cnf -v /usr/mysql/data:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=xiaoyuge mysql 启动时提示：Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: signal: segmentation fault (core dumped), stdout: , stderr:: unknown 解决方式： 1sudo yum upgrade 或者可以试下 12345rm -rf /usr/mysql/conf/my.cnftouch /usr/mysql/conf/my.cnfvim my.cnf#然后重新配置一下","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/tags/Docker/"}]},{"title":"docker安装","slug":"docker-01","date":"2021-12-09T13:20:57.000Z","updated":"2022-04-02T07:45:56.614Z","comments":true,"path":"docker-01/","link":"","permalink":"https://xiaoyuge5201.github.io/docker-01/","excerpt":"","text":"新的服务器没有安装docker，使用docker命令时提示：docker: command not found错误信息 1. 更新yum包 1yum update 2.安装依赖软件包 1yum install -y yum-utils device-mapper-persistent-data lvm2 3.设置yum源 1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 4.安装docker 12#默认安装最新的docker稳定版本。yum install docker-ce 5.启动docker服务 1systemctl start docker 6.设置开机自启动 1systemctl enable docker 7. 查看docker版本信息 1docker version 至此，解决。 8. 停止所有容器 1docker stop $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2)","categories":[{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://xiaoyuge5201.github.io/tags/docker/"}]},{"title":"Nginx基础篇（四）Nginx实现反向代理","slug":"nginx-04","date":"2021-12-05T08:52:42.000Z","updated":"2022-10-30T10:55:40.806Z","comments":true,"path":"nginx-04/","link":"","permalink":"https://xiaoyuge5201.github.io/nginx-04/","excerpt":"","text":"1. 正向代理和反向代理 正向代理： 正向代理类似一个跳板机，代理访问外部资源 比如我们国内访问谷歌，直接访问访问不到，我们可以通过一个正向代理服务器，请求发到代理服，代理服务器能够访问谷歌，这样由代理去谷歌取到返回数据，再返回给我们，这样我们就能访问谷歌了 正向代理的用途： （1）访问原来无法访问的资源，如google （2） 可以做缓存，加速访问资源 （3）对客户端访问授权，上网进行认证 （4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 正向代理即是客户端代理, 代理客户端, 服务端不知道实际发起请求的客户端 反向代理： 反向代理（Reverse Proxy）实际运行方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器 反向代理的作用： （1）保证内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网 （2）负载均衡，通过反向代理服务器来优化网站的负载 反向代理即是服务端代理, 代理服务端, 客户端不知道实际提供服务的服务端 2. Nginx配置反向代理 在http-&gt; server块中配置server_name 1234567891011121314151617server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name http://192.168.44.99; #设置虚拟主机的基本信息 location / &#123; proxy_pass http://192.168.44.1:9096; ###最重要的配置，转发到目标地址， 也可以配置服务器组，然后upstream一个服务器组 proxy_method POST; #设置转发请求的格式 #Nginx在header里面增加一个自定义字段 Host， 用于存放当前客户端IP地址 proxy_set_header Host $host; #获取客户端的真实IP地址设置到header中的字段名为X-Real-IP里面 proxy_set_header X-Real-IP $remote_addr; #获取所有转发请求的IP信息列表 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 那么访问http://192.168.44.99 ， nginx会将请求转发给目标服务器http://192.168.44.1:9096 2.1 location 匹配规则 匹配规则从上到下，匹配规则越宽松； 模式 含义 location=/uri = 表示精确匹配，只有完全匹配才能生效 location ^~ /uri ^~ 开头对URL路径进行前缀匹配，并且在正则之前 location ~ pattern 开头表示区分大小写的正则匹配 location ~* pattern 开头表示不区分大小写的正则匹配 location /uri 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后 location / 通用匹配，任何未匹配到其他location的请求都会匹配到，相当于switch中的default","categories":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"Nginx基础篇（三）实现虚拟主机","slug":"nginx-03","date":"2021-12-05T08:31:25.000Z","updated":"2022-10-30T10:55:34.469Z","comments":true,"path":"nginx-03/","link":"","permalink":"https://xiaoyuge5201.github.io/nginx-03/","excerpt":"","text":"1. 虚拟主机Virtual Host 一种在单一主机或主机群上，实现多网域服务的方法，可以运行多个网站或服务的技术，虚拟主机之间完全独立，并可由用户自行管理虚拟并非指不存在，而是指空间是由实体的服务器延伸而来，其硬件系统可以是基于服务器群，或者单个服务器 使用域名访问虚拟主机，虚拟主机会给一个文件路径，然后部署自己的内容；访问域名时就会访问改文件夹下的某 个资源 2. 使用Nginx配置虚拟主机 在nginx下建立一个ygb的文件夹，里面新建一个index.html 在nginx.conf配置下http -&gt; server块内配置 12345678910111213141516171819202122server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name www.xiaoyuge.work; #设置访问的语言编码 #charset koi8-r; #设置虚拟主机访问日志的存放路径及日志的格式为main #access_log logs/host.access.log main; # 这个是域名反问的虚拟主机的文件路径 root /usr/local/nginx/data/ygb #设置虚拟主机的基本信息 location / &#123; #设置虚拟主机默认访问的网页 index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动,然后在浏览器访问域名www.xiaoyuge.work 1./nginx -c ./nginx.conf","categories":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"Nginx基础篇（二）安装","slug":"nginx-02","date":"2021-12-05T08:10:44.000Z","updated":"2022-11-15T13:35:16.102Z","comments":true,"path":"nginx-02/","link":"","permalink":"https://xiaoyuge5201.github.io/nginx-02/","excerpt":"","text":"1.Nginx安装 安装nginx前首先要确认系统中是否安装了gcc 、pcre-devel、zlib-devel、openssl-devel 1234#1、rpm包安装的，可以用 rpm -qa 看到，如果要查找某软件包是否安装，用 rpm -qa | grep &quot;软件或者包的名字&quot;#2、以deb包安装的，可以用 dpkg -l 看到。如果是查找指定软件包，用 dpkg -l | grep &quot;软件或者包的名字&quot;#3、yum方法安装的，可以用 yum list installed 查找，如果是查找指定包，用 yum list installed | grep &quot;软件名或者包名&quot;yum list installed | grep &quot;gcc&quot; 安装依赖包 1yum -y install gcc pcre-devel zlib-devel openssl openssl-devel 下载并解压安装包 1234567//创建nginx存放文件夹cd /usr/local#下载tar包wget http://nginx.org/download/nginx-1.23.2.tar.gztar -xvf nginx-1.23.2.tar.gzmv nginx-1.23.2 nginx# 配置 123456cd nginxmkdir logs./configure --prefix=/usr/local/nginxmakemake install 测试是否安装成功 12cd /usr/local/nginx./sbin/nginx -t 配置nginx.conf 1234567891011121314151617181920vim /usr/local/nginx/cong/nginx.conf#修改如下server &#123; listen 80; server_name localhost; # 注意设定 root路径是有dist的 location / &#123; root /usr/local/webapp/dist; index /index.html; &#125; #跨域 ip和port自行替换 location /adminApi &#123; proxy_pass http://ip:port; &#125;&#125; 启动 123#启动nginxcd /usr/local/nginx/sbin./nginx 常见问题 nginx启动提示：nginx: [emerg] bind() to 0.0.0.0:8080 failed (98: Address already in use) 修改端口 123456789101112131415#首先进入nginx/conf目录（根据自己的目录来写）# vi /usr/nginx/conf/nginx.conf#修改nginx.conf，将8080端口修改为其他端口号 server &#123; listen 8080; server_name localhost;#更换端口之后，然后重启nginx就可以了server &#123; listen 8888; server_name localhost; ...&#125; 取消占用端口号进程 123456#查看被占用的端口netstat -nlp|grep :8080tcp 0 0 0.0.0.0:8888 0.0.0.0:* LISTEN 24594/nginx: master#结束进程24594kill -9 24594#然后再重启nginx就可以了 常用命令 12345678910111213141516171819202122232425262728293031323334353637383940#修改配置后重新启动./nginx -s reload#如果出现：nginx: [error] open() ＂/usr/local/nginx/logs/nginx.pid＂ failed/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf#再次启动即可#查看nginx进程是否启动ps -ef|grep nginx#平滑启动nginxkill -HUP#主进程号或进程号文件路径 或者使用/usr/nginx/sbin/nginx -s reload#注意，修改了配置文件后最好先检查一下修改过的配置文件是否正 确，以免重启后Nginx出现错误影响服务器稳定运行。#判断Nginx配置是否正确命令如下：nginx -t -c /usr/nginx/conf/nginx.conf#或者使用/usr/nginx/sbin/nginx -t#重启nginx reload/usr/local/nginx/sbin/nginx -s reload service nginx restart#检查 nginx.conf 配置文件是否有错/usr/local/nginx/sbin/nginx -t#nginx启动命令:/usr/local/nginx/sbin/nginx#指定配置文件启动/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf#关闭命令:/usr/local/nginx/sbin/nginx -s stop#重启命令:/usr/local/nginx/sbin/nginx -s reload#启动./nginx#关闭./nginx -s stop 启动后访问localhost 效果如下： 2.Nginx配置 12345678910111213141516171819202122232425...... 全局块events &#123;true//events 块&#125;###数据库配置stream &#123; server &#123; listen 3306; proxy_pass db; &#125; upstream db &#123; server 192.168.18.130:3305; server 192.168.18.129:3305; &#125; &#125;http&#123; ##http全局块true server+&#123;truetruelocation +[]true&#125;&#125; 2.1配置内容规则 官网配置教程：https://nginx.org/en/docs/dirindex.html 变量应用：https://nginx.org/en/docs/varindex.html 用#表示注释 每行配置的结尾需要加上分号 如果配置项值中包括语法符号，比如空格符，那么需要使用单引号或者双引号行括住配置项值，否则ngin x会报语法错误 单位简写： K或者k千字节（kilo byte, KB） M或者m兆字节（megabyte MB） ms(毫秒)，s(秒)， m(分)， h(小时) ， d (天)， w（周）， M（月，包含30天），y（年） 2.2 详细配置内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157######## Nginx的main(全局配置)文件#指定nginx运行的用户及用户组,默认为nobody#user nobody;#开启的线程数，一般跟逻辑CPU核数一致worker_processes 1;#定位全局错误日志文件，级别以notice显示，还有debug,info,warn,error,crit模式，debug输出最多，crir输出最少，根据实际环境而定#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#指定进程id的存储文件位置#pid logs/nginx.pid;#指定一个nginx进程打开的最多文件描述符数目，受系统进程的最大打开文件数量限制#worker_rlimit_nofile 65535events &#123; #设置工作模式为epoll,除此之外还有select,poll,kqueue,rtsig和/dev/poll模式 #use epoll; #定义每个进程的最大连接数,受系统进程的最大打开文件数量限制。 worker_connections 1024;&#125;###数据库的负载均衡stream &#123; upstream mysql_nginx &#123; hash $remote_addr consistent; server 192.168.18.128:3306 weight=5 max_fails=3 fail_timeout=30s; server 192.168.18.129:3306; server 192.168.18.130:3306; ##last_conn; #最小连接 &#125; server &#123; listen 3306; # 数据库服务器监听端口 proxy_connect_timeout 10s; proxy_timeout 300s; # 设置客户端和代理服务之间的超时时间，如果5分钟内没操作将自动断开。 proxy_pass mysql_nginx; &#125;&#125;#######Nginx的Http服务器配置,Gzip配置http &#123; #主模块指令，实现对配置文件所包含的文件的设定，可以减少主配置文件的复杂度，DNS主配置文件中的zonerfc1912,acl基本上都是用include语句。 include mime.types; #核心模块指令，智力默认设置为二进制流，也就是当文件类型未定义时使用这种方式 default_type application/octet-stream; #下面代码为日志格式的设定，main为日志格式的名称，可自行设置，后面引用 #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #引用日志main， main是log-format的格式，在上面配置了；后面可以加上日志缓冲区大小，写满了就flush到磁盘中buffer = 1M; #access_log logs/access.log main; #设置允许客户端请求的最大的单个文件字节数 #client_max_body_size 20M; #指定来自客户端请求头的headebuffer大小 #client_header_buffer_size 32k; #指定连接请求试图写入缓存文件的目录路径 #client_body_temp_path /dev/shm/client_body_temp; #指定客户端请求中较大的消息头的缓存最大数量和大小，目前设置为4个32KB #large client_header_buffers 4 32k; #开启高效文件传输模式 sendfile on; #开启防止网络阻塞 #tcp_nopush on; #开启防止网络阻塞 #tcp_nodelay on; #设置客户端连接保存活动的超时时间 #keepalive_timeout 0; keepalive_timeout 65; #设置客户端请求读取超时时间 #client_header_timeout 10; #设置客户端请求主体读取超时时间 #client_body_timeout 10; #用于设置相应客户端的超时时间 #send_timeout ####HttpGZip模块配置 #httpGzip modules #开启gzip压缩 #gzip on; #设置允许压缩的页面最小字节数 #gzip_min_length 1k; #申请4个单位为16K的内存作为压缩结果流缓存 #gzip_buffers 4 16k; #设置识别http协议的版本，默认为1.1 #gzip_http_version 1.1; #指定gzip压缩比，1-9数字越小，压缩比越小，速度越快 #gzip_comp_level 2; #指定压缩的类型 #gzip_types text/plain application/x-javascript text/css application/xml; #让前端的缓存服务器进过gzip压缩的页面 #gzip_vary on; #########Nginx的server虚拟主机配置 server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name localhost; #设置访问的语言编码 #charset koi8-r; #设置虚拟主机访问日志的存放路径及日志的格式为main #access_log logs/host.access.log main; #设置虚拟主机的基本信息 location / &#123; #设置虚拟主机的网站根目录 root html; #设置虚拟主机默认访问的网页 index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125;&#125; 2.3 日志 在nginx同级目录下logs文件夹 access.log 正常日志 error.log 错误日期 需要在nginx.conf中的http模块配置access_log","categories":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"Nginx基础篇（一）扫盲","slug":"nginx-md","date":"2021-12-05T06:56:36.000Z","updated":"2022-10-30T10:55:37.923Z","comments":true,"path":"nginx-md/","link":"","permalink":"https://xiaoyuge5201.github.io/nginx-md/","excerpt":"","text":"1.Nginx发展史 作者：logo Sysoev 2000年地洞，c语言编写 2004年开源 2011年成立商业公司 2013 发布商业版本Nginx plus 2019.5月F5 Networks收购nginx 2019.12被Rambler集团起诉 2.Nginx与其他web服务器对比 Nginx与Apache HTTP server project区别 用来响应用户请求的web服务器 Nginx 和tomcat区别 Nginx是HTTP Server，主要是用于访问一些静态资源，可以用做代理服务器 Tomcat是Application Server应用服务器，用来存放和运行程序； HTTP Server 和Application Server区别与联系 3. HTTP知识 3.1 IP和端口 120.77.38.160:80 0为A类，10为B类，110为C类，1110为D类，1111为E类。D类地址供组播使用，E类地址保留。 端口是：0～65535 3.2 域名 协议、子域名、顶级域名、域名类型、资源路径、参数 12345678#https 协议默认端口443 可以省略https://www.baidu.com:443#user：子域名， com为域名类型（cn中国， us美国...）； 3623252831 为资源路径https://user.qzone.qq.com/3623252831#？号后面为参数https://baike.baidu.com/item/测试/232323?fr=asdfasdf 域名(domainName)和IP的关系以及域名的组成 域名：https://www.baidu.com:443/member/query?far=adsfad http/ https: 协议 baidu: 顶级域名 Com： 域名类型 www: 子域名，可以有多级：user.qzone.qq.com/232323 far=asdfa: 参数 member/query: 资源路径 DNS(domain name server)将域名转化为ip+port 3.3 HTTP协议的特点 简单快速 灵活 无连接（一次请求，连接关闭） 无状态（每次请求都和之前的请求无关） 3.4 HTTP协议的请求格式 12345Request URL: https://prtas.videocc.net/v2/view?pid=1638687363047X1327470&amp;vid=8c8d9388d0b4c16f41ef557fba23dede_8&amp;uid=8c8d9388d0&amp;flow=0&amp;ts=1638688553584&amp;href=aHR0cHM6Ly9rZS5ndXBhb2VkdS5jbi9wbGF5LzI4OD9waGFzZUlkPTU&amp;duration=1278&amp;cts=789&amp;sign=fcf19468eff088e983796d5826268f2d&amp;sd=1190&amp;pd=788&amp;pn=HTML5&amp;pv=v1.15.0&amp;sid=ZDIzZGM4ODUtNDM2My00MTQ3LWJmYTktY2M3MDgwM2U0NDc5&amp;param1=&amp;param2=MTc2MjEyODQ5OTg&amp;param3=&amp;cataid=1591268435818Request Method: GETStatus Code: 200 Remote Address: 221.231.81.238:443Referrer Policy: strict-origin-when-cross-origin 请求行 请求类型 Request Method GET: 请求指定的页面细腻，并返回尸体主题 HEAD: 类似于GET请求，只不过返回的相应中没有具体的内容，用于获取报头 POST：想指定资源提交数据进行处理请求，数据被高喊在请求体中 PUT: 从客户端想服务器传送的数据取代指定的文档的内容 DELETE: 请求服务器删除指定的页面 CONNECT: HTTP/1.1协议中预留给能够将连接方式改为管道方式的代理服务器 OPTIONS: 允许客户端查看服务器的性能 TRACE: 回显服务器收到的请求，主要用于测试后诊断 请求头 空行和请求数据 3.5 HTTP协议的返回格式 状态行、小洗头、空行和响应正文 1234567891011HTTP/1.1 200Server: nginx/1.20.1Date: Sun, 05 Dec 2021 07:24:45 GMTContent-Type: application/json;charset=UTF-8Transfer-Encoding: chunkedConnection: keep-aliveAccess-Control-Allow-Origin: https://ke.gupaoedu.cnAccess-Control-Allow-Credentials: trueAccess-Control-Allow-Methods: PUT,POST,GET,DELETE,OPTIONS,PATCHAccess-Control-Allow-Headers: DNT,web-token,app-token,Authorization,Accept,Origin,Keep-Alive,User-Agent,X-Mx-ReqToken,X-Data-Type,X-Auth-Token,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,token,showerrAccess-Control-Max-Age: 86400 Http格式响应状态码有哪些 1xx: informational(信息性状态码) 接受的请求正在处理 2xx: success(成功状态码) 请求正常处理完毕 3xx：redirection（重定向状态码）需要进行复检操作以完成请求 4xx：client error（客户端错误状态码） 服务器无法处理请求 5xx: server error（服务器错误错误状态码） 服务器处理请求出错 3.6 通用头字段Common Header 字段 含义 Cache-control 控制缓存的行为 Connection 控制不再转发给代理的收不字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主题的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 3.7 响应头字段Response Header 字段 含义 Accept-Ranges 是否接收字节范围请求 Age 推算资源创建经过的时间 ETag 资源的匹配信息 Location 另客户端重定向至指定的URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 3.8 实体头字段 Entity Header 字段 含义 Allow 资源科支持的http方法 Connect-Encoding 实体主体适用的编码格式 Content-Language 实体主体的自然语言 Content-length 实体主体的大小 Content-Location 替代敌营资源的URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间","categories":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"二分法查找题","slug":"algorithm-dinary-search","date":"2021-11-26T13:57:32.000Z","updated":"2022-03-27T14:06:03.335Z","comments":true,"path":"algorithm-dinary-search/","link":"","permalink":"https://xiaoyuge5201.github.io/algorithm-dinary-search/","excerpt":"","text":"1. 第一个错误的版本 1.1 题目描述 你是产品经理，目前正在带领一个团队开发新的产品。不幸的是，你的产品的最新版本没有通过质量检测。由于每个版本都是基于之前的版本开发的，所以错误的版本之后的所有版本都是错的。 假设你有 n 个版本 [1, 2, …, n]，你想找出导致之后所有版本出错的第一个错误的版本。 你可以通过调用bool isBadVersion(version)接口来判断版本号 version 是否在单元测试中出错。实现一个函数来查找第一个错误的版本。你应该尽量减少对调用 API 的次数。 示例 1234567输入：n = 5, bad = 4输出：4解释： 调用 isBadVersion(3) -&gt; false 调用 isBadVersion(5) -&gt; true 调用 isBadVersion(4) -&gt; true所以，4 是第一个错误的版本 1.2 解题思路 当一个版本为正确版本，则该版本之前的所有版本均为正确版本；当一个版本为错误版本，则该版本之后的所有版本均为错误版本。我们可以利用这个性质进行二分查找。 具体地，将左右边界分别初始化为 1和 n ，其中 n 是给定的版本数量。设定左右边界之后，每次我们都依据左右边界找到其中间的版本，检查其是否为正确版本。如果该版本为正确版本，那么第一个错误的版本必然位于该版本的右侧，我们缩紧左边界；否则第一个错误的版本必然位于该版本及该版本的左侧，我们缩紧右边界。 这样我们每判断一次都可以缩紧一次边界，而每次缩紧时两边界距离将变为原来的一半，因此我们至多只需要缩紧 O(logn) 次。 1.3 代码 123456789101112131415public int firstBadVersion(int n) &#123; int left = 1, right = n; while (left &lt; right)&#123; int mid = left + (right - left) / 2; // 防止计算时溢出 if (isBadVersion(mid))&#123; // 答案在区间 [left, mid] 中 right = mid; //如果中间版本是错误的版本，那么它之后的都是错误的; &#125;else &#123; // 答案在区间 [mid+1, right] 中 left = mid + 1; &#125; &#125; //此时有 left == right,退出了while循环 return left;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"}]},{"title":"Mysql添加/修改/删除字段","slug":"mysql-column","date":"2021-11-15T13:13:42.000Z","updated":"2022-04-06T09:51:44.947Z","comments":true,"path":"mysql-column/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql-column/","excerpt":"","text":"1. 添加字段 1.1 在末尾添加字段 1）语法： 1ALTER TABLE &lt;表名&gt; ADD &lt;字段名&gt; &lt;数据类型&gt; [约束条件]; 语法格式的说明： &lt;表名&gt; 为数据表的名字； &lt;字段名&gt; 为所要添加的字段的名字； &lt;数据类型&gt; 为所要添加的字段能存储数据的数据类型； [约束条件] 是可选的，用来对添加的字段进行约束。 这种语法格式默认在表的最后位置（最后一列的后面）添加新字段 2）示例：在user表末尾添加字段phone 1ALTER TABLE user ADD phone VARCHAR(11) DEFAULT NULL COMMENT &#x27;电话号码&#x27;; 1.2 在开头添加字段 1）语法： 1ALTER TABLE &lt;表名&gt; ADD &lt;字段名&gt; &lt;数据类型&gt; [约束条件] FIRST; FIRST 关键字一般放在语句的末尾 2）示例：在user表开头添加字段user_id 1ALTER TABLE user ADD user_id VARCHAR(32) NOT NULL COMMENT &#x27;用户主键&#x27; FIRST; 1.3 在中间添加字段 1）语法： 1ALTER TABLE &lt;表名&gt; ADD &lt;字段名&gt; &lt;数据类型&gt; [约束条件] AFTER &lt;已经存在的字段名&gt;; AFTER 的作用是将新字段添加到某个已有字段后面。 注意：只能在某个已有字段的后面添加新字段，不能在它的前面添加新字段 2）示例：在user表的user_id字段后添加username字段 1ALTER TABLE user ADD username VARCHAR(30) DEFAULT NULL COMMENT &#x27;用户名&#x27; AFTER `user_id`; 2. 修改字段 2.1 修改字段属性 1）语法： 1ALTER TABLE &lt;表名&gt; MODIFY &lt;字段名&gt; &lt;数据类型&gt; [约束条件]; 2）示例1：修改字段属性 12-- 将email字段VARCHAR(50)修改成VARCHAR(200)ALTER TABLE user MODIFY email VARCHAR(200) NOT NULL DEFAULT &#x27;email@163.com&#x27;; 注意：修改时如果不带完整性约束条件，原有的约束条件将丢失，如果想保留修改时就得带上完整性约束条件 3）示例2： 将email移到phone后面 1ALTER TABLE user MODIFY email VARCHAR(50) AFTER `phone`; 4）示例3：放置第一个，保留原完成性约束条件 1ALTER TABLE user`MODIFY email VARCHAR(50) NOT NULL DEFAULT &#x27;test@163.com&#x27; FIRST; 5）示例4：修改成大小写敏感，即查询区分大小写 1ALTER TABLE user MODIFY username VARCHAR(30) BINARY CHARACTER SET utf8 COLLATE utf8_bin DEFAULT NULL COMMENT &#x27;用户名&#x27;; 2.2 修改字段名称和属性 1）语法： 1ALTER TABLE &lt;表名&gt; CHANGE &lt;原字段名&gt; &lt;新字段名&gt; &lt;数据类型&gt; [约束条件]; 2）示例：将username字段修改成user_name 1ALTER TABLE user CHANGE username user_name VARCHAR(30) DEFAULT NULL COMMENT &#x27;用户名&#x27;; 2.3 添加、删除默认值 1）语法： 12345-- 添加默认值ALTER TABLE &lt;表名&gt; ALTER &lt;字段名&gt; SET DEFAULT &lt;默认值&gt;;-- 删除默认值ALTER TABLE &lt;表名&gt; ALTER &lt;字段名&gt; DROP DEFAULT; 2）示例：给sex添加默认值 1ALTER TABLE USER ALTER sex SET DEFAULT &#x27;难&#x27;; 3）示例：删除sex默认值 1ALTER TABLE user ALTER sex DROP DEFAULT; 2.4 添加、删除主键 语法： 12345-- 添加主键ALTER TABLE &lt;表名&gt; ADD [CONSTRAINT &lt;约束名&gt;] PRIMARY KEY (&lt;字段名称,...&gt;);-- 删除主键ALTER TABLE &lt;表名&gt; DROP PRIMARY KEY; 2）示例：添加主键 1ALTER TABLE user ADD PRIMARY KEY (user_id) 3）示例：添加复合主键 1ALTER TABLE user_role ADD PRIMARY KEY (user_id, role_id); 4）示例：删除主键 1ALTER TABLE user DROP PRIMARY KEY; 5）示例：删除带自增长属性的主键 1234-- 先用MODIFY删除自增长属性，注意MODIFY不能去掉主键属性ALTER TABLE test MODIFY id INT UNSIGNED;-- 再来删除主键ALTER TABLE test DROP PRIMARY KEY; 2.5 添加、删除唯一索引 1）语法： 12345-- 添加唯一性约束ALTER TABLE &lt;表名&gt; ADD [CONSTANT &lt;约束名&gt;] UNIQUE [INDEX | KEY] [索引名称](&lt;字段名称,...&gt;)-- 删除唯一性约束ALTER TABLE &lt;表名&gt; DROP [INDEX | KEY] [索引名称]; 2）示例：为username添加唯一性约束，如果没有指定索引名称，系统会以字段名建立索引 1ALTER TABLE user ADD UNIQUE(username); 3）示例：为username添加唯一性约束，并指定索引名称 1ALTER TABLE user ADD UNION KEY uni_username(username); 4）示例：查看索引 1SHOW CREATE TABLE user; 5）示例：添加联合UNIQUE 1ALTER TABLE user ADD UNIQUE INDEX uni_nickname_username(nickname, username); 6）示例：删除索引 123ALTER TABLE user DROP INDEX username;ALTER TABLE user DROP KEY uni_username;ALTER TABLE user DROP INDEX uni_nickname_username; 2.6 修改表的存储引擎 1）语法： 1ALTER TABLE &lt;表名&gt; ENGINE=&lt;存储引擎名称&gt; 2）示例： 12ALTER TABLE user ENGINE=MyISAM;ALTER TABLE user ENGINE=INNODB; 2.7 修改自增长值 1）语法： 1ALTER TABLE &lt;表名&gt; AUTO_INCREMENT=[值]; 2）示例： 1ALTER TABLE user AUTO_INCREMENT= 100; 博客原文链接：https://www.cnblogs.com/Jimc/p/12979319.html 如有侵权，请联系删除！","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"TIDB设置sql_mode","slug":"sql-model","date":"2021-11-15T12:57:46.000Z","updated":"2022-04-06T09:51:44.957Z","comments":true,"path":"sql-model/","link":"","permalink":"https://xiaoyuge5201.github.io/sql-model/","excerpt":"","text":"1. 使用命令查询当前sql_mode 123select @@sql_mode-- 或者select @@GLOBAL.sql_mode sql_mode常用值： ONLY_FULL_GROUP_BY 对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中 NO_AUTO_VALUE_ON_ZERO 该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。如果用户希望插入的值为0，而该列又是自增长的，那么这个选项就有用了。 STRICT_TRANS_TABLES 在该模式下，如果一个值不能插入到一个事务中，则中断当前的操作，对非事务表不做限制 NO_ZERO_IN_DATE 在严格模式下，不允许日期和月份为零 NO_ZERO_DATE 设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告 ERROR_FOR_DIVISION_BY_ZERO 在insert或update过程中，如果数据被零除，则产生错误而非警告。如果未给出该模式，那么数据被零除时Mysql返回NULL NO_AUTO_CREATE_USER 禁止GRANT创建密码为空的用户 NO_ENGINE_SUBSTITUTION 如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常 PIPES_AS_CONCAT 将&quot;||&quot;视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样是，也和字符串的拼接函数Concat想类似 ANSI_QUOTES 启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符 2. 临时设置（新session仍然使用之前的sql_mode） 1set sql_mode=‘ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES’; 3. 全局设置（新session仍然使用修改后的sql_mode） 1set @@global.sql_mode=&#x27;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE‘；","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"tidb","slug":"tidb","permalink":"https://xiaoyuge5201.github.io/tags/tidb/"}]},{"title":"Java中将List列表转换为字符串","slug":"list-to-string","date":"2021-10-10T09:48:19.000Z","updated":"2022-03-27T14:06:03.359Z","comments":true,"path":"list-to-string/","link":"","permalink":"https://xiaoyuge5201.github.io/list-to-string/","excerpt":"","text":"1. toString() 方法 List.toString()是最简单的，但它在开头和结尾添加方括号，每个字符串用逗号分隔符分隔。 缺点是我们不能用另一个分隔符替换逗号，也不能去掉方括号 12345678910111213141516171819public class ListToStringUsingToStringExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // converting List&lt;String&gt; to String using toString() method String stringFromList = list.toString(); // priting the string System.out.println(&quot;String : &quot;+stringFromList); &#125;&#125;// 输出：String : [One, Two, Three, Four, Five] 2. Java 8 String.join() java 8 String添加了一个特殊的方法String.join()以将集合转换为具有给定分隔符的字符串 123456789101112131415161718192021222324252627public class ListToStringUsingString_JoinExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // converting List&lt;String&gt; to String using toString() method String stringFromList = String.join(&quot;~&quot;, list); // priting the string System.out.println(&quot;String with tilde delimiter: &quot;+stringFromList); // delimiting with pipe | symbol. String stringPipe = String.join(&quot;|&quot;, list); // printing System.out.println(&quot;String with pipe delimiter : &quot;+stringPipe); &#125;&#125;//输出：// String with tilde delimiter: One~Two~Three~Four~Five// String with pipe delimiter : One|Two|Three|Four|Five 3. Collectors.joining() Collectors.join()方法来自 java 8 stream api。Collctors.joining()方法将分隔符、前缀和后缀作为参数。此方法将列表转换为具有给定分隔符、前缀和后缀的字符串。 查看以下有关使用不同分隔符的 join() 方法的示例。但是，String.join() 方法不提供前缀和后缀选项。 123456789101112131415161718192021222324public class ListToStringUsingString_JoinExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // using java 8 Collectors.joining with delimiter, prefix and suffix String joiningString = list.stream().collect(Collectors.joining(&quot;-&quot;, &quot;&#123;&quot;, &quot;&#125;&quot;)); // printing System.out.println(&quot;Collectors.joining string : &quot;+joiningString); String joiningString3 = list.stream().collect(Collectors.joining(&quot;@&quot;, &quot;&quot;, &quot;&quot;)); // printing System.out.println(&quot;Collectors.joining string with @ separator : &quot;+joiningString3); &#125;&#125;//输出：//Collectors.joining string : &#123;One-Two-Three-Four-Five&#125;//Collectors.joining string with @ separator : One@Two@Three@Four@Five 4. Apache Commons StringUtils.join() 使用来自 apache commons 包的外部库。该库有一个方法StringUtils.join() ，它采用类似于 String.join() 方法的列表和分隔符 12345678910111213141516171819202122232425public class ListToStringUsingStringUtils_JoinExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // using java 8 Collectors.joining with delimiter, prefix and suffix String joiningString = StringUtils.join(list, &quot;^&quot;); // printing System.out.println(&quot;StringUtils.join string with ^ delimiter : &quot;+joiningString); String joiningString3 = StringUtils.join(list, &quot;$&quot;); // printing System.out.println(&quot;StringUtils.join string with @ separator : &quot;+joiningString3); &#125;&#125;//输出：// StringUtils.join string with ^ delimiter : One^Two^Three^Four^Five// StringUtils.join string with @ separator : One$Two$Three$Four$Five","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"集合","slug":"集合","permalink":"https://xiaoyuge5201.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"linux关机命令","slug":"shutdown","date":"2021-10-02T03:39:17.000Z","updated":"2022-03-27T14:06:03.482Z","comments":true,"path":"shutdown/","link":"","permalink":"https://xiaoyuge5201.github.io/shutdown/","excerpt":"","text":"1. shutdown命令 shutdown会给系统计划一个时间关机。它可以被用于停止、关机、重启机器。 你可以指定一个时间字符串（通常是 now或者用hh:mm 指定小时/分钟）作为第一个参数。 shutdown命令示例： 12345678910111213shutdownshutdown now #立即关机shutdown 13:20 # 下午13：20关机shutdown -p now ### 关闭机器shutdown -H now ### 停止机器 shutdown -r09:35 ### 在 09:35am 重启机器shutdown -c ## 取消关机 2. halt 命令 halt通知硬件来停止所有的 CPU 功能，但是仍然保持通电。你可以用它使系统处于低层维护状态。 注意在有些情况会它会完全关闭系统。 halt 命令示例： 12345halt ### 停止机器halt -p ### 关闭机器halt --reboot ### 重启机器 3.poweroff 命令 poweroff会发送一个 ACPI 信号来通知系统关机 12345poweroff ### 关闭机器poweroff --halt ### 停止机器poweroff --reboot ### 重启机器 4.reboot 命令 reboot 通知系统重启。 12345reboot ### 重启机器reboot --halt ### 停止机器reboot -p ### 关闭机器 5. init 命令 一. init是Linux系统操作中不可缺少的程序之一。 所谓的init进程，它是一个由内核启动的用户级进程。 内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。 内核会在过去曾使用过init的几个地方查找它，它的正确位置（对Linux系统来说）是/sbin/init。如果内核找不到init，它就会试着运行/bin/sh，如果运行失败，系统的启动也会失败。 二. init一共分为7个级别，这7个级别的所代表的含义如下 0：停机或者关机（千万不能将initdefault设置为0） 1：单用户模式，只root用户进行维护 2：多用户模式，不能使用NFS(Net File System) 3：完全多用户模式（标准的运行级别） 4：安全模式 5：图形化（即图形界面） 6：重启（千万不要把initdefault设置为6）","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"shutdown","slug":"shutdown","permalink":"https://xiaoyuge5201.github.io/tags/shutdown/"}]},{"title":"安装Centos系统以及配置IP","slug":"Installing-CentOS-system","date":"2021-10-01T08:47:11.000Z","updated":"2022-03-29T06:26:02.010Z","comments":true,"path":"Installing-CentOS-system/","link":"","permalink":"https://xiaoyuge5201.github.io/Installing-CentOS-system/","excerpt":"","text":"1. 系统安装 安装 选择语言 设置时区以及软件安装 选择GNOME桌面，开发工具。然后点击左上角的完成 配置分区，选址本地标准磁盘，并且在分区中勾选&quot;我要配置分区&quot;,“我想让额外空间可用”；初学者可以使用自动配置分区 开始安装 设置Root账户 等待安装成功,安装成功后会提示重启； 2. 永久关闭防火墙 1234567891011121314151617一、下面是red hat/CentOs7关闭防火墙的命令!#1:查看防火状态systemctl status firewalldservice iptables status#2:暂时关闭防火墙systemctl stop firewalldservice iptables stop#3:永久关闭防火墙systemctl disable firewalldchkconfig iptables off#4:重启防火墙systemctl enable firewalldservice iptables restart 3. 配置SELinux SELinux是Linux 内核中提供的强制访问控制系统。selinux有disabled、permissive、enforcing 三种选择： disabled ：不启用控制系统。 permissive：开启控制系统，但是处于警告模式。即使你违反了策略的话它让你继续操作，但是把你的违反的内容记录下来。 Enforcing：开启控制系统，处于强制状态。一旦违反了策略，就无法继续操作下去 使用命令： 12cd /etc/sysconfig/vim selinux 4.修改ip配置文件 进入文件目录 1cd /etc/sysconfig/network-scripts/ #进入配置文件 写入配置信息并保存退出 1vim ifcfg-ens33 #编辑配置文件ifcfg-ens33 如果要设置固定IP的话，常见设置属性有：BOOTPROTO、ONBOOT、IPADDR、NETMASK、GATEWAY 12345678910111213141516171819202122#以下为配置文件的内容TYPE=&quot;Ethernet&quot; #网卡类型（通常是Ethemet以太网）PROXY_METHOD=&quot;none&quot; #代理方式：为关闭状态BROWSER_ONLY=&quot;no&quot; #只是浏览器：否BOOTPROTO=&quot;static&quot; #网卡的引导协议【static：静态IP(指定静态后IP地址就固定了,不建议采用动态分配) dhcp：动态IP none：不指定，不指定容易出现各种各样的网络受限】DEFROUTE=&quot;yes&quot; #默认路由IPV4_FAILURE_FATAL=&quot;no&quot; #是否开启IPV4致命错误检测IPV6INIT=&quot;yes&quot; #IPV6是否自动初始化：是（现在还未用到IPV6，不会有任何影响）IPV6_AUTOCONF=&quot;yes&quot; #IPV6是否自动配置：是（现在还未用到IPV6，不会有任何影响）IPV6_DEFROUTE=&quot;yes&quot; #IPV6是否可以为默认路由：是（现在还未用到IPV6，不会有任何影响）IPV6_FAILURE_FATAL=&quot;no&quot; #是否开启IPV6致命错误检测IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot; #IPV6地址生成模型NAME=&quot;ens33&quot; #网卡物理设备名称UUID=&quot;ab60d501-535b-49f5-a76b-3336a4120f64&quot; #通用唯一识别码，每一个网卡都会有，不能重复，否则两台linux机器只有一台可上网,可不写DEVICE=&quot;ens33&quot; #网卡设备名称，必须和‘NAME’值一样ONBOOT=&quot;yes&quot; #是否开机启动(如果yes则开机后自动加载使用当前配置文件)，要想网卡开机就启动或通过 `systemctl restart network`控制网卡,必须设置为 `yes`IPADDR=192.168.1.111 # 本机IP 设置固定IP 对应上面的BOOTPROTONETMASK=255.255.255.0 #子网掩码 ,可不写GATEWAY=192.168.137.2 #默认网关 ,可不写DNS1=8.8.8.8 # 可不写DNS2=8.8.8.5 # 可不写ZONE=public # 可不写 重启网络服务 1service network restart #重启网卡 查看IP 1ip addr 重启系统 1reboot","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/tags/linux/"}]},{"title":"LockSupport线程工具类","slug":"locksupport","date":"2021-09-25T04:59:36.000Z","updated":"2022-11-06T09:40:35.966Z","comments":true,"path":"locksupport/","link":"","permalink":"https://xiaoyuge5201.github.io/locksupport/","excerpt":"","text":"1. 概要 LockSupport位于java.util.concurrent（简称juc）包中，是一个编程工具类， 主要是为了阻塞和唤醒线程用的。所有的方法都是静态方法，可以让线程在任意位置阻塞，也可以在任意位置唤醒 主要的方法： park(阻塞线程) 和 unpark(启动唤醒线程) 关于线程等待/唤醒的方法： 方式1：使用Object中的wait()方法让线程等待，使用Object中的notify()方法唤醒线程 使用juc包中Condition的await()方法让线程等待，使用signal()方法唤醒线程 2. wait/notify 示例1 1234567891011121314151617181920212223242526public class ObjectDemo &#123; static final Object lock = new Object(); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; synchronized (lock)&#123; System.out.println(Thread.currentThread().getName()+&quot;: &quot;+System.currentTimeMillis()+&quot; start&quot;); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+&quot;: &quot;+System.currentTimeMillis()+&quot; 被唤醒&quot;); &#125; &#125;); t1.setName(&quot;t1&quot;); t1.start(); //休眠5秒 TimeUnit.SECONDS.sleep(5); synchronized (lock)&#123; lock.notify(); &#125; &#125;&#125; 输出： 12t1: 1667620040963 startt1: 1667620045967 被唤醒 t1 线程调用lock.wait()方法让t1线程等待，主线程休眠5s后，调用lock.notify()方法唤醒t1线程，然后输出信息，程序正常退出。 示例2 如果将上面代码块中的两个synchronized去掉，发现调用wait()方法和notify()方法都会报错 12345678910111213141516171819202122public class ObjectDemo &#123; static final Object lock = new Object(); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;: &quot; + System.currentTimeMillis() + &quot; start&quot;); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;: &quot; + System.currentTimeMillis() + &quot; 被唤醒&quot;); &#125;); t1.setName(&quot;thread1&quot;); t1.start(); //休眠5秒 TimeUnit.SECONDS.sleep(5); lock.notify(); &#125;&#125; 123456789thread1: 1667624638968 startException in thread &quot;thread1&quot; java.lang.IllegalMonitorStateException at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at org.example.ObjectDemo.lambda$main$0(ObjectDemo.java:13) at java.lang.Thread.run(Thread.java:748)Exception in thread &quot;main&quot; java.lang.IllegalMonitorStateException at java.lang.Object.notify(Native Method) at org.example.ObjectDemo.main(ObjectDemo.java:27) 原因： Object类中的wait、notify、notifyAll用于线程等待和唤醒的方法，都必须在同步代码块中运行（必须使用关键字synchronized） 示例3 唤醒方法在等待方法之前 1234567891011121314151617181920212223242526272829303132public class ObjectDemo &#123; static final Object lock = new Object(); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (lock)&#123; System.out.println(Thread.currentThread().getName()+&quot;: &quot;+System.currentTimeMillis()+&quot; start&quot;); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+&quot;: &quot;+System.currentTimeMillis()+&quot; 被唤醒&quot;); &#125; &#125;); t1.setName(&quot;thread1&quot;); t1.start(); //休眠5秒 TimeUnit.SECONDS.sleep(1); synchronized (lock)&#123; lock.notify(); &#125; System.out.println(&quot;lock.notify 执行完毕&quot;); &#125;&#125; 输出： 12lock.notify 执行完毕thread1: 1667625571660 start 输出上面2行之后，程序一直无法结束，t1线程调用wait()方法之前先调用了notify()方法，导致等待的线程无法被唤醒了 唤醒方法在等待方法之前执行，线程无法被唤醒，将上面休眠1s的时间改成大于线程中休眠的时间即可； 关于Object类中的用户线程等待和唤醒的方法，总结一下： wait()/notify()/notifyAll()方法都必须放在同步代码（必须在synchronized内部执行）中执行，需要先获取锁 线程唤醒的方法（notify、notifyAll）需要在等待的方法（wait）之后执行，等待中的线程才可能会被唤醒，否则无法唤醒 3. condition实现线程等待和唤醒 示例1 1234567891011121314151617181920212223242526272829303132public class ConditionDemo &#123; static ReentrantLock lock = new ReentrantLock(); static Condition condition = lock.newCondition(); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; start&quot;); try &#123; condition.await(); //进入等待 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; 被唤醒&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;); t1.setName(&quot;t1&quot;); t1.start(); //休眠5秒 TimeUnit.SECONDS.sleep(5); lock.lock(); try &#123; condition.signal(); //唤醒 t1线程 &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 输出： 12t1:1667712939347 startt1:1667712944350 被唤醒 t1 线程制动之后，调用condition.await()方法将线程处于等待中，主线程休眠5秒之后调用condition.signal()方法将t1线程唤醒； 示例2 1234567891011121314151617181920212223242526public class ConditionDemo &#123; static ReentrantLock lock = new ReentrantLock(); static Condition condition = lock.newCondition(); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; start&quot;); try &#123; condition.await(); //进入等待 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; 被唤醒&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;); t1.setName(&quot;t1&quot;); t1.start(); //休眠5秒 TimeUnit.SECONDS.sleep(5); condition.signal(); //唤醒 t1线程 &#125;&#125; 输出： 12345678910t1:1667713155895 startException in thread &quot;t1&quot; java.lang.IllegalMonitorStateException at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:151) at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1261) at java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:457) at org.example.ConditionDemo.lambda$main$0(ConditionDemo.java:23) at java.lang.Thread.run(Thread.java:748)Exception in thread &quot;main&quot; java.lang.IllegalMonitorStateException at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.signal(AbstractQueuedSynchronizer.java:1939) at org.example.ConditionDemo.main(ConditionDemo.java:30) 有异常发生， condition.await();和 condition.signal();都触发了 IllegalMonitorStateException异常。 原因：调用condition中线程等待和唤醒的方法的前提是必须要先获取lock的锁。 示例3 唤醒代码在等待之前执行 123456789101112131415161718192021222324252627282930313233343536373839public class ConditionDemo &#123; static ReentrantLock lock = new ReentrantLock(); static Condition condition = lock.newCondition(); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; try &#123; System.out.println(&quot;进入线程t1&quot;); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; start&quot;); try &#123; condition.await(); //进入等待 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; 被唤醒&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;); t1.setName(&quot;t1&quot;); t1.start(); //休眠5秒 TimeUnit.SECONDS.sleep(1); lock.lock(); try&#123; condition.signal(); //唤醒 t1线程 &#125;finally &#123; lock.unlock(); &#125; System.out.println(System.currentTimeMillis() +&quot; condition.signal;执行完毕&quot;); &#125;&#125; 输出： 123进入线程t11667714134893 condition.signal;执行完毕t1:1667714138893 start 输出上面2行之后，程序无法结束，代码结合输出可以看出signal()方法在await()方法之前执行的，最终t1线程无法被唤醒，导致程序无法结束。 关于Condition中方法使用总结： 使用Condition中的线程等待和唤醒方法之前，需要先获取锁。否者会报 IllegalMonitorStateException异常 signal()方法先于await()方法之前调用，线程无法被唤醒 Object和Condition的局限性 Object和Condition的局限性 关于Object和Condtion中线程等待和唤醒的局限性，有以下几点： 2种方式中的让线程等待和唤醒的方法能够执行的先决条件是：线程需要先获取锁 唤醒方法需要在等待方法之后调用，线程才能够被唤醒 关于这2点，LockSupport都不需要，就能实现线程的等待和唤醒。下面我们来说一下LockSupport类。 4. LockSupport LockSupport类可以阻塞当前线程以及唤醒指定被阻塞的线程，主要是通过park()和unpark(thread)方法来实现阻塞和唤醒线程操作的 每个线程都有一个许可（permit），permit只有两个值 1 和 0（默认） 当调用unpark(thread)方法，就会将thread线程的许可permit设置为1（多次调用结果一致） 当嗲用park()方法，如果当前线程的permit是1， 那么将permit 设置为0，并立即返回；如果当前park方法会被唤醒，然后会将permit再次设置为0，并返回； 注意：因为permit默认是0，所以一开始调用park()方法，线程必定会被阻塞。调用unpark(thread)方法后，会自动唤醒thread线程，即park方法立即返回。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151//源码package java.util.concurrent.locks;import sun.misc.Unsafe; public class LockSupport &#123; private LockSupport() &#123;&#125; // Cannot be instantiated. private static void setBlocker(Thread t, Object arg) &#123; // Even though volatile, hotspot doesn&#x27;t need a write barrier here. UNSAFE.putObject(t, parkBlockerOffset, arg); &#125; /** * @param thread the thread to unpark, or &#123;@code null&#125;, in which case * this operation has no effect */ public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread); &#125; /** * 阻塞当前线程 * blocker是用来记录线程被阻塞时被谁阻塞的。用于线程监控和分析工具来定位原因的。 * @param blocker the synchronization object responsible for this * thread parking * @since 1.6 */ public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); //setBlocker作用是记录t线程是被broker阻塞的 setBlocker(t, blocker); //UNSAFE是一个非常强大的类，他的的操作是基于底层的 UNSAFE.park(false, 0L); setBlocker(t, null); &#125; /** * 暂停当前线程，有超时时间 * blocker是用来记录线程被阻塞时被谁阻塞的。用于线程监控和分析工具来定位原因的。 * @param blocker the synchronization object responsible for this * thread parking * @param nanos the maximum number of nanoseconds to wait * @since 1.6 */ public static void parkNanos(Object blocker, long nanos) &#123; if (nanos &gt; 0) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, nanos); setBlocker(t, null); &#125; &#125; /** * 暂停当前线程，知道某个时间 * blocker是用来记录线程被阻塞时被谁阻塞的。用于线程监控和分析工具来定位原因的。 * @param blocker the synchronization object responsible for this * thread parking * @param deadline the absolute time, in milliseconds from the Epoch, * to wait until * @since 1.6 */ public static void parkUntil(Object blocker, long deadline) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(true, deadline); setBlocker(t, null); &#125; /** * Returns the blocker object supplied to the most recent * invocation of a park method that has not yet unblocked, or null * if not blocked. The value returned is just a momentary * snapshot -- the thread may have since unblocked or blocked on a * different blocker object. * * @param t the thread * @return the blocker * @throws NullPointerException if argument is null * @since 1.6 */ public static Object getBlocker(Thread t) &#123; if (t == null) throw new NullPointerException(); return UNSAFE.getObjectVolatile(t, parkBlockerOffset); &#125; /** * 无期限暂停当前线程 */ public static void park() &#123; UNSAFE.park(false, 0L); &#125; /** * 暂停当前线程，不过有超时时间限制 */ public static void parkNanos(long nanos) &#123; if (nanos &gt; 0) UNSAFE.park(false, nanos); &#125; /** * 暂停当前线程，知道某个时间 * @param deadline 暂停结束时间 */ public static void parkUntil(long deadline) &#123; UNSAFE.park(true, deadline); &#125; /** * Returns the pseudo-randomly initialized or updated secondary seed. * Copied from ThreadLocalRandom due to package access restrictions. */ static final int nextSecondarySeed() &#123; int r; Thread t = Thread.currentThread(); if ((r = UNSAFE.getInt(t, SECONDARY)) != 0) &#123; r ^= r &lt;&lt; 13; // xorshift r ^= r &gt;&gt;&gt; 17; r ^= r &lt;&lt; 5; &#125; else if ((r = java.util.concurrent.ThreadLocalRandom.current().nextInt()) == 0) r = 1; // avoid zero UNSAFE.putInt(t, SECONDARY, r); return r; &#125; // Hotspot implementation via intrinsics API private static final sun.misc.Unsafe UNSAFE; private static final long parkBlockerOffset; private static final long SEED; private static final long PROBE; private static final long SECONDARY; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; tk = Thread.class; parkBlockerOffset = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;parkBlocker&quot;)); SEED = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSeed&quot;)); PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomProbe&quot;)); SECONDARY = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSecondarySeed&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125;&#125; 4.1 示例 示例一 主线程线程等待5秒之后，唤醒t1线程 123456789101112131415public class LockSupportDemo1 &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; start&quot;); LockSupport.park();//阻塞当前线程 System.out.println(Thread.currentThread().getName() + &quot;:&quot; + System.currentTimeMillis() + &quot; 被唤醒&quot;); &#125;); t1.setName(&quot;t1&quot;); t1.start(); //休眠5秒 TimeUnit.SECONDS.sleep(5); LockSupport.unpark(t1); System.out.println(System.currentTimeMillis() + &quot; lock.unpart 执行完毕&quot;); &#125;&#125; 输出： 123t1:1667727256993 start1667727261994 lock.unpart 执行完毕t1:1667727261994 被唤醒 t1 中调用LockSupport.park()方法让当前线程t1等待，主线程休眠5秒后，调用LockSupport.unpart(t1)将线程唤醒 LockSupport.park();无参数，内部直接会让当前线程处于等待中；unpark方法传递了一个线程对象作为参数，表示将对应的线程唤醒。 4.3 先interrupt在park 12345678910111213141516171819202122232425public class LockSupportTest &#123; public static class MyThread extends Thread&#123; @Override public void run() &#123; System.out.println(getName() + &quot;进入线程&quot;); LockSupport.park(); System.out.println(&quot;运行结束&quot;); System.out.println(&quot;是否中断：&quot;+Thread.currentThread().isInterrupted()); &#125; &#125; public static void main(String[] args) &#123; MyThread thread = new MyThread(); thread.start(); System.out.println(&quot;线程启动了，但是在内部进行了park&quot;); thread.interrupt(); System.out.println(&quot;main 线程结束&quot;); &#125;&#125;//输出// 线程启动了，但是在内部进行了park// main 线程结束// Thread-0进入线程// 运行结束 4.2 先park在interrupt 1234567891011121314151617181920public static class MyThread extends Thread&#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(getName() + &quot;进入线程&quot;); LockSupport.park(); System.out.println(&quot;运行结束&quot;); &#125;&#125;/** * 输出： * 线程启动了，但是在内部进行了park * main 线程结束 * Thread-0进入线程 * 运行结束 */ 5. 线程等待和唤醒方式对比 方式1：Object中的wait、notify、notifyAll方法 方式2：juc中Condition接口提供的await、signal、signalAll方法 方式3：juc中的LockSupport提供的park、unpark方法 LockSupport是用来阻塞和环线线程的，wait/notify同样也是，那么两者的区别是什么？ wait和notify都是Object中的方法，在调用这两个方法前必须获得锁对象，但是park不需要获取某个对象的锁就可以锁住线程 notify只能随机选择一个线程唤醒，无法唤醒指定的线程，unpark可以唤醒一个指定的线程 6. 趣味题 用两个线程，一个输出字母，一个输出数字交替输出如：1A2B3C4D… 1234567891011121314151617181920212223242526public class ThreadDemoTest &#123; static Thread t1 = null, t2 = null; public static void main(String[] args) &#123; char[] a = &quot;1234567&quot;.toCharArray(); char[] b = &quot;ABCDEFG&quot;.toCharArray(); t1 = new Thread(() -&gt; &#123; for (char i : a) &#123; System.out.print(i); LockSupport.unpark(t2); LockSupport.park(); &#125; &#125;, &quot;t1&quot;); t2 = new Thread(() -&gt; &#123; for (char i : b) &#123; LockSupport.park(); System.out.print(i); LockSupport.unpark(t1); &#125; &#125;, &quot;t1&quot;); t1.start(); t2.start(); &#125;&#125;//输出： 1A2B3C4D5E6F7G 使用自旋锁也可以实现上面的结果 12345678910111213141516171819202122232425262728public class CasTest &#123; //定义枚举，包含两个变量 enum ReadyToRun&#123;T1, T2&#125;; static volatile ReadyToRun r = ReadyToRun.T1; public static void main(String[] args) &#123; char[] a = &quot;1234567&quot;.toCharArray(); char[] b = &quot;ABCDEFG&quot;.toCharArray(); new Thread(()-&gt;&#123; for (char c : a)&#123; //当r不为T1时， 空转占着cpu等待，然后输出字符，将r的值设置为T2 while (r != ReadyToRun.T1)&#123;&#125; System.out.print(c+&quot; &quot;); r = ReadyToRun.T2; &#125; &#125;,&quot;t1&quot;).start(); new Thread(()-&gt;&#123; for (char c : b)&#123; while (r != ReadyToRun.T2)&#123;&#125; System.out.print(c+&quot; &quot;); r = ReadyToRun.T1; &#125; &#125;,&quot;t2&quot;).start(); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"thread","slug":"thread","permalink":"https://xiaoyuge5201.github.io/tags/thread/"}]},{"title":"mysql行列转置","slug":"mysql行列转置","date":"2021-08-25T02:36:37.000Z","updated":"2022-04-06T09:51:44.953Z","comments":true,"path":"mysql行列转置/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql%E8%A1%8C%E5%88%97%E8%BD%AC%E7%BD%AE/","excerpt":"","text":"数据表： 行转列结果为： 数据库表语句： 1234567891011121314151617181920create table t_score( id int primary key auto_increment, name varchar(20) not null, #名字 Subject varchar(10) not null, #科目 Fraction double default 0 #分数);INSERT INTO `t_score`(name,Subject,Fraction) VALUES (&#x27;王海&#x27;, &#x27;语文&#x27;, 86), (&#x27;王海&#x27;, &#x27;数学&#x27;, 83), (&#x27;王海&#x27;, &#x27;英语&#x27;, 93), (&#x27;陶俊&#x27;, &#x27;语文&#x27;, 88), (&#x27;陶俊&#x27;, &#x27;数学&#x27;, 84), (&#x27;陶俊&#x27;, &#x27;英语&#x27;, 94), (&#x27;刘可&#x27;, &#x27;语文&#x27;, 80), (&#x27;刘可&#x27;, &#x27;数学&#x27;, 86), (&#x27;刘可&#x27;, &#x27;英语&#x27;, 88), (&#x27;李春&#x27;, &#x27;语文&#x27;, 89), (&#x27;李春&#x27;, &#x27;数学&#x27;, 80), (&#x27;李春&#x27;, &#x27;英语&#x27;, 87); 方法一：使用if 12345678910111213141516171819select name as 名字 , sum(if(Subject=&#x27;语文&#x27;,Fraction,0)) as 语文, sum(if(Subject=&#x27;数学&#x27;,Fraction,0))as 数学, sum(if(Subject=&#x27;英语&#x27;,Fraction,0))as 英语, round(AVG(Fraction),2) as 平均分, SUM(Fraction) as 总分from t_score group by name-- 如果不用求总分的话，不需要下面的unionunion( select name as 名字 , sum(语文) Chinese,sum(数学) Math,sum(英语) English,round(AVG(总分),2)as 平均分,sum(总分) score from( select &#x27;TOTAL&#x27; as name, sum(if(Subject=&#x27;语文&#x27;,Fraction,0)) as 语文, sum(if(Subject=&#x27;数学&#x27;,Fraction,0))as 数学, sum(if(Subject=&#x27;英语&#x27;,Fraction,0))as 英语, SUM(Fraction) as 总分 from t_score group by Subject )t GROUP BY t.`name`) 方法二：使用case 1234567891011121314151617select name as name,sum(case when Subject = &#x27;语文&#x27; then Fraction end) as Chinese,sum(case when Subject = &#x27;数学&#x27; then Fraction end) as Math,sum(case when Subject = &#x27;英语&#x27; then Fraction end) as English,sum(fraction)as scorefrom t_score group by name-- 如果不用求总分的话，不需要下面的unionUNION ALL( select name as Name,sum(Chinese) as Chinese,sum(Math) as Math,sum(English) as English,sum(score) as score from( select &#x27;TOTAL&#x27; as name, sum(case when Subject = &#x27;语文&#x27; then Fraction end) as Chinese, sum(case when Subject = &#x27;数学&#x27; then Fraction end) as Math, sum(case when Subject = &#x27;英语&#x27; then Fraction end) as English, sum(fraction)as score from t_score group by Subject,name)t GROUP BY t.`name`) 方法三：使用with rollup 在group分组字段的基础上在进行统计数据； 12345678select -- coalesce(name,&#x27;TOTAL&#x27;) name, ifnull(name,&#x27;TOTAL&#x27;) name, sum(if(Subject=&#x27;语文&#x27;,Fraction,0)) as 语文, sum(if(Subject=&#x27;英语&#x27;,Fraction,0)) as 英语, sum(if(Subject=&#x27;数学&#x27;,Fraction,0))as 数学, sum(Fraction) 总分from t_score group by name with rollup","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"转换成小写字母","slug":"algoright-2","date":"2021-08-22T05:15:12.000Z","updated":"2022-03-27T14:06:03.431Z","comments":true,"path":"algoright-2/","link":"","permalink":"https://xiaoyuge5201.github.io/algoright-2/","excerpt":"","text":"实现函数 ToLowerCase()，该函数接收一个字符串参数 str，并将该字符串中的大写字母转换成小写字母，之后返回新的字符串。 1234567示例 1：输入: &quot;Hello&quot;输出: &quot;hello&quot;示例2：输入: &quot;LOVELY&quot;输出: &quot;lovely&quot; 方法一： ASCCII码 解题思路：通过ascii码表操作字符串即可,a和A相差32； a-z: 97 - 122 A-Z: 65 - 90 0-9: 48 - 57 123456789101112131415public static String toLowerCase(String str) &#123; if (str == null || str.length() == 0) &#123; return str; &#125; StringBuilder sb = new StringBuilder(); for (char ch : str.toCharArray()) &#123; // a-z：97-122 A-Z：65-90 0-9：48-57 if (ch &gt;= &#x27;A&#x27; &amp;&amp; ch &lt;= &#x27;Z&#x27;) &#123; sb.append((char)(ch + 32)); &#125; else &#123; sb.append(ch); &#125; &#125; return sb.toString();&#125; 或者： 123456789101112public static String toLowerCase(String str) &#123; if (str == null || str.length() == 0) &#123; return str; &#125; char[] ch = str.toCharArray(); for (int i = 0; i &lt; str.length(); i++) &#123; if (ch[i] &gt;= &#x27;A&#x27; &amp;&amp; ch[i] &lt;= &#x27;Z&#x27;) &#123; ch[i] += 32; &#125; &#125; return String.valueOf(ch);&#125; 方法二： 位运算 解题思路： 大写变小写、小写变大写：字符 ^= 32; 大写变小写、小写变小写：字符 |= 32; 大写变大写、小写变大写：字符 &amp;= 33; ASCII码表中大写的A是65，小写的a是97，它们的差是32 65 | 32 转为二进制（按8位来算）可以得到 0100 0001 | 0010 0000 = 0110 0001 = 97 = a 12345678910public String toLowerCase(String str) &#123; if (str == null || str.length() == 0) &#123; return str; &#125; char[] ch = str.toCharArray(); for (int i = 0; i &lt; str.length(); i++) &#123; ch[i] |= 32; &#125; return String.valueOf(ch);&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"}]},{"title":"mysqldumpslow分析慢查询日志","slug":"mysqldumpslow分析慢查询日志","date":"2021-08-21T08:16:02.000Z","updated":"2022-04-06T09:51:44.950Z","comments":true,"path":"mysqldumpslow分析慢查询日志/","link":"","permalink":"https://xiaoyuge5201.github.io/mysqldumpslow%E5%88%86%E6%9E%90%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97/","excerpt":"","text":"按照平均查询输出5行慢查询记录 1mysqldumpslow -s at -t 5 /phpstudy/data/slowquery.log -s 排序方式，可选值有c（记录次数）、t（查询时间）、l（锁定时间）、r（返回记录）、a（平均） -t 显示的记录数Spawn failed解决方式 -g 后面跟正则表达式（如 left join），不区分大小写。 -r 正序排序，即从小到大排序。 -d 调试 debug -v 查看版本 按照平均查询时间排序且只显示含有left join的记录 1mysqldumpslow -s at -g &#x27;left join&#x27; /phpstudy/data/slowquery.log","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"mysql索引","slug":"mysql-index","date":"2021-08-20T07:12:00.000Z","updated":"2022-04-06T09:51:44.939Z","comments":true,"path":"mysql-index/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql-index/","excerpt":"","text":"拿汉语字典的目录页（索引）打比方，我们可以按拼音、笔画、偏旁部首等排序的目录（索引）快速查找到需要的字。 索引分单列索引和组合索引。 单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。 组合索引，即一个索引包含多个列。 创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。 实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。 上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点： 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 建立索引会占用磁盘空间的索引文件。 1.普通索引 创建索引 12-- 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。CREATE INDEX indexName on table_name (column_name ) 添加索引（修改表结构） 12-- 表结构已经存在了，然后使用alter修改表结构添加索引alter table table_name add INDEX indexName(column_name ) 创建表指定 12345CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引 1drop index [indexName] on table_name 2. 唯一索引 他和普通索引类似，不同的是：索引列的值必须唯一，但允许有控制。如果是组合索引，则列值的组合必须唯一。 创建索引 1CREATE UNIQUE INDEX indexName ON table_name (column_name (length )) 修改表结构 1ALTER table mytable ADD UNIQUE [indexName] (column_name(length)) 创建表的时候指定 12345CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 3.组合索引 修改表结构指定索引 1ALTER TABLE table_name ADD INDEX indexName (column_name1 , column_name2,...) 创建表的时候指定 12345CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, KEY [indexName] (column_name1 , column_name2,...) ); 3.1 组合索引查询问题 问题描述：在mysql中有张表test_a，有3个字段id,name,num；对这三个字段建立组合索引，那么查询时使用其中某两个或者一个作为查询条件，是否还会走索引 根据查询字段的位置不同来决定，如查询id、id,num、id,num,name、 id, name 都可以走索引的，其他条件的查询不能走索引。 组合索引 有“最左前缀”原则。就是只从最左面的开始组合，并不是所有只要含有这三列存在的字段的查询都会用到该组合索引 12-- 添加组合索引ALTER TABLE test_a ADD INDEX &#x27;lianhe&#x27;(id, num, name) 使用三个字段id, num, name查询 123-- 只要三个条件都有，可以随意变换位置，结果都会走索引-- 优化器会将条件顺序优化成上面三种情况后执行EXPLAIN SELECT * FROM test_a WHERE id=1 AND num=&#x27;001&#x27; AND name = &#x27;1#&#x27; 从执行结果上可以看到是从走索引进行查询的 使用num, name 查询 123EXPLAIN SELECT * FROM test_a WHERE name = &#x27;1#&#x27;EXPLAIN SELECT * FROM test_a WHERE num=&#x27;001&#x27; 3. 使用id, name或者id, num 查询 1234-- 只要包括id，可以随意变换位置，结果都会走索引-- 优化器会将条件顺序优化成上面三种情况后执行--如果只有两个字段，只有id条件命中，num或者name 条件不走联合索引。EXPLAIN SELECT * FROM test_a WHERE id=1 AND name = &#x27;1#&#x27; 需要避免索引失效的情况，如：LIKE %xxx，或者条件中使用函数等。 4. 使用id查询 1EXPLAIN SELECT * FROM test_a WHERE id=1 使用name或者num查询 123EXPLAIN SELECT * FROM test_a WHERE name = &#x27;1#&#x27;EXPLAIN SELECT * FROM test_a WHERE num = &#x27;001&#x27; 3.2 创建组合索引选择规则 经常用的列优先（最左匹配原则） 离散度高的列优先（离散度高原则） 宽度小的列优先（最少空间原则） 4.使用alter命令添加索引 1234567891011-- 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): -- 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。ALTER TABLE tbl_name ADD UNIQUE index_name (column_list):-- 添加普通索引，索引值可出现多次。ALTER TABLE tbl_name ADD INDEX index_name (column_list):--该语句指定了索引为 FULLTEXT ，用于全文索引。ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"二分查找","slug":"algorithm","date":"2021-08-19T14:54:43.000Z","updated":"2022-03-27T14:06:03.470Z","comments":true,"path":"algorithm/","link":"","permalink":"https://xiaoyuge5201.github.io/algorithm/","excerpt":"","text":"二分法查找是一种基于比较目标值和数组中间元素的算法 如果目标值 = 中间值，则找到目标值 如果目标值 &lt; 中间值，则在左侧继续搜索 如果目标值 &gt; 中间值，则在右侧继续搜索 解题思路： 初始化指针left = 0, right=n-1; 当left &lt;= right： 比较中间元素nums[pivot]和目标值target 1.target = nums[pivot], 返回pivot 2.target &gt; nums[pivot], 则在右侧继续搜索left = pivot+1 3.target &lt; nums[pivot], 则在左侧继续搜索right = pivot+1 123456789101112131415161718192021/** * 给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target ， * 写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。 * 输入: nums = [-1,0,3,5,9,12], target = 9 * 输出: 4 * 解释: 9 出现在 nums 中并且下标为 4 */public int search(int[] nums, int target)&#123; int pivot, left =0, right = nums.length - 1; while (left &lt;= right)&#123; pivot = left + (right - left) / 2; if (nums[pivot] == target)&#123; return pivot; &#125;else if (nums[pivot] &lt; target)&#123; left = pivot + 1; &#125; else&#123; right = pivot - 1; &#125; &#125; return -1;&#125; 复杂度分析： 时间复杂度：O(logN) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"}]},{"title":"springboot读取yml配置的方式","slug":"springboot-yml","date":"2021-08-18T13:41:24.000Z","updated":"2022-09-18T08:22:37.681Z","comments":true,"path":"springboot-yml/","link":"","permalink":"https://xiaoyuge5201.github.io/springboot-yml/","excerpt":"","text":"springboot项目中默认的配置文件是application.properties； 1.yml文件规则 树状结构，结构清晰 不支持tab缩进 可以使用&quot;_“或”-&quot;消协字母代替大写字母；如userName 与user-name， user_name含义是一样的（宽松绑定原则 relaxed binding）; key: value格式书写，value前面有个空格 2. 数据格式 普通的值（数字，字符串，布尔）如： 123port: 123 name: abc flag: true 字符串默认不用加上单引号或者双引号； “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思,name: “zhangsan \\n lisi”：输出；zhangsan 换行 lisi ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据,name: ‘zhangsan \\n lisi’：输出；zhangsan \\n lisi 对象、Map(属性和值)如： 1234567#k: v：在下一行来写对象的属性和值的关系；注意缩进(不支持tab,使用空格)server: port: 8123 tomcat: uri-encoding: utf-8 servlet: context-path: /app 数组（list， set） 1234#用- 值表示数组中的一个元素hands: - left - right 3. 读取方式 @Value注解 12server: port: 8081 12@Value(&quot;$&#123;server.port&#125;&quot;)public String port; 此处的port所在的类需要是一个组件,如果是实体类需要加上@Component @ConfigurationProperties 需要一个JavaBean 来专门映射配置的话,我们一般会使用@ConfigurationProperties来读取. 使用的使用需要@EnableConfigurationProperties注解让类被springboot扫描到； 1234567spring: datasource: druid: url: jdbc:mysql://localhost:3307/app?useUnicode=yes&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;useLegacyDatetimeCode=false driver-class-name: com.mysql.jdbc.Driver username: root password: root 1234567891011//prefix 指定前缀@ConfigurationProperties(prefix = &quot;spring.datasource&quot;)public class MyDataSourceProperties &#123; private String type; private String driverClassName; private String url; private String username; private String password; //省略getter setter方法&#125; 前缀定义了哪些外部属性将绑定到类的字段上 根据 Spring Boot 宽松的绑定规则，类的属性名称必须与外部属性的名称匹配 我们可以简单地用一个值初始化一个字段来定义一个默认值 类本身可以是包私有的 类的字段必须有公共 setter 方法 Environment Spring Environment bean 123456789101112@RestController@RequestMapping(&quot;/test&quot;)public class TestC &#123; @Autowired private Environment env; @RequestMapping(value = &quot;index&quot;, method = RequestMethod.GET) public String index() &#123; return &quot;environment : &quot;+ env.getProperty(&quot;spring.datasource.druid.url&quot;); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://xiaoyuge5201.github.io/tags/springboot/"}]},{"title":"Hexo部署出现错误Error Spawn failed解决方式","slug":"hexo-spawn-failed","date":"2021-08-15T10:28:42.000Z","updated":"2022-05-05T01:29:32.331Z","comments":true,"path":"hexo-spawn-failed/","link":"","permalink":"https://xiaoyuge5201.github.io/hexo-spawn-failed/","excerpt":"","text":"部署过程中可能会出现错误: 123456789101112remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: unable to access &#x27;https://github.com/xiaoyuge5201/xiaoyuge5201.github.io.git/&#x27;: The requested URL returned error: 403FATAL &#123; err: Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (/Users/xiaoyuge/workspace/mybolg/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (events.js:315:20) at Process.ChildProcess._handle.onexit (internal/child_process.js:277:12) &#123; code: 128 &#125;&#125; Something&#x27;s wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.htmlxiaoyuge@xiaoyugedeMacBook-Pro mybolg % hexo clean ####解决方式一： 1234567891011##进入站点根目录cd cd /Users/xiaoyuge/workspace/mybolg##删除git提交内容文件夹rm -rf .deploy_git/##执行git config --global core.autocrlf false##最后hexo clean &amp;&amp; hexo g &amp;&amp; hexo d ####解决方式二： 有可能是你的git repo配置地址不正确,可以将http方式变更为ssh方式（我的就是这个问题） github在2021-08-13正式启用personal access token后，原来的用户名+密码方式部署会报错，需要采用最新的token登录方式进行部署 。 具体方式参考：https://cloud.tencent.com/developer/article/1861466 1remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead. 查看_config.yml文件， 12345deploy: type: git #repo:https://github.com/xiaoyuge5201/xiaoyuge5201.github.io.git 这是原来的路径，现在改成了下面这种 repo: git@github.com:xiaoyuge5201/xiaoyuge5201.github.io.git branch: master","categories":[{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/tags/hexo/"}]},{"title":"Java守护线程和非守护线程","slug":"thread-01","date":"2021-08-15T06:14:56.000Z","updated":"2022-03-27T14:06:03.452Z","comments":true,"path":"thread-01/","link":"","permalink":"https://xiaoyuge5201.github.io/thread-01/","excerpt":"","text":"用户线程：我们平常创建的普通线程。 守护线程：用来服务于用户线程；不需要上层逻辑介入 java线程分为守护线程和非守护线程，当java jvm检测主线程或其他子线程执行完之后，守护线程也会马上停止执行，我们可以使用Thread.setDaemon(ture或false)来设置一个线程是守护线程还是非守护线程，默认为false，可以通过Thread.isDaemon()方法查询该线程是否是守护线程 守护线程是所有的用户线程结束生命周期，守护线程才会结束生命周期，只要有一个用户线程存在，那么守护线程就不会结束，例如Java中的垃圾 回收器就是一个守护线程，只有应用程序中所有的线程结束，它才会结束。 123456789101112131415161718192021public class DaemonThread &#123; public static void main(String[] args) &#123; Thread thread = new Thread(DaemonThread::print); thread.setDaemon(true); thread.start(); System.out.println(&quot;主线程main 结束&quot;); &#125; public static void print() &#123; int counter = 1; //写一个死循环的方法来测试 while (true) &#123; try &#123; System.out.println(&quot;Counter:&quot; + counter++); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 输出： 12主线程main 结束Counter:1 如果我们将daemon设置为非守护线程，代码如下: 1thread.setDaemon(false); 这个时候就不会退出while(true)循环了，会一直执行下去，结果如下： 1234567主线程main 结束Counter:1Counter:2Counter:3Counter:4Counter:5.... 总结：守护线程是为用户线程服务的，当用户线程全部结束，守护线程会自动结束。 注意事项： thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。 在Daemon线程中产生的新线程也是Daemon的。 守护线程不能用于去访问固有资源，比如读写操作或者计算逻辑。因为它会在任何时候甚至在一个操作的中间发生中断。 Java自带的多线程框架，比如ExecutorService，会将守护线程转换为用户线程，所以如果要使用后台线程就不能用Java的线程池。 意义以及应用场景: 当主线程结束时，结束其余的子线程（守护线程）自动关闭，就免去了还要继续关闭子线程的麻烦。如：Java垃圾回收线程就是一个典型的守护线程；内存资源或者线程的管理，但是非守护线程也可以。","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"守护线程","slug":"守护线程","permalink":"https://xiaoyuge5201.github.io/tags/%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B/"}]},{"title":"redis常见使用场景","slug":"redis-usage-scenario","date":"2021-08-14T09:51:30.000Z","updated":"2022-03-27T14:06:03.486Z","comments":true,"path":"redis-usage-scenario/","link":"","permalink":"https://xiaoyuge5201.github.io/redis-usage-scenario/","excerpt":"","text":"1. 缓存 String类型 例如：热点数据缓存、对象缓存、全页缓存可以提升热点数据的访问效率 2. 数据共享分布式 String类型，因为redis是分布式的独立服务，可以在多个应用服务之间共享，例如分布式session 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 3. 分布式锁 String类型 setnx方法，只有不存在时才能添加成功返回true 1234567891011public static boolean getLock(String key) &#123; Long flag = jedis.setnx(key, &quot;1&quot;); if (flag == 1) &#123; jedis.expire(key, 10); &#125; return flag == 1;&#125;public static void releaseLock(String key) &#123; jedis.del(key);&#125; 4. 全局ID int 类型， incrby, 利用原子性 1incrby userid 1000 分库分表的场景，一次性拿一段。 5. 计数器 int 类型，incr方法 例如：文章的阅读量、微博点赞数；允许一定的延迟，先写入redis在定时同步到数据库 第一种方法 12345678910111213141516171819202122232425@Servicepublic class TestService &#123; @Resource RedisTemplate&lt;String,Object&gt; redisTemplate; @Resource(name=&quot;redisTemplate&quot;) private ValueOperations&lt;String,Object&gt; ops; public int testRedis() &#123; try &#123; //此方法会先检查key是否存在，存在+1，不存在先初始化，再+1 ops.increment(&quot;success&quot;, 1); //return (int) ops.get(&quot;success&quot;); //使用这个会出现错误，报错信息 Caused by: org.springframework.core.serializer.support.SerializationFailedException: Failed to deserialize payload. Is the byte array a result of corresponding serialization for DefaultDeserializer?; nested exception is java.io.EOFException。 return Integer.valueOf(redisTemplate.boundValueOps(&quot;success&quot;).get(0, -1)); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125; return 0 ; &#125; &#125; 第二种方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Servicepublic class TestService &#123; @Resource RedisTemplate&lt;String,Object&gt; redisTemplate; @Resource(name=&quot;redisTemplate&quot;) private ValueOperations&lt;String,Object&gt; ops; public int testRedis() &#123; try &#123; //此方法会先检查key是否存在，存在+1，不存在先初始化，再+1 ops.increment(&quot;success&quot;, 1); //return (int) ops.get(&quot;success&quot;); //return Integer.valueOf(redisTemplate.boundValueOps(&quot;success&quot;).get(0, -1)); return (int) getKey(&quot;success&quot;); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125; return 0 ; &#125; public long getKey(final String key) &#123; return redisTemplate.execute(new RedisCallback&lt;Long&gt;() &#123; @Override public Long doInRedis(RedisConnection connection) throws DataAccessException &#123; RedisSerializer&lt;String&gt; redisSerializer = redisTemplate.getStringSerializer(); byte[] rowkey = redisSerializer.serialize(key); byte[] rowval = connection.get(rowkey); try &#123; String val = redisSerializer.deserialize(rowval); return Long.parseLong(val); &#125; catch (Exception e) &#123; return 0L; &#125; &#125; &#125;); &#125; &#125; 设置每天零点过期，重新计数 1234567//当天时间Date date = new Date();//当天零点date = DateUtils.truncate(date, Calendar.DAY_OF_MONTH);//第二天零点date = DateUtils.addDays(date, +1);redisTemplate.expireAt(&quot;success&quot;, date); 6. 限流 int类型，incr方法 以访问者的IP和其他信息作为key,访问一次增加一次次数，超过次数 则返回false 7. 位统计 String类型的bitcount 字符是以8位二进制存储的 1234567891011set k1 asetbit k1 6 1setbit k1 7 0get k1 /* 6 7 代表的a的二进制位的修改a 对应的ASCII码是97，转换为二进制数据是01100001b 对应的ASCII码是98，转换为二进制数据是01100010因为bit非常节省空间（1 MB=8388608 bit），可以用来做大数据量的统计。*/ 例如：在线用户统计，留存用户统计 123setbit onlineusers 01 setbit onlineusers 11 setbit onlineusers 20 支持按位与、按位或等等操作 1234BITOPANDdestkeykey[key...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。 BITOPORdestkeykey[key...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 BITOPXORdestkeykey[key...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 BITOPNOTdestkeykey ，对给定 key 求逻辑非，并将结果保存到 destkey 。 计算出7天都在线的用户 1BITOP &quot;AND&quot; &quot;7_days_both_online_users&quot; &quot;day_1_online_users&quot; &quot;day_2_online_users&quot; ... &quot;day_7_online_users&quot; 8. 购物车 String 或hash。所有String可以做的hash都可以 hash类型是一个String类型的field和value的映射表，每个hash都可以存储2^32 -1键值对 使用hash做购物车：以用户id为key, 商品id为field，商品数量为value。 9. 用户消息时间线timeline list，双向链表，直接作为timeline就好了。插入有序 10. 消息队列 List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间 blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低 队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列 栈：先进后出：rpush brpop 11. 抽奖 自带一个随机获得值 1spop myset 12. 点赞、签到、打卡 假如上面的微博ID是t1001，用户ID是u3001 用 like:t1001 来维护 t1001 这条微博的所有点赞用户 点赞了这条微博：sadd like:t1001 u3001 取消点赞：srem like:t1001 u3001 是否点赞：sismember like:t1001 u3001 点赞的所有用户：smembers like:t1001 点赞数：scard like:t1001 13. 商品标签 用 tags:i5001 来维护商品所有的标签。 sadd tags:i5001 画面清晰细腻 sadd tags:i5001 真彩清晰显示屏 sadd tags:i5001 流程至极 14.商品筛选 123456// 获取差集sdiff set1 set2// 获取交集（intersection ）sinter set1 set2// 获取并集sunion set1 set2 1234567sadd brand:apple iPhone11sadd brand:ios iPhone11sad screensize:6.0-6.24 iPhone11sad screentype:lcd iPhone 11 筛选商品，苹果的、ios的、屏幕在6.0-6.24之间的，屏幕材质是LCD屏幕 1sinter brand:apple brand:ios screensize:6.0-6.24 screentype:lcd 15. 用户关注、推荐模型 12345## follow 关注 fans 粉丝sadd 1:follow 2sadd 2:fans 1sadd 1:fans 2sadd 2:follow 1 我关注的人也关注了他(取交集)： 1sinter 1:follow 2:fans 可能认识的人： 12345## 用户1可能认识的人(差集)：sdiff 2:follow 1:follow## 用户2可能认识的人：sdiff 1:follow 2:follow 16. 排行榜 id 为6001 的新闻点击数加1：zincrby hotNews:20190926 1 n6001 获取今天点击最多的15条：zrevrange hotNews:20190926 0 15 withscores redis不适用的场景 Redis是一种缓存技术，主要用来提高应用的性能，更多的应用场景是对数据库读数据进行缓存，减轻数据库的IO的访问压力，以下场景不太适合使用Redis: 数据规模大小角度 Redis是将数据放在内存进行缓存的，内存相对于磁盘来锁价格是比较贵的。如果成本是需要考虑的重要因素，那么大规模的数据就不太适合； 数据冷热程度角度 很多业务数据可以根据数据读的频繁程度分为热数据和冷数据；频繁使用的热数据一般适合用redis，冷数据一般不太适合用redis,如果大量的冷数据进行了缓存，那是对内存资源的浪费， 所以在应用场景上区分冷热数据，将热数据放在内存中，进而提高性能。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"}]},{"title":"MVCC多版本并发控制","slug":"mvcc","date":"2021-08-14T03:03:40.000Z","updated":"2022-04-06T09:51:44.961Z","comments":true,"path":"mvcc/","link":"","permalink":"https://xiaoyuge5201.github.io/mvcc/","excerpt":"","text":"1. MVCC 全称Multi-Version Concurrency Control即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中是心啊事务内存。 MVCC在mysql Innodb中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使读写冲突时，也能做到不加锁，非阻塞并发读 2. 当前读和快照读 当前读 像select lock in share mode（共享锁），select for update， update, insert,delete(排他锁)这些操作都是一种当前读；当前读就是读取记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。 快照读 像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别（串行级别快照读会变成当前读）；快照读的实现是基于多版本并发控制（即MVCC）；可以任务MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销； 既然是基于多版本，即快照读可能读到的并不一定是最新版本的数据，有可能是之前的历史版本 MVCC就是为了实现读（快照读）-写冲突不加锁，当前读实际上是一种加锁的操作，是悲观锁的实现。 3. 当前读、快照读和MVCC的关系 MVCC多版本并发控制指的是&quot;维持一个数据的多个版本，使得读写操作没有冲突&quot;； Mysql通过快照读的方式去实现MVCC理想模型的其中一个具体非阻塞读功能，相对而言，当前读就是悲观锁的具体功能实现 MVCC模型在Mysql中具体实现有3个隐式字段：undo日志、Read View等去完成的 4. MVCC的作用与好处 数据库并发场景分为以下三种： 读-读：没有问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，（脏读、幻读、不可重复读） 写-写：有线程安全问题，可能会存在更新丢失问题 MVCC带来的好处： MVCC是一种用来解决读-写冲突的无所并发控制（在MVCC提出之前采用的是采用悲观锁），也就是事务分配增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务前的数据库快照，主要解决以下问题： 在并发读写数据库时，可以做到在读操作是不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能； 解决脏读、幻读、不可重复读等事务隔离性问题，但不能解决更新丢失问题 MVCC组合方法 MVCC + 悲观锁： MVCC解决读写冲突，悲观锁解决写写冲突 MVCC + 乐观锁： MVCC解决读写冲突，乐观锁解决写写冲突，这种方式可能最大程度的提高数据库并发性能，并解决读写冲突和写写冲突导致的问题 5. MVCC的实现原理 实现原理主要是依赖记录中的 3个隐式字段、undo日志 、ReadView 来实现的 在Mysql的InnoDB引擎中就是指在已提交读(READ COMMITTD)和可重复读(REPEATABLE READ)这两种隔离级别下的事务对于SELECT操作会访问版本链中的记录的过程 这就使得别的事务可以修改这条记录，反正每次修改都会在版本链中记录。SELECT可以去版本链中拿记录，这就实现了读-写，写-读的并发执行，提升了系统的性能。 5.1 版本链 123456begin;#触发分配TRX_IDselect * from t_role;#指定TRX_MYSQL_THREAD_ID=当前CONNECTION_ID,表示查询当前连接select TRX_ID, ROLL_PTR, ROW_ID from INFORMATION_SCHEMA.INNODB_TRX where TRX_MYSQL_THREAD_ID = CONNECTION_ID();commit; 在InnoDB引擎表中，它的聚簇索引记录中有两个必要的隐藏列： TRX_ID 6byte，这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id roll_pointer 每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本) ROW_ID 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引 实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了 比如现在有个事务id是60的执行的这条记录的修改语句 此时在undo日志中就存在版本链 5.2 ReadView 已提交读和可重复读的区别就在于它们生成ReadView的策略不同 ReadView中主要就是有个列表来存储我们系统中当前活跃着的读写事务，也就是begin了还未提交的事务。通过这个列表来判断记录的某个版本是否对当前事务可见。假设当前列表里的事务id为[80,100]。 如果你要访问的记录版本的事务id为50，比当前列表最小的id80小，那说明这个事务在之前就提交了，所以对当前活动的事务来说是可访问的。 如果你要访问的记录版本的事务id为90,发现此事务在列表id最大值和最小值之间，那就再判断一下是否在列表内，如果在那就说明此事务还未提交，所以版本不能被访问。如果不在那说明事务已经提交，所以版本可以被访问。 如果你要访问的记录版本的事务id为110，那比事务列表最大id100都大，那说明这个版本是在ReadView生成之后才发生的，所以不能被访问。 这些记录都是去版本链里面找的，先找最近记录，如果最近这一条记录事务id不符合条件，不可见的话，再去找上一个版本再比较当前事务的id和这个版本事务id看能不能访问，以此类推直到返回可见的版本或者结束。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"java缓存一致性问题","slug":"cache-consistency","date":"2021-08-11T05:31:52.000Z","updated":"2022-03-27T14:06:03.477Z","comments":true,"path":"cache-consistency/","link":"","permalink":"https://xiaoyuge5201.github.io/cache-consistency/","excerpt":"","text":"","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"}]},{"title":"volatile关键字","slug":"volatile","date":"2021-08-02T10:20:38.000Z","updated":"2022-06-06T02:37:32.781Z","comments":true,"path":"volatile/","link":"","permalink":"https://xiaoyuge5201.github.io/volatile/","excerpt":"","text":"1.volatile作用 volatile保证有序性，可见性，不能保证原子性 禁止指令重排 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量值，这个新值对其他线程立即可见的 不能保证原子性(线程不安全) 2. 实现原理 通过插入内存屏障指令禁止编译器和CPU对程序进行重排序。 当对声明了volatile的变量进行写操作时，JVM就会向处理器发送一条Lock前缀的指令，这条Lock前缀指令产生如下两个作用： Lock前缀指令会引起处理器缓存回写到系统内存，并使用缓存一致性机制来确保回写的原子性。 一个处理器的缓存回写到系统内存会导致其他处理器的缓存无效。处理器使用MESI控制协议去维护内部缓存和其他处理器缓存的一致性。处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充 3.synchronized与volatile比较 volatile关键字是线程同步的轻量级实现，性能较synchronized好；但是volatile关键字只能用于变量，而synchronized关键字可以修饰方法以及代码块 synchronized关键字在java1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其他各种优化之后执行效率有了显著的提升； 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞 volatile关键字保证数据的可见性，但是不能保证数据的原子性；synchronized关键字两者都能保证（synchronized保证原子性，有序性，可见性） volatile关键字主要用于解决变量在多个线程之间的可见性，而synchronized关键字解决的是多个线程之间访问资源的同步性。 synchronized是同步锁，同步快内的代码相当于同一时刻单线程执行 4. 可见性问题 Java虚拟机规范中定义了一种Java内存 模型（Java Memory Model，即JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果。Java内存模型的主要目标就是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的细节。 JMM中规定所有的变量都存储在主内存（Main Memory）中，每条线程都有自己的工作内存（Work Memory），线程的工作内存中保存了该线程所使用的变量的从主内存中拷贝的副本。线程对于变量的读、写都必须在工作内存中进行，而不能直接读、写主内存中的变量。同时，本线程的工作内存的变量也无法被其他线程直接访问，必须通过主内存完成 整体内存模型如下： 4.1 synchronized synchronized关键字的语义JMM（Java Main Memory）有两个规定，保证其实现内存可见性： - 线程解锁前，必须把共享变量的最新值刷新到主内存中 - 线程加锁前，将清空工作内存中共享变量的值，从主内存中重新取值 4.2 volatile 当对volatile变量执行写操作后，JMM会把工作内存中的最新变量值强制刷新到主内存 写操作会导致其他线程中的缓存无效 这样，其他线程使用缓存时，发现本地工作内存中此变量无效，便从主内存中获取，这样获取到的变量便是最新的值，实现了线程的可见性。","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"thread","slug":"thread","permalink":"https://xiaoyuge5201.github.io/tags/thread/"}]},{"title":"Java内存泄漏排查","slug":"outOfMemoryError","date":"2021-08-01T11:25:57.000Z","updated":"2022-07-03T03:22:39.842Z","comments":true,"path":"outOfMemoryError/","link":"","permalink":"https://xiaoyuge5201.github.io/outOfMemoryError/","excerpt":"","text":"1.内存溢出 java.lang.OutOfMemoryError：是指程序在申请内存是，没有足够的内存空间供其使用，出现OutOfMemoryError 产生原因 JMM内存过小 程序不严谨，产生了过多的垃圾 具体表现在以下集中情况 内存中加载的数据量过于庞大，如一次从数据库取出过多的数据 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收 代码中存在死循环或循环过多产生过多重复的对象实体 使用第三方软件的bug 启动参数内存值设定过小 常见错误提示 tomcat:java.lang.OutOfMemoryError: PermGen space tomcat:java.lang.OutOfMemoryError: Java heap space weblogic:Root cause of ServletException java.lang.OutOfMemoryError resin:java.lang.OutOfMemoryError java:java.lang.OutOfMemoryError 解决方法 增加JVM的内存大小 对于tomcat容器，找到tomcat在电脑中的安装目录，进入这个目录，然后进入bin目录中，在window环境下找到bin目录中的catalina.bat，在linux环境下找到catalina.sh。 编辑catalina.bat文件，找到JAVA_OPTS（具体来说是 set “JAVA_OPTS=%JAVA_OPTS% %LOGGING_MANAGER%”）这个选项的位置，这个参数是Java启动的时候，需要的启动参数。 也可以在操作系统的环境变量中对JAVA_OPTS进行设置，因为tomcat在启动的时候，也会读取操作系统中的环境变量的值，进行加载。 如果是修改了操作系统的环境变量，需要重启机器，再重启tomcat，如果修改的是tomcat配置文件，需要将配置文件保存，然后重启tomcat，设置就能生效了 优化程序，释放垃圾 主要思路就是避免程序体现上出现的情况。避免死循环，防止一次载入太多的数据，提高程序健壮型及时释放。因此，从根本上解决Java内存溢出的唯一方法就是修改程序，及时地释放没用的对象，释放内存空间 2. 内存泄漏 Memory Leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存，迟早会被占光。 在Java中，内存泄漏就是存在一些被分配的对象，这些对象有下面两个特点： 1）首先，这些对象是可达的，即在有向图中，存在通路可以与其相连； 2）其次，这些对象是无用的，即程序以后不会再使用这些对象。 如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。 关于内存泄露的处理页就是提高程序的健壮型，因为内存泄露是纯代码层面的问题 3.内存溢出和内存泄漏的联系 内存泄露会最终会导致内存溢出。 相同点：都会导致应用程序运行出现问题，性能下降或挂起。 不同点： 1) 内存泄露是导致内存溢出的原因之一，内存泄露积累起来将导致内存溢出。 2) 内存泄露可以通过完善代码来避免，内存溢出可以通过调整配置来减少发生频率，但无法彻底避免。 4.排查案例 Java的内存泄露多半是因为对象存在无效的引用，对象得不到释放，如果发现Java应用程序占用的内存出现了泄露的迹象，那么我们一般采用下面的步骤分析： 用工具生成java应用程序的heap dump（如jmap） 使用Java heap分析工具（如MAT），找出内存占用超出预期的嫌疑对象 根据情况，分析嫌疑对象和其他对象的引用关系。 分析程序的源代码，找出嫌疑对象数量过多的原因。 实际操作如下： 1.登录linux服务器，获取tomcat的pid 1ps -ef|grep java 2.利用jmap初步分析内存映射 1jmap -histo:live pid | head -7 第2行是我们业务系统的对象，通过这个对象的引用可以初步分析出到底是哪里出现了引用未被垃圾回收收集，通知开发人员优化相关代码 3.如果上面一步还无法定位到关键信息，那么需要拿到heap dump，生成离线文件，做进一步分析 1jmap -dump:live,format=b,file=heap.hprof 3514 4. 拿到heap dump文件，利用eclipse插件MAT来分析heap profile。 1.安装MAT插件 2.在eclipse里切换到Memory Analysis视图 3.用MAT打开heap profile文件。 直接看到下面Action窗口，有4种Action来分析heap profile，介绍其中最常用的2种: Histogram：这个使用的最多，跟上面的jmap -histo 命令类似，只是在MAT里面可以用GUI来展示应用系统各个类产生的实例。 Shllow Heap排序后发现 Cms_Organization 这个类占用的内存比较多（没有得到及时GC），查看引用 分析引用栈，找到无效引用，打开源码 查看源码！！！","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"内存溢出","slug":"内存溢出","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/"}]},{"title":"JAVA类加载过程","slug":"classLoad","date":"2021-07-31T03:04:02.000Z","updated":"2022-03-27T14:06:03.354Z","comments":true,"path":"classLoad/","link":"","permalink":"https://xiaoyuge5201.github.io/classLoad/","excerpt":"","text":"1.类加载机制 JVM将类描述数据从.class文件中加载到内存，并对数据进行解析、初始化，最终形成被JVM直接使用的Java类型；类从被加载到JVM中开始，到卸载为止， 整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载7个阶段 加载 加载时jvm做了三件事 1)通过一个类的全限定名获取该类的二进制流 2)将这个字节流的静态存储结构转化为方法区运行时数据结构 3)在内存堆中生成一个代表该类的java.lang.class对象，最为该类数据的访问入口 验证 验证、准备、解析这三步可以看作是一个连接的过程，将类的字节码连接到JVM的运行黄台之中; 验证是为了确保class文件的字节流中包含的信息符合当前虚拟机的要求，不会威胁到jvm的安全。 验证内容如下： 文件格式的验证： 验证字节流是否符合class文件袋额规范，是否能被当前版本的虚拟机处理 元数据验证： 对字节码描述的信息进行语义分析，确保符合Java语言规范 字节码验证：通过数据流和控制流分析，确定寓意是否合法，符合逻辑的 符号引用验证：这个娇艳在解析阶段发生 准备 为类的静态变量分配内存，设置初始值，对于final static修饰的变量，直接赋值为用户的定义值。 12//准备阶段过后的初始值为0， 而不是7 public static int a = 7; 解析 解析是将常量池内的符号引用转化为直接引用（如物理内存地址指针） 初始化 初始化阶段，jvm才开始真正执行类中定义的Java代码 执行类构造器()方法的过程，类构造器方法是有编译器自动手机类中所有类变量的赋值动作和静态语句块（static块）中的语句合并产生的 当初始化一个类的时候，如果发现其父类还没有进行过初始化，需有限触发其父类的初始化 虚拟机会保证一个类的()方法在多线程环境被正确加锁和同步 2.类加载器 类加载器的主要任务：对类加载过程中的加载操作（根据一个类的全限定名读取该类的二进制字节流到JVM内部，然后转换为一个对应的java.lang.Class对象实例） 类加载器的分类 启动类加载器Bootstrap ClassLoader: 在HotSpot虚拟机中，Bootstrap ClassLoader用C++语言编写并嵌入JVM内部，主要负载加载JAVA_HOME/lib目录中的所有类，或者加载由选项-Xbootcalsspath指定的路径下的类 拓展类加载器/ExtClassLoader： ExtClassLoader继承ClassLoader类，负载加载JAVA_HOME/lib/ext目录中的所有类型，或者由参数-Xbootclasspath指定路径中的所有类型 应用程序类加载器/AppClassLoader: ExtClassLoader继承ClassLoader类，负责加载用户类路径ClassPath下的所有类型，一般情况下为程序的默认类加载器 自定义加载器: Java虚拟机规范将所有继承抽象类java.lang.ClassLoader的类加载器，定义为自定义类加载器 3. 双亲委派模型 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式 。 除了启动类加载器以外，每个类加载器拥有一个父类加载器，用户的自定义类加载器的父类加载器是AppClassLoader； 双亲委派模型可以保证全限名指定的类，只被加载一次； 双亲委派模型不具有强制性约束，是Java设计者推荐的类加载器实现方式； 3.1 双亲委派模式优势 采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次 java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改 如果我们在classpath路径下自定义一个名为java.lang.SingleInterge类(该类是胡编的)呢？该类并不存在java.lang中，经过双亲委托模式，传递到启动类加载器中，由于父类加载器路径下并没有该类，所以不会加载，将反向委托给子类加载器加载，最终会通过系统类加载器加载该类。但是这样做是不允许，因为java.lang是核心API包，需要访问权限，强制加载将会报出如下异常 3.2 双庆委派模型实现源码 可以打开 java.lang.ClassLoader 类，其 loadClass方法如下： 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 实现方式很简单，首先会检查该类是否已经被加载过了，若加载过了直接返回（默认resolve取false）；若没有被加载，则调用父类加载器的 loadClass方法，若父类加载器为空则默认使用启动类加载器作为父加载器。如果父类加载失败，则在抛出 ClassNotFoundException 异常后，在调用自己的 findClass 方法进行加载 4.自定义类加载器 加密 我们知道Java字节码是可以进行反编译的，在某些安全性高的场景，是不允许这种情况发生的。那么我们可以将编译后的代码用某种加密算法进行加密，加密后的文件就不能再用常规的类加载器去加载类了。而我们自己可以自定义类加载器在加载的时候先解密，然后在加载 动态创建 比如很有名的动态代理。 从非标准的来源加载代码 我们不用非要从class文件中获取定义此类的二进制流，还可以从数据库，从网络中，或者从zip包等。 4.1 自定义类加载器方法 类加载时根据双亲委派模型会先一层层找到父加载器，如果加载失败，则会调用当前加载器的 findClass() 方法来完成加载。因此我们自定义类加载器，有两个步骤： 1、继承 ClassLoader 2、覆写 findClass() 方法","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"ClassLoader","slug":"ClassLoader","permalink":"https://xiaoyuge5201.github.io/tags/ClassLoader/"}]},{"title":"Hexo添加评论系统Valine","slug":"valine","date":"2021-07-27T13:49:57.000Z","updated":"2022-05-05T01:43:21.800Z","comments":true,"path":"valine/","link":"","permalink":"https://xiaoyuge5201.github.io/valine/","excerpt":"","text":"Hexo的评论系统有很多，常见的有以下几个 多说 网易云跟帖 畅言 来必力（LiveRe） Disqus Hypercomments valine 首先多说和网易云已经倒下了，其次畅言需要备案，Disqus，Hypercomments和LiveRe都是国外的，加载速度贼慢，甚至有被墙的可能，寻觅了很久之后，从Material主题换成next主题之后，终于找到了一个好用的评论系统，那就是 valine 我使用的是Next 6.x版本，本身就已经集成了valine，因此正常情况下是按照官方文档走就可以了，5分钟开启你的评论系统~ 注册LeanCloud 我们的评论系统其实是放在Leancloud上的，因此首先需要去注册一个账号，注册地址：https://www.leancloud.cn/ 获取AppId 注册完了之后 创建一个应用，名字随便起；然后进入应用-&gt;设置-&gt;应用凭证 中获取appid 和 appkey 配置valine 拿到appid和appkey之后，打开主题配置文件_config.yml 搜索 valine，填入appid 和 appkey 123456789101112comment: type: valine # 启用哪种评论系统 valine: # Valine. https://valine.js.org appid: your leancloud application appid appkey: your leancloud application appkey notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: Just go go # comment box placeholder avatar: mm # gravatar style meta: nick,mail #,link # custom comment header pageSize: 10 # pagination size visitor: true # Article reading statistic https://valine.js.org/visitor.html LeanCloud 安全域名配置 在LeanCloud -&gt; 设置 -&gt; 安全中心 -&gt; Web 安全域名 把你的域名加进去 查看评论数据 在数据存储 -&gt; 结构化数据 中可以查看到所有的存储的数据信息","categories":[{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/tags/hexo/"}]},{"title":"mysql数据库锁","slug":"mysql数据库锁","date":"2021-07-24T08:57:10.000Z","updated":"2022-07-03T03:14:48.012Z","comments":true,"path":"mysql数据库锁/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%81/","excerpt":"","text":"当数据库有事务的时候，可能会产生数据的不一致，这时就需要一些机制来保证访问的次序，这就是锁的机制； 锁的作用：用于挂你对共享资源的并发访问，保证数据库的完整性和一致性。 ##1. 不同引擎的锁以及锁分类 Mysql数据库中，InnoDB支持表、行级锁，而MyISAM支持表级锁 Mysql大致可以归纳为以下3种锁： 表级锁：开销小，加锁块，不会出现死锁，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢，会出现死锁，发生锁冲突的概率最低，并发度最高。 页面锁：开销和加锁的时间介于表级锁和行级锁之间，会出现死锁，锁粒度介于两者之间；并发度一般，一次锁定相邻一组记录 Mysql表级锁两种模式: 表共享锁（Table Read Lock）和 表独占写锁（Table Write Lock），表现如下： 对一个表的读操作，不会阻塞其他用户对同一表请求，但会阻塞对同一表的写请求； 对MyISAM的写操作，则会则色其他用户对同一表的读和写操作； MyISAM表的读操作和写操作之间，以及写操作之间是串行的。 当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作，其他线程的读、写操作都会等待。 2.加表级锁 MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要直接用LOCK TABLE命令给MyISAM表显式加锁。 给MyISAM表显式加锁，一般是为了一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。例如，有一个订单表orders，其中记录有订单的总金额total，同时还有一个订单明细表order_detail，其中记录有订单每一产品的金额小计subtotal，假设我们需要检查这两个表的金额合计是否相等，可能就需要执行如下两条SQL","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"mycat学习","slug":"mycat","date":"2021-07-23T08:16:49.000Z","updated":"2022-03-27T14:06:03.312Z","comments":true,"path":"mycat/","link":"","permalink":"https://xiaoyuge5201.github.io/mycat/","excerpt":"","text":"Mycat(分库分表中间件) 1. 数据库优化策略 重启：释放资源 SQL与索引 表与存储引擎（字段类型选择，长度设置，是否需要分表、分区） 数据库与应用架构（考虑使用缓存服务器，减轻是数据库压力；可以数据库分布式，读写分离，主从复制） 数据库与操作系统配置（修改mysql配置，使用单独服务器部署数据库） 硬件 2. 数据库演化 根据业务需要、数据量变化，随之而来的数据库的变化 数据库与应用部署在同一台服务器 单体应用架构，单数据库（数据库服务器和应用服务器分离，但是业务系统越做越大） 多应用单数据库（应用解耦） 多应用 独立数据库 但应用多数据库(分表) 3. 如何分库分表 垂直切分 单库 多库 水平切分 按照月分表或者分成实时、历史表等 分成多库 4. 分库分表带来的问题 跨库关联查询 增加冗余字段（违反了第三范式：表中的所有数据元素不但要能唯一地被主关键字所标识,而且它们之间还必须相互独立,不存在其他的函数关系） 跨数据库的同步（canal、Mq（最好）、ETL、kettle、ogg）(在某个库中同步其他数据库中表的数据，避免跨库关联查询) 全局表(广播表)：比如行政区划表，所有的系统都是一样的； API 分布式事务 Local 排序、翻页、函数计算 全局主键 雪花算法leaf redis(int 类型可以设置incby) ZookKeeper uuid(数据过长， 影响索引存储) 多数据源连接（动态数据源） 5. Mycat分库分表中间件 官网地址：http://www.mycat.org.cn/ 从阿里cobar升级而来，完全实现了mysql协议，可以当作一个mysql数据库来使用，通过JDBC支持其他数据库实现分库分表，解决了多表join、分布式事务、全局序列号、翻页查询、函数计算的问题 一个彻底开源的，面向企业应用开发的大数据库集群 支持事务、ACID、可以替代MySQL的加强版数据库 一个可以视为MySQL集群的企业级数据库，用来替代昂贵的Oracle集群 一个融合内存缓存技术、NoSQL技术、HDFS大数据的新型SQL Server 结合传统数据库和新型分布式数据仓库的新一代企业级数据库产品 一个新颖的数据库中间件产品 华为云的DDM其实也是根据mycat做的 5.1 核心概念 5.2 Mycat安装与配置 5.2.1 Mycat安装 从官网下载安装版本，解压到文件(官网建议安装在/usr/local/Mycat)后页面如下图所示： 目录解释如下： **bin：*存放window版和linux版本除了提供封装成服务的版本之外，也提供了nowrap的shell脚本命令，方便选择和修改；Linux下运行:./mycat console， 首先要chmod + x;(mycat支持的命令console、start、stop、restart、status、dump) **conf：**server.xml是mycat服务器参数调整和用户授权的配置文件，schema.xml是逻辑库定义和表以及分片定义的配置文件，rule.xml是分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件，也在这个目录下，配置文件修改，需要重启mycat或者通过9066端口reload **lib:**主要存放mycat依赖的一些jar文件 logs:日志存放在mycat.log中，每天一个文件，日志的配置是在conf/log4j.xml中，根据自己的需要，可以调整输出级别为debug，方便排查问题；注意Linux下部署安装mysql，默认不忽略，需要手动到/etc/my.cnf下配置lower_case_table_names=1使Linux环境下MySQL忽略表明大小写，否则使用mycat的时候会提示找不到表的错误 5.2.2 服务启动与配置 Mycat在Linux中部署启动时，首先需要在Linux系统的环境变量中配置MYCAT_HOE,操作方式如下： vi /etc/profile，在系统环境变量文件中增加MYCAT_HOME=/usr/lib/tools/mycat 执行 source/etc/profile命令，使环境变量生效。如果是多台Linux系统中组件Mycat集群，那需要在mycat Server所在的服务器配置对其他ip和主机名的映射，配置方式如下： 经过以上两个步骤的配置，就可以到/usr/lib/tools/mycat/bin目录下执行./mycat start启动mycat服务；使用mycat status查看mycat的运行状态；如下图 5.2.2.1 安装遇到的问题 schema TESTDB refered by user root is not exist! 解决方式： 12345678&lt;!--在conf/server.xml文件中schemas中配置schema.xml文件中的schema的name值--&gt;&lt;!--user中的name为mycat服务的用户名--&gt; &lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;!--这个是mycat服务连接的密码--&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;xiaoyuge&lt;/property&gt;&lt;/user&gt; 5.2.3日志分析 mycat的日志文件配置为MYCAT_HOME/conf/log4j.xml 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE log4j:configuration SYSTEM &quot;log4j.dtd&quot;&gt; &lt;log4j:configuration xmlns:log4j=&quot;http://jakarta.apache.org/log4j/&quot;&gt; &lt;appender name=&quot;ConsoleAppender&quot; class=&quot;org.apache.log4j.ConsoleAppender&quot;&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;MM-dd HH:mm:ss.SSS&#125; %5p [%t] (%F:%L) -%m%n&quot; /&gt;true&lt;/layout&gt;true&lt;/appender&gt;true&lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.RollingFileAppender&quot;&gt; &lt;!--日志文件存放的目录--&gt; &lt;param name=&quot;file&quot; value=&quot;$&#123;MYCAT_HOME&#125;/logs/mycat.log&quot; /&gt; &lt;param name=&quot;Append&quot; value=&quot;false&quot;/&gt; &lt;param name=&quot;MaxFileSize&quot; value=&quot;10000KB&quot;/&gt; &lt;param name=&quot;MaxBackupIndex&quot; value=&quot;10&quot;/&gt; &lt;param name=&quot;encoding&quot; value=&quot;UTF-8&quot; /&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;MM/dd HH:mm:ss.SSS&#125; %5p [%t] (%F:%L) -%m%n&quot; /&gt;true&lt;/layout&gt;true&lt;/appender&gt;true&lt;root&gt; &lt;!--level是日志级别，生产环境下加以将级别调整为info/ware，如果是研究测试，碰到异常设置为debug--&gt;truetrue&lt;level value=&quot;debug&quot; /&gt;truetrue&lt;appender-ref ref=&quot;ConsoleAppender&quot; /&gt;true&lt;/root&gt;&lt;/log4j:configuration&gt; 5.2.3.1 warpper日志 目前mycat的启动时经过warpper封装成启动脚本，所以日志也会有其相关的日志文件：${MYCAT_HOME}/logs/warapper.log， 在启动的时候如果系统环境配置错误或缺少配置时，导致mycat无法启动，可以通过查看wrapper.log查看具体错误原因。 正常启动 1234567STATUS | wrapper | 2015/04/12 15:05:00 | --&gt; Wrapper Started as DaemonSTATUS | wrapper | 2015/04/12 15:05:00 | Launching a JVM...INFO | jvm 1 | 2015/04/12 15:05:01 | Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.orgINFO | jvm 1 | 2015/04/12 15:05:01 | Copyright 1999-2006 Tanuki Software, Inc. AllRights Reserved.INFO | jvm 1 | 2015/04/12 15:05:01 |INFO | jvm 1 | 2015/04/12 15:05:01 | log4j 2015-04-12 15:05:01 [./conf/log4j.xml]load completed.INFO | jvm 1 | 2015/04/12 15:05:02 | MyCAT Server startup successfully. see logs in logs/mycat.log 启动异常 1234567891011STATUS | wrapper | 2015/02/14 01:43:44 | --&gt; Wrapper Started as DaemonSTATUS | wrapper | 2015/02/14 01:43:44 | Launching a JVM...INFO | jvm 1 | 2015/02/14 01:43:45 | Error: Exception thrown by the agent : java.rmi.server.ExportException:Port already in use: 1984; nested exception is:INFO | jvm 1 | 2015/02/14 01:43:45 | java.net.BindException: Address already in useERROR | wrapper | 2015/02/14 01:43:45 | JVM exited while loading the application. # 日志显示异常原因为 java.net.BindException: Address already in use,也就是端口占用，很有可能是原有服务未停止，或者 Mycat 默认端口被其他程序占用，正常启动成功后会有 mycat.log 日志，如果服务未启动成功不会有对应的日志。 也可以去修改 conf 文件夹里的 wrapper.conf 里的 wrapper.java.additional.7=-Dcom.sun.management.jmxremote.port=1984，server.xml 的&lt;property name=&quot;serverPort&quot;&gt;8066&lt;/property&gt;和&lt;property name=&quot;managerPort&quot;&gt;9066&lt;/property&gt;，这方法适合一台机器上两个 mycat 或者 1984,8066,9066 端口被其它应用占用的情况 5.2.3.2 mycat日志 5.2.4 mycat防火墙设置 白名单和SQL黑名单说明： 12345678910111213&lt;!--在 server.xml 中配置：--&gt;&lt;firewall&gt; &lt;!--ip 白名单列表，可以配置多个--&gt; &lt;whitehost&gt; &lt;!--ip 白名单 用户对应的可以访问的 ip 地址--&gt; &lt;host user=&quot;mycat&quot; host=&quot;127.0.0.1&quot;&gt;&lt;/host&gt; &lt;/whitehost&gt; &lt;!-是否开启检查黑名单列表--&gt; &lt;blacklist check=&quot;true&quot;&gt; &lt;!--黑名单允许的 权限 后面为默认--&gt; &lt;property name=&quot;selelctAllow&quot;&gt;false&lt;/property&gt; &lt;/blacklist&gt;&lt;/firewall&gt; 黑名单配置拦截明细如下： 配置项 缺省值 描述 rollbackAllow true 是否允许执行 roll back 操作,如果把 selectIntoAllow、deleteAllow、updateAllow、insertAllow、mergeAllow 都设置为 false，这就是一个只读数据源了。 selectAllow true 是否运行执行SELECT语句 selectAllColumnAllow true 是否允许执行 SELECT * FROM T 这样的语句。如果设置为 false，不允许执行 select * from t，但 select * from (select id, name from t) a。这个选项是防御程序通过调用 select *获得数据表的结构信息 selectIntoAllow true SELECT 查询中是否允许 INTO 字句 deleteAllow true 是否允许执行 DELETE 语句 updateAllow true 是否允许执行 UPDATE 语句 insertAllow true 是否允许执行 INSERT 语句 replaceAllow true 是否允许执行 REPLACE 语句 mergeAllow true 是否允许执行 MERGE 语句，这个只在 Oracle 中有用 callAllow true 是否允许通过 jdbc 的 call 语法调用存储过程 setAllow true 是否允许使用 SET 语法 truncateAllow true truncate 语句是危险，缺省打开，若需要自行关闭 createTableAllow true 是否允许创建表 alterTableAllow true 是否允许执行 Alter Table 语句 dropTableAllow true 是否允许修改表 commentAllow false 是否允许语句中存在注释，Oracle 的用户不用担心，Wall 能够识别 hints和注释的区别 noneBaseStatementAllow false 是否允许非以上基本语句的其他语句，缺省关闭，通过这个选项 就能够屏蔽 DDL。 multiStatementAllow false 是否允许一次执行多条语句，缺省关闭 useAllow true 是否允许执行 mysql 的 use 语句，缺省打开 describeAllow true 是否允许执行 mysql 的 describe 语句，缺省打开 showAllow true 是否允许执行 mysql 的 show 语句，缺省打开 commitAllow true 是否允许执行 commit 操作 拦截配置=-永真条件： 配置项 缺省值 描述 selectWhereAlwayTrueCheck true 检查 SELECT 语句的 WHERE 子句是否是一个永真条件 selectHavingAlwayTrueCheck true 检查 SELECT 语句的 HAVING 子句是否是一个永真条件 deleteWhereAlwayTrueCheck true 检查 DELETE 语句的 WHERE 子句是否是一个永真条件 deleteWhereNoneCheck false 检查 DELETE 语句是否无 where 条件，这是有风险的，但不是 SQL 注入类型的风险 updateWhereAlayTrueCheck true 检查 UPDATE 语句的 WHERE 子句是否是一个永真条件 updateWhereNoneCheck false 检查 UPDATE 语句是否无 where 条件，这是有风险的，但不是SQL 注入类型的风险 conditionAndAlwayTrueAllow false 检查查询条件(WHERE/HAVING 子句)中是否包含 AND 永真条件 conditionAndAlwayFalseAllow false 检查查询条件(WHERE/HAVING 子句)中是否包含 AND 永假条件 conditionLikeTrueAllow true 检查查询条件(WHERE/HAVING 子句)中是否包含 LIKE 永真条件 其他拦截配置： 配置项 缺省值 描述 selectIntoOutfileAllow false SELECT … INTO OUTFILE 是否允许，这个是 mysql 注入攻击的常见手段，缺省是禁止的 selectUnionCheck true 检测 SELECT UNION selectMinusCheck true 检测 SELECT MINUS selectExceptCheck true 检测 SELECT EXCEPT selectIntersectCheck true 检测 SELECT INTERSECT mustParameterized false 是否必须参数化，如果为 True，则不允许类似 WHERE ID = 1 这种不参数化的 SQL strictSyntaxCheck true 是否进行严格的语法检测，Druid SQL Parser 在某些场景不能覆盖所有的，SQL 语法，出现解析 SQL 出错，可以临时把这个选项设置为 false，同时把 SQL 反馈给 Druid 的开发者 conditionOpXorAllow false 查询条件中是否允许有 XOR 条件。XOR 不常用，很难判断永真或者永假，缺省不允许。 conditionOpBitwseAllow true 查询条件中是否允许有&quot;&amp;&quot;、&quot;~&quot;、&quot; conditionDoubleConstAllow false 查询条件中是否允许连续两个常量运算表达式 minusAllow true 是否允许 SELECT * FROM A MINUS SELECT * FROM B 这样的语句 intersectAllow true 是否允许 SELECT * FROM A INTERSECT SELECT * FROM B 这样的语句 constArithmeticAllow true 拦截常量运算的条件，比如说 WHERE FID = 3 - 1，其中&quot;3 - 1&quot;是常量运算表达式。 limitZeroAllow false 是否允许 limit 0 这样的语句 禁用对象检测配置： 配置项 缺省值 描述 tableCheck true 检测是否使用了禁用的表 schemaCheck true 检测是否使用了禁用的 Schema functionCheck true 检测是否使用了禁用的函数 objectCheck true 检测是否使用了“禁用对对象” variantCheck true 检测是否使用了“禁用的变量” readOnlyTables 空 指定的表只读，不能够在 SELECT INTO、DELETE、UPDATE、INSERT、MERGE 中作为&quot;被修改表&quot;出现 5.2.5 mycat配置文件 5.2.5.1 schema.xml配置 schema.xml作为mycat中重要的配置文件之一，管理者mycat的逻辑库、表、分片规则、DataNode以及DataSource。 5.2.5.2 scheme标签 1&lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt;&lt;/schema&gt; schema标签用于定义mycat实例中的逻辑库，mycat可以由多个逻辑库，每个逻辑库都有自己的相关配置，可以使用schema标签来划分这些不同的逻辑库。如果不配置schema标签，所有的表配置，会属于同一个默认的逻辑库。 1234567891011&lt;!--逻辑库TESTDB--&gt;&lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt;true&lt;table name=&quot;travelrecord&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; &gt;&lt;/table&gt;&lt;/schema&gt;&lt;!--USERDB--&gt;&lt;schema name=&quot;USERDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt;true&lt;table name=&quot;company&quot; dataNode=&quot;dn10,dn11,dn12&quot; rule=&quot;auto-sharding-long&quot; &gt;&lt;/table&gt;&lt;/schema&gt;&lt;!-- 逻辑库的概念和MySQL数据库中的database概念相同，我们在查询这两个不同的逻辑库中表的时候需要切换到该逻辑库下才可以查询到所需要的表--&gt; 在server.xml中可以配置不同的用户能够使用的schema 123456789101112131415161718192021222324&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;property name=&quot;defaultSchema&quot;&gt;TESTDB&lt;/property&gt; &lt;!--No MyCAT Database selected 错误前会尝试使用该schema作为schema，不设置则为null,报错 --&gt; &lt;!-- 表级 DML 权限设置 --&gt; &lt;!-- &lt;privileges check=&quot;false&quot;&gt; &lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt; &lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt; &lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt;&lt;/user&gt;&lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;user&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;defaultSchema&quot;&gt;TESTDB&lt;/property&gt;&lt;/user&gt; schema标签的相关属性： 属性名 值 数量限制 dataNode 任意string （0…1） checkSQLschema Boolean （1） sqlMaxLimit Integer （1） 5.2.5.2.1 dataNode 该属性用于绑定逻辑库到某个具体的database上，1.3版本如果配置了dataNode,则不可以配置分片表，1.4可以配置默认分片，只需要配置需要分片的表即可，具体配置如下： 1&lt;!--1.3版本配置--&gt;&lt;schema name=&quot;USERDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;dn1&quot;&gt;&lt;!—里面不能配置任何表--&gt;&lt;/schema&gt;&lt;!--1.4版本配置--&gt;&lt;schema name=&quot;USERDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;dn2&quot;&gt;&lt;!—配置需要分片的表--&gt; &lt;table name=“tuser” dataNode=”dn1”/&gt;&lt;/schema&gt;&lt;!-- 那么现在tuser就绑定到dn1所配置的具体database上，可以直接访问这个database，没有配置的表则会走默认的节点dn2，这里注意没有配置在分片里面的表工具查看无法显示，但是可以正常使用。--&gt; 5.2.5.2.2 checkSQLschema 当改制设置为true时，我们执行“SELECT * FROM TESTDB.travelrecord；”则mycat会把语句修改为“SELECT * FROM travelrecord;”即把表示schema的字符去掉，避免发送到后端数据库执行报ERROR 1146：Table ‘testdb.travelrecord’ doest’t exist.不过，即使设置该值为 true ，如果语句所带的是并非是 schema 指定的名字，例如：select * from db1.travelrecord; 那么 MyCat 并不会删除 db1 这个字段，如果没有定义该库的话则会报错，所以在提供 SQL语句的最好是不带这个字段。 5.2.5.2.3 sqlMaxLimit 当该值设置为某个数值时。每条执行的 SQL 语句，如果没有加上 limit 语句，MyCat 也会自动的加上所对应的值。例如设置值为 100，执行**select * from TESTDB.travelrecord;的效果为和执行select * from TESTDB.travelrecord limit 100;**相同。 设置该值的话，MyCat 默认会把查询到的信息全部都展示出来，造成过多的输出。所以，在正常使用中，还是建议加上一个值，用于减少过多的数据返回。 当然 SQL 语句中也显式的指定 limit 的大小，不受该属性的约束。 需要注意的是，如果运行的 schema 为非拆分库的，那么该属性不会生效。需要手动添加 limit 语句。 5.2 分配规则 范围分片：根据某个字设置auto-sharding-long，如果这个primaryKey超出了范围会报错 取模分片： ER分片（将父子表有关联的数据放在一个data-node里面） 全局表：所有dataNode存储相同的数据，查询的时候是随机查询某个表 type=global，查询的时候随机从某个datanode获取 非分片表：只在某个dataNode上存储,指定一个dataNode并且不写分片规则 单库分表：有个bug在实际数据库中必须要创建mycat中一摸一样的数据表，而且truncat的时候要现在dataNode先删除，才能删除的掉mycat的数据 5.3 全局ID 文件方式—0 数据库方式—1 本地时间戳----2 ZK方式----3 6. Mycat分片策略详解 连续分片与离散分片 连续分片： 范围分片 日期/事件 缺点： 存在数据热点的可能性 并发访问能力受限于单一或少量DataNode（访问集中），并不能分摊数据库访问的压力 离散： 取模（partioncount 的总数必须和分片总数相同） 枚举 一致性哈希(qs-murmur) 固定分片哈希 partitionCount: 2, 1表示有三个分片必须和节点数量一致，否则会报错，前面两个一样长 partitionLength: 256, 512表示长度为256和512 综合在一起就是前面2个分片长度为256， 最后一个为512，结果如下图所示（注意partitionCount和partitionLength的数量一定要一致） 取模范围(sharting-by-pattern)：先取模PartitionByPattern后分片 范围取模: PartitionByRangeMod(partition-rane-mod.txt) 0-2000=1 #范围在2000以内的在第一个节点（取模的结果还是本身） 2001-4000=2 #范围在2001到4000以内的再模2，结果为0在第一个节点，结果为1在第三个节点 12345678910111213141516171819202122232425262728293031323334353637- 其他优点：- 并发访问能力增强（负载到不同的节点）- 范围条件查询性能提升（并行计算）缺点：- 数据扩容比较困难，设计到数据迁移问题- 数据库连接消耗比较多分片策略的选择：1） 确定分片表2） 找出分片键3） 考虑容量、增速、业务用户如果在查询语句中没有携带分片建，那么mycat会将sql发布到所有的节点上## 7. Mycat扩缩容### 7.1 在线不停机扩缩容（双写）![image-20201107205855474](./mycat/image-20201107205855474.png)### 7.2 离线扩缩容#### 7.2.1Mysql Dump```shellmysqldump -uroot -p123456 -h127.0.0.1 -p3306 -c -t --skip-extended-insert 数据库名称 &gt; mysql.11.11.sql 7.2.2 Mycat自带工具 mycat所在环境安装mysql客户端程序 mycat的lib目录下添加mysql的jdbc驱动包（mysql-connector-java-5.7.1.jar） 对扩容缩容的表所有节点数据进行备份 复制schema.xml、rule.xml并重命名为newSchema.xml、newRule.xml 修改newSchema.xml和newRule.xml配置文件为扩容缩容后的参数 在conf/migrateTable.properties配置文件中配置分片库和分片表如：imall=table_test1 dataMigrate.sh配置mysqldump路径 停止mycat服务 执行bin/dataMigrate.sh脚本（不能用openjdk） 替换schema.xml、rule.xml 注意事项： 保证分片表迁移数据前后路由规则一致（取模–&gt;取模） 保证分片表歉意数据前后分片字段一致 全局表将被忽略 不要将非分片表配置到migrateTables.properties文件中 暂时只支持分片表使用Mysql作为数据源的扩容缩容 8. Mycat读写分离 8.1 主从复制 数据备份回复 负载均衡（读写分离） 高可用HA 8.2 主从复制形式; binlog(Binary log 二进制日志) 12--查看binglog: SHOW binlog events in &#x27;mysql-bin.000001&#x27;--show variables like &#x27;max_blog_max&#x27; binlog配置 STATEMENT: 记录每一天修改数据的sql语句（减少日志量，节约IO） ROW: 记录哪条数据被修改了，修改成什么样子了（5.7以后默认） MIXED: 结合两种方式，一般语句用STATEMENT,函数之类的使用ROW binlog格式（mysql-bin.00001等） 查看binlog 1show binlog events in &#x27;mysql-bin.00001&#x27;; 主从复制原理 SQL Thread是单线程的， 这也是所有的主从复制延迟的原因，那么relay log接受master节点的sql语句主要是用于缓冲 mycat读写分离配置 8.5 Mycat注解（hint） 注解用法： 12345/*!mycat:sql=注解sql语句*/真正执行的SQL比如说在mycat上创建表无法创建成功，可以使用注解/*!mycat:sql=select * from table_1 where id = 1*/create table test2(id int);主要注解sql可以确认mycat可以路由到子结点上，就可以执行后面的真正执行的sql语句 注解用途： 跨库关联查询 DDL或存储过程 自定义分片 读写分离 分布式事务 基于XA协议的两阶段提交 XA角色 XA实现 9. Mycat核心流程 9.1 架构图 9.2 启动流程 MycatServer启动，解析配置文件，包括服务器、分片规则等 创建工作线程，建立前端连接和后端连接 9.3 执行SQL流程 前端连接接收mysql命令 解析MySQL，mycat用的是Druid的DruidParser 获取路由 改写MySQL，例如两个条件在两个节点上，则变成两条单独的sql 与后端数据库建立连接 发送sql语句到MySQL执行 获取返回结果 处理返回结果，例如排序、计算等等 返回给客户端 Mycat高可用","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"mycat","slug":"mycat","permalink":"https://xiaoyuge5201.github.io/tags/mycat/"}]},{"title":"mysql事务","slug":"mysql-transcation","date":"2021-07-23T08:00:57.000Z","updated":"2022-04-06T09:51:44.943Z","comments":true,"path":"mysql-transcation/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql-transcation/","excerpt":"","text":"事务的定义 事务是数据管理系统DBMS执行过程中的一个逻辑单位，有一个有限的数据库操作序列构成 事务四大特性 原子性atomicity：依赖undo log做到全部失败 隔离性isolation：实现方式LBCC 和 MVCC 持久性durability ：实现方式redo log和double write 一致性consistency：通过上面的三种方式实现 数据恢复： redo log 崩溃恢复 双写缓冲（double write） Mysql中insert、delete、update 自带事务 1234show veriables like ‘autocommit’;set session autocommit = on;update xxx where set xx =1 ;commit; 结束事务两种方式：rollback commit 事务并发的三大问题 数据并发的三大问题其实都是数据库读一致性问题，必须有数据库提供一定的事务隔离机制来解决。 脏读 不可重复读 幻读 事务隔离级别 http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt MVCC思想 Read View（一致性试图） 存储内容 Read View判断规则 RC与RR read View 的区别 所以RC解决不了脏读的问题 Mysql InnoDb所得基本类型 InnoDB支持行锁 MyiSAM支持行锁 表锁和行锁的区别 锁力度：表锁 &gt; 行锁 加锁效率：表锁 &gt; 行锁 冲突概率：表锁 &gt; 行锁 并发性能：表锁 &lt; 行锁 表锁 一个事务能够给一张表加上锁的前提是：没有其他任何一个事务锁定了这张表的任意一行数据。如果没有意向锁的话，那么加表锁需要扫描表中的每行数据，大大的浪费时间； 如果在添加行锁的时候，会在表上添加意向锁，那么在添加表锁的时候就不需要去扫描所有表数据了，只需要看下表上是否由意向锁就可； 行锁 共享锁shared locks 排它锁Exclusive locks Innodb行锁锁定的是什么 锁定的是index索引，如果表中没有索引，那么Innodb会把隐藏列DB_ROW_ID当作聚集索引 加锁一定要加上条件，不然会锁表 记录锁Rcord Lock 锁定记录 间隙锁Gap Lock 锁定范围 专门用于阻塞插入，间隙锁如果没有命中的话，会锁定最后一个值到正无穷，那么在最后一个值和正无穷之间的插入都不能成功。 临健锁Next-key Lock ：锁定范围加记录 为了解决幻读的问题 事务隔离级别的实现 事务隔离级别的选择","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"mysql知识总结","slug":"mysql","date":"2021-07-23T08:00:57.000Z","updated":"2022-04-06T09:51:44.967Z","comments":true,"path":"mysql/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql/","excerpt":"","text":"mysql 初识 1. 版本历史 1996年 mysql.10发布 1996年10月3.11.1发布 2000年ISAM升级成MyISAM引擎，mysql开源 2003年 Mysql4.0发布集成InnoDB存储引擎 2005年 MySQL 5.0版本发布，提供了试图，存储过程等功能 2010年MySQL5.5发布，InnoDB成为默认的存储引擎 2016年发布8.0.0版本 2. 流行分支 Maria DB Percona Server 3. SQL 执行流程 通信类型 同步 异步 连接方式 长连接 短连接 超时时间 非交互式超时时间，如JDBC程序，单位s 1SHOW GLOBAL VARIABLES LIKE &#x27;wait_timeout&#x27; 交互式超时间，如数据库工具 1SHOW GLOBAL variables LIKE &#x27;interactive_timeout&#x27; 查看连接 1show GLOBAL STATUS LIKE &#x27;Thread%&#x27; 连接名称 描述 Threads_cached 缓存中的线程 Threads_connected 连接中线程 Threads_created 创建过的线程 Threads_running 正在执行的线程 查看所有的线程 如果是root权限，可以看到所有用户发起的线程，否则只能看到自己的线程 1show processlist id ：一个表示，kill一个语句的时候可以使用 user：显示当前用户，如果不是root，这个命令就只显示你权限范围内的sql语句 host：显示这个语句是从哪个ip的端口上发出的，可以用来追踪出问题语句的用户 db：显示这个进程目前连接的是哪个数据库 commmand：显示当年连接的执行命令，一般分为休眠slee、查询query、连接connect time：此状态持续的时间，单位是秒 state： 显示使用当年连接的sql语句状态，state只是语句执行中的某一个状态，如查询：需要经过copying to tmp table、sorting result、sending data等转台才可以完成 info：显示这个sql语句，因为长度有限，所以长的sql语句就显示不全 查看最大连接数 1show variables LIKE &#x27;max_connections&#x27;; //一般默认是151，最大可以是2的14次方 mysql变量级别 global全局 1234在mysql中修改全局变量global有两种方法：1. 修改my.ini配置文件（永久有效）2. 在不修改配置文件的基础上，使用关键字global设置全局变量 set global autocommit = 1;将autocommit变量的值设置为ON，需要注意的是此方法对global全局变量的设计进对于新开启的会话有效，对已开启的会话无效，同理，如果修改回哈session变量，可以使用session关键字，如set session autocommit = 1；这个仅对本session的变量配置有效，对其他的session无效；（在MySQL服务重启之后，数据库的配置重新按照my.ini文件 初始化，global和session 的配置都会失效） session当前会话 通信协议 Unix Socket TCP/IP Named Pipes命名管道 Share Memory共享内存 通信方式 单工 半双工 全双工 MySQL 缓存 12SHOW VARIABLES LIKE &#x27;query_cache%&#x27;#默认关闭，是因为mysql要保证两次执行的sql完全一致，连空格，大小写都一致，而且当数据表中的任何一条数据发生变化，整个缓存会失效； #2. 删除数据 1. 数据删除方式 DELETE Truncate Drop 2. 执行速度 drop &gt; truncate &gt; delete 2.1 DELETE 1DELETE FROM table_name WHERE XXX DELETE 数据数据库DML操作语言，只删除数据不删除表的结构，会走事务，执行时会触发trigger 在InnoDB中，delete其实并不会真的把数据删除，mysqL实际上只是给删除的数据打个标记为删除，因此delete删除表中的数据，表文件在磁盘所占的控件不会变小，存储控件不会被释放，只是把删除的数据设置为不可见。虽然未释放磁盘控件，但是下次插入数据的时候，仍然可以重用这部分空间（重用-&gt;覆盖） delete执行时，会先把所删除数据缓存到rollback segement中，事务commit之后生效 delete from table_name 删除表的全部数据对于MyISAM会释放磁盘控件，Innodb不会释放磁盘空间 对于DELETE from table_name where xxx带条件的删除，不管是Innodb还是MyISAM都不会释放磁盘控件 delete 操作以后使用optimize table table_name会里级释放磁盘空间（不管是Innodb还是MyISAM） 123456--查看表占用磁盘空间大小select concat(round(sum(DATA_LENGTH/1024/1024),2),&#x27;M&#x27;) as table_sizefrom information_schema.tables where table_schema=&#x27;demo_db&#x27; AND table_name=&#x27;demo_table&#x27;;-- 执行空间优化语句，以及执行后的表size变化optimize table demo_table delete 操作时一行一行执行删除的，并且同时将该行的删除操作日志记录在redo和undo表空间中以便进行回滚（rollback）和重做操作，生成大量日志也会占用磁盘空间 2.2 Truncate 123--删除表数据， 不带where条件--与不带where的delete ：只删除数据，而不删除表的结构 Truncate table table_name Truncate数据数据库DDL定义语言，不走事务，原数据不放到rollback segement中，操作不触发trigger，执行后里级生效，无法找回； truncate table table_name里级释放磁盘空间不管是Innodb 和MyISAM；truncate table其实有点类似余drop table然后create，只不过这个crate table的过程做了优化，比如表结构文件之前已经有了等，所以速度上应该是接近drop table的速度 truncate 能快速清空一个表，并且重置auto_increment的值 ​ 但是对于不同的类型存储引擎需要注意的地方是： 对于MyISAM：truncate会重置auto_increment（自增序列）的值为1，而delete后表仍然保持auto_increment。 对于Innodb：truncate会重置auto_increment（自增序列）的值为1， 而delete后表仍然保持auto_increment。但是在做delete整个表之后重启mysql的话，而重启后的auto_increment会被置为1 也就是说，Innodb的表本身是无法持久保存auto_increment。delete表之后auto_increment仍然保存在内存，但是重启后就丢失了，只能从1开始，实质上重启后的auto_increment会从SELETE 1+MAX(ai_col) FROM t开始 小心使用 truncate，尤其没有备份的时候，如果误删除线上的表，记得及时联系中国民航，订票电话：400-806-9553 2.3 Drop 12-- 删除表结构以及表数据Drop table table_name drop：属于数据库DDL定义语言，同Truncate； 执行后立即生效，无法找回！ 执行后立即生效，无法找回！ 执行后立即生效，无法找回！ **drop table table_name 立刻释放磁盘空间 ，不管是 InnoDB 和 MyISAM; **drop 语句将删除表的结构被依赖的约束(constrain)、触发器(trigger)、索引(index); 依赖于该表的存储过程/函数将保留,但是变为 invalid 状态。 小心使用 drop ，要删表跑路的兄弟，请在订票成功后在执行操作！订票电话：400-806-9553 3. 总结 可以这么理解，一本书，delete是把目录撕了，truncate是把书的内容撕下来烧了，drop是把书烧了","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"锁优化","slug":"lock01","date":"2021-07-23T06:04:02.000Z","updated":"2022-03-27T14:06:03.480Z","comments":true,"path":"lock01/","link":"","permalink":"https://xiaoyuge5201.github.io/lock01/","excerpt":"","text":"1. 优化思路以及方法 减少锁持有时间 减小锁粒度 锁分离 锁粗化 锁消除 1.1 减少锁持有时间 12345public synchronized void syncMethod()&#123; othercode1(); mutextMethod(); othercode2();&#125; 像上述代码，在进入方法前就要得到锁，其他线程就要在外面等待。 分析：锁里面的资源在同一时间只允许一个线程执行，我们不仅要减少其他线程等待的时间，也要尽力减少线程在锁里面的执行时间，所以，尽量只有在有线程安全要求的程序代码上加锁。 1234567public void syncMethod()&#123; othercode1(); synchronized(this)&#123; metextMethod(); &#125; othercode2();&#125; 1.2 减小锁粒度 将大对象（这个对象可能会被很多线程访问）拆成小对象，大大增加并行度。 降低锁竞争，那么偏向锁、轻量级锁成功率才会提高。 最最典型的减小锁粒度的案例就是ConcurrentHashMap。在HashMap的基础上进行优化，使用了cas与synchronized来确保安全性，在保证安全性的基础上为了充分利用线程资源，更是巧妙的设计了多线程同扩容的模式。 1.3 锁分离 最常见的锁分离就是读写锁ReadWriteLock，根据功能进行分离成读锁和写锁。这样读读不互斥，读写互斥，写写互斥。既保证了线程安全，又提高了性能。 分析：读写分离这种思想可以延伸到我们其他的设计中，只要操作上互不影响，那锁就可以进行分离，比如：LinkedBlockingQueue 从头部获取数据，从尾部放入数据，使用两把锁。 1.4 锁粗化 通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁，只有这样，等待在这个锁上的其他线程才能尽早的获取资源执行任务；但是凡事都有一个度，如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化。 123456789public void demoMethod()&#123; synchronized&#123; //dow sth.true&#125; //....做其他不需要同步的工作，但能很快执行完毕 synchronized&#123; //do sth. &#125;&#125; 这种情况，根据锁粗化的思想，应该合并： 1234567public void demoMethod()&#123; //整合成一次锁请求,前提时中间哪些不需要同步的工作很快就执行完成 synchronized(lock)&#123; //do sth. //....做其他不需要同步的工作，但能很快执行完毕 &#125;&#125; 再举一个极端的例子： 12345for(int i =0; i &lt; circle; i++)&#123; synchronized(lock)&#123; //..... &#125;&#125; 在一个循环内不同得获得锁。虽然JDK内部会对这个代码做些优化，但是还不如直接写成： 1234synchronized(lock)&#123; for(int i =0; i &lt; circle; i++)&#123; &#125;&#125; 当然如果有需求说，这样的循环太久，需要给其他线程不要等待太久，那只能写成上面那种。如果没有这样类似的需求，还是直接写成后者那种比较好。 分析: 锁粗化是JVM默认启动的一种机制，锁粗化针对的是对连续的区域进行分段加锁这种场景，JVM会自发进行优化。但作为开发者而言在满足业务的情况下，应该减少锁的使用。 1.5 锁消除 锁消除是在编译器级别的事情。在即时编译器(JIT)时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作。也许你会觉得奇怪，既然有些对象不可能被多线程访问，那为什么要加锁呢？写代码时直接不加锁不就好了。 但是有时，这些锁并不是程序员所写的，有的是JDK实现中就有锁的，比如Vector和StringBuffer这样的类，它们中的很多方法都是有锁的。当我们在一些不会有线程安全的情况下使用这些类的方法时，达到某些条件时，编译器会将锁消除来提高性能。 1234567891011121314public static void main(String args[]) throws InterrruptedException&#123; long start = System.currentTimeTimeMillis(); for(int i = 0;i &lt; 20000; i++)&#123; createStringBuffer(&quot;JVM&quot;,&quot;asdfasdfasdf&quot;); &#125; long bufferCost = System.currentTimeTimeMillis() - start; System.out.println(&quot;createStringBuffer:&quot;+bufferCost+&quot;ms&quot;);&#125;public static String createStringBuffer(String s1, String s2)&#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString();&#125; 上述代码中的StringBuffer.append是一个同步操作，但是StringBuffer却是一个局部变量，并且方法也并没有把StringBuffer返回，所以不可能会有多线程去访问它。那么此时StringBuffer中的同步操作就是没有意义的。 开启锁消除是在JVM参数上设置的，当然需要在server模式下： 1-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks 并且要开启逃逸分析。 逃逸分析的作用呢，就是看看变量是否有可能逃出作用域的范围。 比如上述的StringBuffer，上述代码中craeteStringBuffer的返回是一个String，所以这个局部变量StringBuffer在其他地方都不会被使用。如果将craeteStringBuffer改成 123456public static StringBuffer createStringBuffer(String s1, String s2)&#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb;&#125; 那么这个 StringBuffer被返回后，是有可能被任何其他地方所使用的（譬如被主函数将返回结果put进map啊等等）。那么JVM的逃逸分析可以分析出，这个局部变量 StringBuffer逃出了它的作用域。 所以基于逃逸分析，JVM可以判断，如果这个局部变量StringBuffer并没有逃出它的作用域，那么可以确定这个StringBuffer并不会被多线程所访问，那么就可以把这些多余的锁给去掉来提高性能。 当JVM参数为： 1-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks 输出： 1createStringBuffer: 302ms JVM参数为： 1-server -XX:+DoEscapeAnalysis -XX:-EliminateLocks 输出： 1createStringBuffer: 660ms 显然，锁消除的效果还是很明显的。","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"lock","slug":"lock","permalink":"https://xiaoyuge5201.github.io/tags/lock/"}]},{"title":"ElasticSearch安装","slug":"ElasticSearch","date":"2021-07-23T05:41:24.000Z","updated":"2022-03-27T14:06:03.362Z","comments":true,"path":"ElasticSearch/","link":"","permalink":"https://xiaoyuge5201.github.io/ElasticSearch/","excerpt":"","text":"1. JDK14安装 下载jdk14： https://jdk.java.net/14/ 将文件存放在linux系统某文件夹内 解压 1tar -zxvf openjdk-14.0.2_linux-x64_bin.tar.gz 配置环境变量 123456vim /etc/profile##在文件最末尾添加，其中JAVA_HOME是jdk解压后的文件路径JAVA_HOME=/usr/lib/tools/jdk-14.0.2PATH=$JAVA_HOME/bin:$PATHCLASSPATH=$JAVA_HOME/jre/lib/ext:$JAVA_HOME/lib/tools.jarexport PATH JAVA_HOME CLASSPATH 保存后，更新配置文件 1source /etc/profile 查看JDK是否配置完成 1java -version 出现下图表示安装成功！ 2. ElasticSearch安装 解压tar.gz包 1tar -zxvf elasticsearch-7.8.0-linux-x86_64.tar.gz 添加elasticsearch用户 1useradd elastic 赋予elastic search操作文件夹的权限 1chown -R elastic:elastic /usr/lib/tools/elasticsearch-7.8.0/* 查看本机的hostname 12hostname#localhost.localdomain 修改elastic search配置 12 cd ./elasticsearch-7.8.0/configvim elasticsearch.yml elasticsearch.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#集群名称，默认可以不修改，此处 xiaoyugecluster.name: xiaoyuge# ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#节点名称，必须修改 ，默认修改为当前机器名称，若是多实例则需要区分node.name: xiaoyuge-local1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):##数据目录与日志目录，默认在当前运行程序下，生产环境需要指定#path.data: /path/to/data## Path to log files:##path.logs: /path/to/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:#内存交换锁定，此处需要操作系统设置才生效#bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#IP 地址，默认是 local，仅限本机访问，外网不可访问，设置 0.0.0.0 通用做法network.host: 192.168.135.111## Set a custom port for HTTP:#访问端口，默认 9200，9300，建议明确指定http.port: 9200transport.port: 9300## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]## 集群发现配置discovery.seed_hosts: [&quot;192.168.135.111:9300&quot;]## Bootstrap the cluster using an initial set of master-eligible nodes:#cluster.initial_master_nodes: [&quot;192.168.135.111:9300&quot;]## For more information, consult the discovery and cluster formation module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##防止批量删除索引action.destructive_requires_name: true#设置密码xpack.security.enabled: truexpack.license.self_generated.type: trialxpack.security.transport.ssl.enabled: truehttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;http.cors.allow-headers: Authorization 切换为elastic search用户，然后启动elastic search 12su elastic #切换用户./bin/elasticsearch -d #后台启动 设置密码 12345678910111213141516171819202122232425./bin/elasticsearch-setup-passwords interactive#执行设置用户名和密码的命令,这里需要为4个用户分别设置密码，elastic, kibana, logstash_system,beats_systemInitiating the setup of passwords for reserved users elastic,kibana,logstash_system,beats_system.You will be prompted to enter passwords as the process progresses.Please confirm that you would like to continue [y/N]yEnter password for [elastic]:passwords must be at least [6] characters longTry again.Enter password for [elastic]:Reenter password for [elastic]:Passwords do not match.Try again.Enter password for [elastic]:Reenter password for [elastic]:Enter password for [kibana]:Reenter password for [kibana]:Enter password for [logstash_system]:Reenter password for [logstash_system]:Enter password for [beats_system]:Reenter password for [beats_system]:Changed password for user [kibana]Changed password for user [logstash_system]Changed password for user [beats_system]Changed password for user [elastic] 常见异常： 1234 #java.lang.RuntimeException: can not run elasticsearch as root #切换为elastic search用户，不能用root项目启动 su elastic 12345#Exception in thread &quot;main&quot; java.nio.file.AccessDeniedException: /usr/lib/tools/elasticsearch-7.8.0/config/elasticsearch.keystore#elastic search用户没有操作该文件夹的权限 su rootchown -R elastic:elastic /usr/lib/tools/elasticsearch-7.8.0/* 123456789101112131415161718ERROR: [2] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] #分配内存不够#1. 修改 /etc/security/limits.confsudo vi /etc/security/limits.conf#在文件末尾加上* soft nofile 65536* hard nofile 65536* soft nproc 4096* hard nproc 4096#2. 修改 /etc/sysctl.confsudo vi /etc/sysctl.conf#在文件末尾增加vm.max_map_count=262144#3. 配置重新生效sysctl -p 效果如下： 3. Kibana安装 解压文件 1tar -zxvf kibana-7.8.0-linux-x86_64.tar.gz 修改配置文件 1vim ./config/kibana.yml kibana.yml: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Kibana is served by a back end server. This setting specifies the port to use.##访问端口，默认无需修改server.port: 5601# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.# The default is &#x27;localhost&#x27;, which usually means remote machines will not be able to connect.# To allow connections from remote users, set this parameter to a non-loopback address.#访问地址 IP，默认本地 ;如果需要外网访问，则配置0.0.0.0server.host: &quot;0.0.0.0&quot;# Enables you to specify a path to mount Kibana at if you are running behind a proxy.# Use the `server.rewriteBasePath` setting to tell Kibana if it should remove the basePath# from requests it receives, and to prevent a deprecation warning at startup.# This setting cannot end in a slash.#server.basePath: &quot;&quot;# Specifies whether Kibana should rewrite requests that are prefixed with# `server.basePath` or require that they are rewritten by your reverse proxy.# This setting was effectively always `false` before Kibana 6.3 and will# default to `true` starting in Kibana 7.0.#server.rewriteBasePath: false# The maximum payload size in bytes for incoming server requests.#server.maxPayloadBytes: 1048576# The Kibana server&#x27;s name. This is used for display purposes.#server.name: &quot;your-hostname&quot;# The URLs of the Elasticsearch instances to use for all your queries.# ES 服务指向，集群下配置多个elasticsearch.hosts: [&quot;http://192.168.135.111:9200&quot;]# When this setting&#x27;s value is true Kibana uses the hostname specified in the server.host# setting. When the value of this setting is false, Kibana uses the hostname of the host# that connects to this Kibana instance.#elasticsearch.preserveHost: true# Kibana uses an index in Elasticsearch to store saved searches, visualizations and# dashboards. Kibana creates a new index if the index doesn&#x27;t already exist.# Kibana 元数据存储索引名字，默认.kibana 无需修改#kibana.index: &quot;.kibana&quot;# The default application to load.#kibana.defaultAppId: &quot;home&quot;# If your Elasticsearch is protected with basic authentication, these settings provide# the username and password that the Kibana server uses to perform maintenance on the Kibana 启动 1234 # 当前窗口内启动 ./bin/kibana# #后台进程启动nohup ./bin/kibana &amp; 效果如下 遇见问题： root启动报错 12#切换到elastic账户su xiaoyuge elastic用户权限不足 Babel could not write cache to file: /usr/share/kibana/optimize/.babel_register_cache.json 1234567#切换到root用户su root #赋予elastic账户 xiaoyuge操作权限chown -R xiaoyuge /usr/local/kibana-7.7.1-linux-x86_64#切换为elastic账户su xiaoyuge#再次启动即可","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://xiaoyuge5201.github.io/tags/ELK/"}]},{"title":"vue学习","slug":"vue","date":"2021-07-23T03:40:44.000Z","updated":"2022-04-25T07:02:49.241Z","comments":true,"path":"vue/","link":"","permalink":"https://xiaoyuge5201.github.io/vue/","excerpt":"","text":"Object.freeze()，这会阻止修改现有的 property，也意味着响应系统无法再追踪变化。 1. export 用于规定模块的对外接口，export输出变量和方法、类 变量 1234567// profile.jsexport var firstName = &#x27;Michael&#x27;;export var lastName = &#x27;Jackson&#x27;;export var year = 1958;//简写--优先使用export &#123;firstName, lastName, year&#125; 方法 123//如果想为输入的变量重新命名， 可以使用AS 关键字重新命名import &#123; buildMenus as buildMenus&#125; from &#x27;@/api/menu&#x27;;//import命令接受一对大括号，里面指定要从其他模块导入的变量名。大括号里面的变量名，必须与被导入模块（profile.js）对外接口的名称相同 2. export default 为模块指定默认输出， 使用import命令的时候，用户需要知道所要加载的变量名和函数名，否则无法加载；了解模块有哪些方法和属性比较麻烦，使用export default命令，为模块指定默认输出 1234// export-default.jsexport default function () &#123; console.log(&#x27;foo&#x27;);&#125; 上面代码是一个模块文件export-default.js。默认输出1个函数； 与export命令的区别：其他模块加载该模块是，import命令可以为该匿名函数指定任意名字 123// import-default.jsimport customName from &#x27;./export-default&#x27;;customName(); // &#x27;foo&#x27; 上面代码的import命令，可以用任意名称指向export-default.js输出的方法，这时就不需要知道原模块输出的函数名。需要注意的是，这时import命令后面，不使用大括号。 本质上，export default就是输出一个叫做default的变量或方法，然后系统允许你为它取任意名字。所以，下面的写法是有效的。 123456789101112// modules.jsfunction add(x, y) &#123; return x * y;&#125;export &#123;add as default&#125;;// 等同于// export default add;// app.jsimport &#123; default as foo &#125; from &#x27;modules&#x27;;// 等同于// import foo from &#x27;modules&#x27;; 正是因为export default命令其实只是输出一个叫做default的变量，所以它后面不能跟变量声明语句。 总结： export命令对外接口是有名称的且import命令从模块导入的变量名与被导入模块对外接口的名称相同，而export default命令对外输出的变量名可以是任意的，这时import命令后面，不使用大括号。 export default命令用于指定模块的默认输出。显然，一个模块只能有一个默认输出，因此export default命令只能使用一次。所以，import命令后面才不用加大括号，因为只可能唯一对应export default命令。 12345678910111213141516171819202122232425262728293031323334//menu.js//get请求获取所有的菜单信息export function buildMenus() &#123; return request(&#123; url: &#x27;api/menus/build&#x27;, method: &#x27;get&#x27; &#125;)&#125;//post 请求保存数据export function add(data) &#123; return request(&#123; url: &#x27;api/menus&#x27;, method: &#x27;post&#x27;, data &#125;)&#125;//delete 请求删除数据export function del(id) &#123; return request(&#123; url: &#x27;api/menus/&#x27; + id, method: &#x27;delete&#x27; &#125;)&#125;//put请求修改数据export function edit(data) &#123; return request(&#123; url: &#x27;api/menus&#x27;, method: &#x27;put&#x27;, data &#125;)&#125;//app.vueimport &#123; buildMenus &#125; from &#x27;@/api/menu&#x27;; 3. Const、var、let ES5 中作用域有：全局作用域、函数作用域。没有块作用域的概念。 ES6 中新增了块级作用域。块作用域由 { } 包括，if语句和 for语句里面的{ }也属于块作用域 12345678910111213141516171819202122232425&#123; var a = 1; console.log(a); // 1&#125;console.log(a); // 1// 通过var定义的变量可以跨块作用域访问到。(function A() &#123; var b = 2; console.log(b); // 2&#125;)();// console.log(b); // 报错，// 可见，通过var定义的变量不能跨函数作用域访问到if(true) &#123; var c = 3;&#125;console.log(c); // 3for(var i = 0; i &lt; 4; i ++) &#123; var d = 5;&#125;;console.log(i); // 4 (循环结束i已经是4，所以此处i为4)console.log(d); // 5// if语句和for语句中用var定义的变量可以在外面访问到，// 可见，if语句和for语句属于块作用域，不属于函数作用域 三者的区别： var定义的变量，没有块的概念，可以跨块访问, 不能跨函数访问。 let定义的变量，只能在块作用域里访问，不能跨块访问，也不能跨函数访问。 const用来定义常量，使用时必须初始化(即必须赋值)，只能在块作用域里访问，而且不能修改。 1234567891011121314151617181920212223242526272829303132// 块作用域&#123; var a = 1; let b = 2; const c = 3; // c = 4; // 报错 var aa; let bb; // const cc; // 报错 console.log(a); // 1 console.log(b); // 2 console.log(c); // 3 console.log(aa); // undefined console.log(bb); // undefined&#125;console.log(a); // 1// console.log(b); // 报错// console.log(c); // 报错// 函数作用域(function A() &#123; var d = 5; let e = 6; const f = 7; console.log(d); // 5 console.log(e); // 6 console.log(f); // 7 &#125;)();// console.log(d); // 报错// console.log(e); // 报错// console.log(f); // 报错 注意：const定义的对象属性是否可以改变 123456const person = &#123; name : &#x27;jiuke&#x27;, sex : &#x27;男&#x27;&#125;person.name = &#x27;test&#x27;console.log(person.name)//person对象的name属性确实被修改了 因为对象是引用类型的，person中保存的仅是对象的指针，这就意味着，const仅保证指针不发生改变，修改对象的属性不会改变对象的指针，所以是被允许的。也就是说const定义的引用类型只要指针不发生改变，其他的不论如何改变都是允许的。 然后我们试着修改一下指针，让person指向一个新对象，果然报错 123456789const person = &#123; name : &#x27;jiuke&#x27;, sex : &#x27;男&#x27;&#125;person = &#123; name : &#x27;test&#x27;, sex : &#x27;男&#x27;&#125;//报错 4. promise promise用途：异步编程的一种解决方案。 优点：比传统的解决方案——回调函数和事件——更合理和更强大。 三种状态：pending（进行中）、fulfilled（已成功）和rejected（已失败）。 123456789101112131415161718//基本用法：const promise = new Promise(function(resolve, reject) &#123; resolve(value);//表示异步操作成功 reject(error);//表示异步操作失败&#125;);//promise常用的几个方法//1. 异步状态为成功时调用第一个函数，为失败时调用第二个函数。then方法的第二个参数可选。promise.then(value =&gt; &#123;&#125;,error =&gt; &#123;&#125;);//2. 异步状态为失败时调用。promise.catch(error =&gt; &#123;&#125;);//3. promise异步状态为失败时或then方法中抛出错误都会执行catch方法。promise.then(value =&gt; &#123;&#125;,error =&gt; &#123;&#125;).catch(error =&gt; &#123;&#125;);//4. 不管状态如何都会执行的操作。promise.finally(() =&gt; &#123;&#125;); 5. 生命周期 6. 模版语法 v-once 执行一次性插值，当数据变化的时候，该内容不会更新；可能会影响该节点其他的数据绑定 1&lt;span v-once&gt;这个将不会改变: &#123;&#123; msg &#125;&#125;&lt;/span&gt; v-html 双大括号会将数据解释为普通文本，而非 HTML 代码。为了输出真正的 HTML，你需要使用v-html; 1234var rawHtml = &quot;&lt;span&gt;这是个使用v-htmls&lt;/span&gt;&quot;&lt;p&gt;Using mustaches: &#123;&#123; rawHtml &#125;&#125;&lt;/p&gt;&lt;p&gt;Using v-html directive: &lt;span v-html=&quot;rawHtml&quot;&gt;&lt;/span&gt;&lt;/p&gt; Attribute Mustache ({}) 语法不能作用在 HTML attribute 上，遇到这种情况应该使用 v-bind 指令： 12345&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt;//isButtonDisabled 的值是 null、undefined 或 false，则 disabled attribute 甚至不会被包含在渲染出来的 &lt;button&gt; 元素中&lt;button v-bind:disabled=&quot;isButtonDisabled&quot;&gt;Button&lt;/button&gt; 三元表达式 1234567891011121314&#123;&#123; number + 1 &#125;&#125;&#123;&#123; ok ? &#x27;YES&#x27; : &#x27;NO&#x27; &#125;&#125;&#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;&lt;div v-bind:id=&quot;&#x27;list-&#x27; + id&quot;&gt;&lt;/div&gt;//这些表达式会在所属 Vue 实例的数据作用域下作为 JavaScript 被解析。有个限制就是，每个绑定都只能包含单个表达式，所以下面的例子都不会生效。&lt;!-- 这是语句，不是表达式 --&gt;&#123;&#123; var a = 1 &#125;&#125;&lt;!-- 流控制也不会生效，请使用三元表达式 --&gt;&#123;&#123; if (ok) &#123; return message &#125; &#125;&#125; 7. 指令Directives 指令 (Directives) 是带有 v- 前缀的特殊 attribute。指令 attribute 的值预期是单个 JavaScript 表达式 (v-for 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。 12//v-if 指令将根据表达式 seen 的值的真假来插入/移除 &lt;p&gt; 元素。&lt;p v-if=&quot;seen&quot;&gt;现在你看到我了&lt;/p&gt; 参数 一些指令能够接收一个“参数”，在指令名称之后以冒号表示。例如，v-bind 指令可以用于响应式地更新 HTML attribute 1234//href 是参数，告知 v-bind 指令将该元素的 href attribute 与表达式 url 的值绑定&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt; 动态参数 2.6.0 开始，可以用方括号括起来的 JavaScript 表达式作为一个指令的参数 12345&lt;a v-bind:[attributeName] = &quot;url&quot;&gt;&lt;/a&gt;&lt;!-- 这里的attributeName会被作为一个javascript表达式进行动态赋值，求得的值会作为最终的参数来使用如果VUE实例有一个data. property. attributeName， 其值为href， 那么绑定将等价于v-bind:href---&gt; 绑定处理函数： 1&lt;a v-on:[eventName]=&quot;dosomething&quot;&gt;&lt;/a&gt; 对动态参数的值的约束 动态参数预期会求出一个字符串，异常情况下值为 null。这个特殊的 null 值可以被显性地用于移除绑定。任何其它非字符串类型的值都将会触发一个警告。 对动态参数表达式的约束 动态参数表达式有一些语法约束，因为某些字符，如空格和引号，放在 HTML attribute 名里是无效的。例如： 修饰符 修饰符（modifier）是以半角句号. 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定；例如.prevent修饰符告诉v-on指令对触发的事件调用event.preventDefault(); 123&lt;form v-on:submit.prevent = &quot;onSubmit&quot;&gt; &lt;/form&gt; 缩写 123456789101112131415161718&lt;!-- 完整语法 --&gt;&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a :href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;!-- 动态参数的缩写 (2.6.0+) --&gt;&lt;a :[key]=&quot;url&quot;&gt; ... &lt;/a&gt;&lt;!-- 完整语法 --&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a @click=&quot;doSomething&quot;&gt;...&lt;/a&gt;&lt;!-- 动态参数的缩写 (2.6.0+) --&gt;&lt;a @[event]=&quot;doSomething&quot;&gt; ... &lt;/a&gt; : 与 @ 对于 attribute 名来说都是合法字符，在所有支持 Vue 的浏览器都能被正确地解析。而且，它们不会出现在最终渲染的标记中。 8. 计算属性 123&lt;div id=&quot;example&quot;&gt; &#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;&lt;/div&gt; 这里是想要显示变量 message 的翻转字符串。当你想要在模板中的多处包含此翻转字符串时，就会更加难以处理。 所以，对于任何复杂逻辑，你都应当使用计算属性 例如： 1234&lt;div id=&quot;example&quot;&gt; &lt;p&gt;Original message: &quot;&#123;&#123; message &#125;&#125;&quot;&lt;/p&gt; &lt;p&gt;Computed reversed message: &quot;&#123;&#123; reversedMessage &#125;&#125;&quot;&lt;/p&gt;&lt;/div&gt; 1234567891011121314151617var vm = new Vue(&#123; el: &#x27;#example&#x27;, data: &#123; message: &#x27;Hello&#x27; &#125;, computed: &#123; // 计算属性的 getter reversedMessage: function () &#123; // `this` 指向 vm 实例 return this.message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125; &#125;&#125;)//页面显示：//Original message: &quot;Hello&quot;//Computed reversed message: &quot;olleH&quot; 声明了一个计算属性reversedMessage；我们提供的函数将用作property vm.reversedMessage的getter函数 123console.log(vm.reversedMessage) // olleHvm.message = &#x27;Goodbye&#x27;console.log(vm.reversedMessage) // =&gt; &#x27;eybdooG&#x27; 你可以打开浏览器的控制台，自行修改例子中的 vm。vm.reversedMessage 的值始终取决于 vm.message 的值。 你可以像绑定普通 property 一样在模板中绑定计算属性。Vue 知道 vm.reversedMessage 依赖于 vm.message，因此当 vm.message 发生改变时，所有依赖 vm.reversedMessage 的绑定也会更新。以声明的方式创建了这种依赖关系：计算属性的 getter 函数是没有副作用 (side effect) 的。 计算属性 VS 方法 使用表达式中调用方法同样可以达到上面的结果 1&lt;p&gt;Reversed message: &quot;&#123;&#123; reversedMessage() &#125;&#125;&quot;&lt;/p&gt; 123456// 在组件中methods: &#123; reversedMessage: function () &#123; return this.message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125; 我们可以将同一函数定义为一个方法而不是一个计算属性。两种方式的最终结果确实是完全相同的。然而，不同的是计算属性是基于它们的响应式依赖进行缓存的。只在相关响应式依赖发生改变时它们才会重新求值。这就意味着只要 message 还没有发生改变，多次访问 reversedMessage 计算属性会立即返回之前的计算结果，而不必再次执行函数。 这也同样意味着下面的计算属性将不再更新，因为 Date.now() 不是响应式依赖： 12345computed: &#123; now: function () &#123; return Date.now() &#125;&#125; 相比之下，每当触发重新渲染时，调用方法将总会再次执行函数。 我们为什么需要缓存？假设我们有一个性能开销比较大的计算属性 A，它需要遍历一个巨大的数组并做大量的计算。然后我们可能有其他的计算属性依赖于 A。如果没有缓存，我们将不可避免的多次执行 A 的 getter！如果你不希望有缓存，请用方法来替代。 计算属性 VS 侦听属性 侦听属性：vue提供了一种更通用的方式来观察和响应vue实例上的数据变动；当有一些数据需要随着其他数据变动而变动时；很容易滥用watch;通常更好的做法是使用计算属性而不是命令式的watch回调； 1&lt;div id=&quot;demo&quot;&gt;&#123;&#123; fullName &#125;&#125;&lt;/div&gt; 123456789101112131415161718192021222324var vm = new Vue(&#123; el: &#x27;#demo&#x27;, data: &#123; firstName: &#x27;Foo&#x27;, lastName: &#x27;Bar&#x27;, fullName: &#x27;Foo Bar&#x27; &#125;, //侦听属性watch watch: &#123; firstName: function (val) &#123; this.fullName = val + &#x27; &#x27; + this.lastName &#125;, lastName: function (val) &#123; this.fullName = this.firstName + &#x27; &#x27; + val &#125; &#125;, //计算属性 computed: &#123; fullName: function () &#123; return this.firstName + &#x27; &#x27; + this.lastName &#125; &#125;&#125;) 计算属性的setter 计算属性默认只有getter，自己可以提供一个setter 1234567891011121314computed: &#123; fullName: &#123; // getter get: function () &#123; return this.firstName + &#x27; &#x27; + this.lastName &#125;, // setter set: function (newValue) &#123; var names = newValue.split(&#x27; &#x27;) this.firstName = names[0] this.lastName = names[names.length - 1] &#125; &#125;&#125; 现在再运行 vm.fullName = 'John Doe' 时，setter 会被调用，vm.firstName 和 vm.lastName 也会相应地被更新。 9. 侦听器 当需要在数据变化时执行异步或开销较大的操作时，watch是最有用的；同时也可以自定义侦听器； 1234567&lt;div id=&quot;watch-example&quot;&gt; &lt;p&gt; Ask a yes/no question: &lt;input v-model=&quot;question&quot;&gt; &lt;/p&gt; &lt;p&gt;&#123;&#123; answer &#125;&#125;&lt;/p&gt;&lt;/div&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!-- 因为 AJAX 库和通用工具的生态已经相当丰富，Vue 核心代码没有重复 --&gt;&lt;!-- 提供这些功能以保持精简。这也可以让你自由选择自己更熟悉的工具。 --&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/axios@0.12.0/dist/axios.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/lodash@4.13.1/lodash.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;var watchExampleVM = new Vue(&#123; el: &#x27;#watch-example&#x27;, data: &#123; question: &#x27;&#x27;, answer: &#x27;I cannot give you an answer until you ask a question!&#x27; &#125;, watch: &#123; // 如果 `question` 发生改变，这个函数就会运行 question: function (newQuestion, oldQuestion) &#123; this.answer = &#x27;Waiting for you to stop typing...&#x27; this.debouncedGetAnswer() &#125; &#125;, created: function () &#123; // `_.debounce` 是一个通过 Lodash 限制操作频率的函数。 // 在这个例子中，我们希望限制访问 yesno.wtf/api 的频率 // AJAX 请求直到用户输入完毕才会发出。想要了解更多关于 // `_.debounce` 函数 (及其近亲 `_.throttle`) 的知识， // 请参考：https://lodash.com/docs#debounce this.debouncedGetAnswer = _.debounce(this.getAnswer, 500) &#125;, methods: &#123; getAnswer: function () &#123; if (this.question.indexOf(&#x27;?&#x27;) === -1) &#123; this.answer = &#x27;Questions usually contain a question mark. ;-)&#x27; return &#125; this.answer = &#x27;Thinking...&#x27; var vm = this axios.get(&#x27;https://yesno.wtf/api&#x27;) .then(function (response) &#123; vm.answer = _.capitalize(response.data.answer) &#125;) //异常捕获 .catch(function (error) &#123; vm.answer = &#x27;Error! Could not reach the API. &#x27; + error &#125;) &#125; &#125;&#125;)&lt;/script&gt; 使用 watch 选项允许我们执行异步操作 (访问一个 API)，限制我们执行该操作的频率，并在我们得到最终结果前，设置中间状态。这些都是计算属性无法做到的 10. class与style绑定 将 v-bind 用于 class 和 style 时，Vue.js 做了专门的增强。表达式结果的类型除了字符串之外，还可以是对象或数组 10.1 绑定html class 10.1.1对象语法 方式一：内联 123456789&lt;div class=&quot;static&quot; v-bind:class=&quot;&#123; active: isActive, &#x27;text-danger&#x27;: hasError &#125;&quot;&gt;&lt;/div&gt;//datadata: &#123; isActive: true, hasError: false&#125; 方式二：绑定的数据对象不必内联定义在模板里 12345678&lt;div v-bind:class=&quot;classObject&quot;&gt;&lt;/div&gt;//vue datadata: &#123; classObject: &#123; active: true, &#x27;text-danger&#x27;: false &#125;&#125; 方式三：绑定一个返回对象的计算属性（常用） 123456789101112131415&lt;div v-bind:class=&quot;classObject&quot;&gt;&lt;/div&gt;//vue datadata: &#123; isActive: true, error: null&#125;,computed: &#123; classObject: function () &#123; return &#123; active: this.isActive &amp;&amp; !this.error, &#x27;text-danger&#x27;: this.error &amp;&amp; this.error.type === &#x27;fatal&#x27; &#125; &#125;&#125; 10.1.2 数组语法","categories":[{"name":"架构师笔记","slug":"架构师笔记","permalink":"https://xiaoyuge5201.github.io/categories/%E6%9E%B6%E6%9E%84%E5%B8%88%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://xiaoyuge5201.github.io/tags/vue/"}]},{"title":"springCloud之FeignClient访问微服务接口缓慢","slug":"bug-sprigCloud","date":"2021-07-03T09:08:10.000Z","updated":"2022-03-27T14:06:03.465Z","comments":true,"path":"bug-sprigCloud/","link":"","permalink":"https://xiaoyuge5201.github.io/bug-sprigCloud/","excerpt":"","text":"问题描述 逻辑是A服务调用B服务(AB在同一个局域网内)。 经过反复测试，有一个访问缓慢的现象，具体表现为： 程序启动第一次访问初始化1.2秒左右，还可以理解。 但后面访问还是要1.1秒左右（格式化到SSS毫秒打印日志监控的）。 但如果连续访问几次，后面几次又是几十毫秒。过一会再访问，或者换浏览器换post工具请求，又会1.2秒左右。 原因排查1 查看连接查实的接口 发现接口调用的是这个地址，其实是别人启动项目的时候吧自己的ip注册到了eureka注册中心，导致接口有时候走的是getway，有时候又是走的别人的接口 解决方法：eureka.client.register-with-eureka 为false 这样就不会注册到eureka注册中心了 原因排查2 查看日志 查看是否是hystrix 配置的时间小于了ribbon的时间","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://xiaoyuge5201.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://xiaoyuge5201.github.io/tags/SpringCloud/"}]},{"title":"ConcurrentHashMap线程安全","slug":"ConcurrentHashMap","date":"2021-07-02T08:17:29.000Z","updated":"2022-03-27T14:06:03.445Z","comments":true,"path":"ConcurrentHashMap/","link":"","permalink":"https://xiaoyuge5201.github.io/ConcurrentHashMap/","excerpt":"","text":"##1. jdk1.7 ConcurrentHashMap jdk1.7 ConcurrentHashMap是由一个Segment数组和多个HashEntry数组组成 其实就是将HashMap分为多个小HashMap,每个Segment元素维护一个小HashMap,目的是锁分离，本来实现同步，直接可以是对整个HashMap加锁，但是加锁粒度太大，影响并发性能，所以变换成此结构，仅仅对Segment元素加锁，降低锁粒度，提高并发性能 ###1.1 初始化过程 由于变换成Segment数组+HashEntry数组，所以初始化时，需要依次对Segment数组和HashEntry数组初始化 Segment数组初始化 初始化时，使用右移一位，乘以2的计算方式，保证ssize是2的幂次方，小于指定参数concurrencyLevel的最大2的幂次方 1234567int sshift = 0;//记录Segment数组大小int ssize = 1;while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1;&#125; HashEntry数组初始化 跟Segment数组初始化方式相同 1234int cap = 1;while(cap &lt; c)&#123; cap &lt;&lt;=1;&#125; 1.2 put操作 对于插入操作，需要两次Hash映射去定位数据存储位置 首先通过第一次hash过程，定位Segment位置 然后通过第二次hash过程定位HashEntry位置 Segment继承ReentrantLock,在数据插入指定HashEntry过程的时候会尝试调用ReentrantLock的tryLock方法获取锁，如果获取成功就直接插入相应位置，如果有线程获取该Segment的锁，当前线程就会以自旋方式去继续调用tryLock方法去获取锁，超过指定次数就挂起，等待唤醒。 1.3 get操作 也是两次Hash映射，相对于put操作，少了加锁过程 1.4 size操作 size操作就是计算ConcurrentHashMap的大小，有两种方案 给每个Segment都加上锁(相当于给整个Map加上锁)，然后计算size返回 不加锁的模式，尝试多次计算ConcurrentHashMap的size,最多三次，比较前后计算的结果，结果一致就认为当前没有元素加入，计算结果是准确的。(查看计算出size的前后modCount的数值有没有发生变化，modCount的值用于记录元素变化的操作。如put，remove，clear) 2. jdk1.8 ConcurrentHashMap jdk1.8ConcurrentHashMap是数组+链表，或者数组+红黑树结构,并发控制使用Synchronized关键字和CAS操作 2.1关键概念点 sizeCtl变量(volatile修饰) 通过CAS操作+volatile, 控制数组初始化和扩容操作 -1 代表正在初始化 -N 前16位记录数组容量，后16位记录扩容线程大小+1，是个负数 正数0，表示未初始化 正数，0.75*当前数组大小 &lt;key,value&gt;键值对，封装为Node对象 table变量(volatile)：也就是所说的数组，默认为null，默认大小为16的数组，每次扩容时大小总是2的幂次方 nextTable(volatile):扩容时新生成的数组，大小为table的两倍 2.2put函数 123public V put(K key, V value) &#123; return putVal(key, value, false);&#125; 1.putValue函数 首先调用spread函数，计算hash值，之后进入一个自旋循环过程，直到插入或替换成功，才会返回。如果table未被初始化，则调用initTable进行初始化。之后判断hash映射的位置是否为null,如果为null,直接通过CAS自旋操作，插入元素成功，则直接返回，如果映射的位置值为MOVED(-1),则直接去协助扩容，排除以上条件后，尝试对链头Node节点f加锁，加锁成功后，链表通过尾插遍历，进行插入或替换。红黑树通过查询遍历，进行插入或替换。之后如果当前链表节点数量大于阈值，则调用treeifyBin函数，转换为红黑树最后通过调用addCount,执行CAS操作，更新数组大小，并且判断是否需要进行扩容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); //spread函数计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //自旋过程 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); //判断映射位置节点是否为空 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; &#125; //如果映射位置节点value==MOVED，说明正在进行扩容操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //红黑树结构 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; //链表节点数量超过阈值，转为红黑树 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 2. spread函数 spread函数，计算hash值。key的hash值与其高16位相异或，然后与HASH_BITS将最高位置0 1234static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS; //HASH_BITS=0x7fffffff&#125; 3. tableAt函数 获取最新的tab[i] 4. casTabAt函数 通过CAS操作，将值赋值进tab中对应位置 12345678static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125;static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; 5. addCount函数 尝试使用CAS操作，将BASECOUNT加1，操作失败，则说明有其他线程在进行加一操作,发生冲突。之后判断是否需要扩容 123456789101112131415161718192021222324252627282930313233343536373839404142434445private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //使用CAS操作，将BASECOUNT加1 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; //发生冲突 boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; //多线程冲突执行 fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //判断是否需要扩容 大于0.75当前数组大小 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; //判断是否需要帮助扩容 //扩容完成，或者扩容线程达到阈值不需要进行扩容，直接break if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //帮助扩容，扩容线程数+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //进行扩容操作 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125; 2.3 initTable函数 进入一个自旋过程，一旦有线程扩容成功，才break 如果sizeCtl &lt; 0,说明已经有线程正在扩容，所以直接让出线程。 如果sizeCtl&gt;=0,说明当前没有线程扩容，尝试CAS操作，设置sizeCtl为-1 设置sizeCtl为-1成功的线程，进行扩容操作，并且将sc更新为数组负载阈值0.75*n 123456789101112131415161718192021222324private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; //自旋过程 while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //0.75*n sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 2.4 统计ConCurrentHashMap中的元素个数 1. mappingCount函数 12345//调用sumCount,获得元素数量public long mappingCount() &#123;long n = sumCount();return (n &lt; 0L) ? 0L : n; // ignore transient negative values&#125; 2. sumCount函数 baseCount+ counterCells各个元素值，就是元素数量 其实baseCount就是记录容器数量的，直接放回baseCount不就可以了吗？为什么sumCount()方法中还要遍历counterCells数组，累加对象的值呢？ 其中：counterCells是个全局的变量，表示的是CounterCell类数组。CounterCell是ConcurrentHashmap的内部类，它就是存储一个值。 JDK1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据put()或则删除数据remove()时，会通过addCount()方法更新baseCount 初始化时counterCells为空，在并发量很高时，如果存在两个线程同时执行CAS修改baseCount值，则失败的线程会继续执行方法体中的逻辑，执行fullAddCount(x, uncontended)方法，这个方法其实就是初始化counterCells，并将x的值插入到counterCell类中，而x值一般也就是1或-1，这可以从put()方法中得知。 这些对象是因为在CAS更新baseCount值时，由于高并发而导致失败，最终将值保存到CounterCell中，放到counterCells里。这也就是为什么sumCount()中需要遍历counterCells数组，sum累加CounterCell.value值了。 1234567891011final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 3. CounterCell类 只存储一个值 1234static final class CounterCell&#123; volatile long value; CountCell(long x) &#123;value = x;&#125;&#125; 原文链接：https://blog.csdn.net/zycxnanwang/article/details/105424734","categories":[{"name":"知识整理","slug":"知识整理","permalink":"https://xiaoyuge5201.github.io/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/tags/Java/"}]},{"title":"常见sql优化方式","slug":"sql-01","date":"2021-07-01T08:00:57.000Z","updated":"2022-04-06T09:51:44.934Z","comments":true,"path":"sql-01/","link":"","permalink":"https://xiaoyuge5201.github.io/sql-01/","excerpt":"","text":"对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： 123select id from t where num is null -- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num=0 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： 12345select id from t where num=10 or num=20 --可以这样查询： select id from t where num=10 union all select id from t where num=20 in 和 not in 也要慎用，否则会导致全表扫描，如： 123select id from t where num in(1,2,3) --对于连续的数值，能用 between 就不要用 in 了： select id from t where num between 1 and 3 下面的查询也将导致全表扫描： 1select id from t where name like &#x27;%abc%&#x27; 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： 123select id from t where num/2=100 ---应改为: select id from t where num=100*2 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： 123select id from t where substring(name,1,3)=&#x27;abc&#x27;--name以abc开头的id ---应改为: select id from t where name like &#x27;abc%&#x27; 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 不要写一些没有意义的查询，如需要生成一个空表结构： 123select col1,col2 into #t from t where 1=0 --这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(...) 很多时候用 exists 代替 in 是一个好的选择： 123select num from a where num in(select num from b) --用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。 一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。 这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 尽可能的使用 varchar 代替 char ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。 避免频繁创建和删除临时表，以减少系统表资源的消耗。 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。 在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 尽量避免大事务操作，提高系统并发能力。 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"Linux安装mysql8","slug":"mysql-install","date":"2021-06-29T06:40:08.000Z","updated":"2022-10-31T14:46:40.629Z","comments":true,"path":"mysql-install/","link":"","permalink":"https://xiaoyuge5201.github.io/mysql-install/","excerpt":"","text":"1. 下载 下载地址：https://downloads.mysql.com/archives/community/ 百度网盘链接: https://pan.baidu.com/s/1BkOuYlz2Ef7KRe9gikDUCg 密码: 0l15 2.卸载mariadb 12345678#查看mariadb 的安装包rpm -qa | grep mariadb#卸载 mariadbrpm -e mariadb-libs-5.5.68-1.el7.x86_64 --nodeps#卸载验证rpm -qa | grep mariadb 3.安装 解压安装包 12345678910111213141516 # 进入下载目录 cd /usr/local/src/#解压， 如果是.tar则用 tar -zxvf解压， 我下载的是.tar.xz包，使用的是tar -xvJf tar -xvJf mysql-8.0.28-linux-glibc2.17-x86_64-minimal.tar.xz# 移动解压后的文件夹至/usr/local mv /usr/local/src/mysql-8.0.28-linux-glibc2.17-x86_64-minimal /usr/local/ cd /usr/local/ # 重命名 mv ./mysql-8.0.28-linux-glibc2.17-x86_64-minimal mysql8 # 创建文件夹data,存储文件; cd /usr/local/mysql8/ mkdir ./data 创建用户以及用户组 1234# 用户组groupadd mysql# 用户 （用户名/密码）useradd -g mysql mysql 授权 1234chown -R mysql.mysql /usr/local/mysql8/ #或chown -R mysql .chgrp -R mysql . 初始化数据库 12345678910# 查看当前所在目录pwd # 若显示/usr/local/mysql-8.0,请继续执行，否则请先进入此目录/usr/local/mysql-8.0# 初始化 注意查看是否存在相关目录,若不存在,请新建# 亲测./bin/mysqld --user=mysql --basedir=/usr/local/mysql8/ --datadir=/usr/local/mysql8/data/ --initialize #或./bin/mysql --user=mysql --basedir=/usr/local/mysql8/ --datadir=/usr/local/mysql8/data/ --initialize ; #如果出现错误：./bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directoryyum install -y libaio #安装后在初始化就OK了 注意：后面白色高亮选中的是初始密码！！！！ 配置my.cnf 12cp /usr/local/mysql8/support-files/mysql.server /etc/init.d/mysqldvim /etc/my.cnf 在配置中键入如下内容： 12345678910111213141516171819202122232425262728293031323334353637 [mysqld]port=3306# 设置mysql的安装目录basedir=/usr/local/mysql8# 设置mysql数据库的数据的存放目录datadir=/usr/local/mysql8/data# 允许最大连接数max_connections=1000# 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统max_connect_errors=100# 服务端使用的字符集默认为UTF8character-set-server=utf8mb4# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用“mysql_native_password”插件认证default_authentication_plugin=mysql_native_password#是否对sql语句大小写敏感，1表示不敏感lower_case_table_names = 1#MySQL连接闲置超过一定时间后(单位：秒)将会被强行关闭#MySQL默认的wait_timeout 值为8个小时, interactive_timeout参数需要同时配置才能生效interactive_timeout = 1800wait_timeout = 1800#Metadata Lock最大时长（秒）， 一般用于控制 alter操作的最大时长sine mysql5.6#执行 DML操作时除了增加innodb事务锁外还增加Metadata Lock，其他alter（DDL）session将阻塞lock_wait_timeout = 3600#内部内存临时表的最大值。#比如大数据量的group by ,order by时可能用到临时表，#超过了这个值将写入磁盘，系统IO压力增大tmp_table_size = 64Mmax_heap_table_size = 64M[mysql]# 设置mysql客户端默认字符集default-character-set=utf8mb4[client]# 设置mysql客户端连接服务端时默认使用的端口port=3306default-character-set=utf8mb4 建立Mysql服务 1234cp -a ./support-files/mysql.server /etc/init.d/mysqlchmod +x /etc/init.d/mysqlchkconfig --add mysqlchkconfig --list mysql 启动Mysql服务 1234# 启动service mysql start;# 查看启动状态service mysql status; 如果提示： -bash: mysql: command not found 1ln -s /usr/local/mysql8/bin/mysql /usr/bin 登录Mysql 12mysql -uroot -p# 输入&quot;初始化数据库&quot;操作时的&quot;临时密码&quot; 修改密码： 1ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;; 远程连接 进入mysql命令行 1234use mysql;update user set host =&#x27;%&#x27; where user=&#x27;root&#x27;;ALTER USER &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;root&#x27;;FLUSH PRIVILEGES; 检查端口 12345678#检查3306端口是否开放netstat -nlp|grep 3306#开放3306端口firewall -cmd --permanent --add-prot=3306/tcp#重启防火墙firewall -cmd --reload 4. 常见问题 The server quit without updating PID file 第一，权限的问题，在出这个错误的时候，我所说的权限是mysq.cnf和所定义的mysql数据库存放目录的权限，要保证是mysql用户的权限，如果启动mysql还有问题，那么需要考虑提高权限了。 说人话， 数据库存放目录必须是mysql这个用户的属组(通常的，安装MySQL的时候建立的用户为mysql，不建议使用别的用户），mysql的启动脚本必须有执行权限。赋予权限的命令为：chown -R mysql. /usr/local/mysql,假设我的mysql是安装在 /usr/local/mysql目录，数据库存放目录为 /usr/local/mysql/data/ 第二，进程中有mysql的进程，上次的退出并没有自动结束该pid，导致新的进程无法启动，毕竟，mysql每次启动系统只会给分配一个pid号，再启动，系统也不可能给你分配pid号了。运行命令 ps -ef |grep mysql 找到mysql的进程结束它，然后在启动mysql。 第三，进入mysql数据库的存放目录，如果有mysql-bin.index这样的文件，删除它，在启动mysql，该文件产生的原因不详，不过删除必定没影响，或者另一个binlog.index也删除，两个index后缀的都删除也可以。 第四，my.cnf 这个配置文件内容不对，检查有没有skip-federated这个字段，如果有注释或者删除。 检查是否定义了数据库存放目录，如果没有定义，请立刻定义。 第五，错误日志目录不存在解决方法：使用“chown” “chmod”命令赋予mysql目录所有者及权限。 第六，my.cnf文件内存在lower_case_table_names=1 字段，注释掉它。（这个选项是1表示不区分大小写）。具体原因不详。 总结：mysql说好安装也好安装，说难也难，难点在于权限的配置，给高了不安全，给低了有可能启动出问题，如果启动出问题了，首先第一件事就是检查目录权限，第二就是检查my.cnf这个配置文件，skip-federated，lower_case_table_names=1 ，这样的字段注释掉，第三，清除旧的mysql进程，如果有就清除掉，旧的不去新的不来，就这么一个道理。第四，进入mysql数据库存放目录删除index后缀的文件。下面，给张图，详细的权限慢慢体会 1ls -al /etc/init.d/mysql Can 't connect to local MySQL server through socket '/tmp/mysql.sock 123连接localhost通常通过一个Unix域套接字文件进行，一般是/tmp/mysql.sock。如果套接字文件被删除了，本地客户就不能连接。这可能发生在你的系统运行一个cron任务删除了/tmp下的临时文件。如果你因为丢失套接字文件而不能连接，你可以简单地通过重启服务器重新创建得到它。因为服务器在启动时重新创建它。如果和我一样，重启服务器还是没有任何变化，你可以先执行下面的语句 1mysql -uroot -h 127.0.0.1 -p 解决方式： 12sudo mkdir /var/run/mysqld/sudo ln -s /tmp/mysql.sock /var/run/mysqld/mysqld.sock however file don’t exists. Create writable for user ‘mysql’ 问题描述： 12[root@test2 my57_3307]# /usr/local/mysql57/bin/mysqld_safe --defaults-file=/dbdata/mysql/my57_3307/my57_3307.cnf --ledir=/usr/local/mysql57/bin2018-08-26T14:12:45.459798Z mysqld_safe error: log-error set to &#x27;/var/log/mysqld/my57_3307.log&#x27;, however file don&#x27;t exists. Create writable for user &#x27;mysql&#x27;. 解决方式： 123touch /usr/local/mysql8/log/error.logchown mysql /usr/local/mysql8/log/error.log/usr/local/mysql8/bin/mysqld_safe --defaults-file=/etc/my.cnf --ledir=/usr/local/mysql8/bin cannot open shared object file: No such file or directory 1234#需要安装 libnumayum install libnumayum -y install numactlyum install libaio1 libaio-dev mysqld启动报错Failed to find valid data directory 123456789vim /etc/my.cnf #查看datadir配置项的路径，然后一般是/var/lib/mysql，将这个文件夹删掉，然后重新初始化/usr/local/mysql8/bin/mysqld --initialize --user=mysql#如果mysqld启动服务时提示不能用root启动，则在/var/lib/mysql中加入这行 user=mysql#重启service mysql restart Navicat无法连接：Host is not allowed to connect to this MySQL server 12mysql -uroot -p#输入密码 操作数据库 12use mysql;select host from user where user=&#x27;root&#x27;; 该结果表示当前的root用户限制在当前的IP内访问，需要修改他的访问域 12update user set host=&#x27;%&#x27; where user=&#x27;root&#x27;;flush privileges ; Can’t connect to MySQL server ‘xxxxxx’ on(60) 我买的是阿里云服务器，前往阿里云服务器配置安全组规则即可","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"Linux安装JDK以及配置","slug":"jdk-install","date":"2021-06-29T01:02:34.000Z","updated":"2022-03-29T06:27:44.644Z","comments":true,"path":"jdk-install/","link":"","permalink":"https://xiaoyuge5201.github.io/jdk-install/","excerpt":"","text":"1. 安装包安装 下载jdk安装包（https://www.oracle.com/cn/java/technologies/javase/downloads/#java8） 上传并解压 在/usr/local/目录下新建文件夹：java 上传介质到/usr/local/java/ 解压：tar -zxvf jdk-8u311-linux-x64.tar.gz 配置环境变量 1234567891011# 编辑配置文件vim /etc/profile# 在末尾追加export JAVA_HOME=/usr/local/java/jdk1.8.0_311export JRE_HOME=/usr/local/java/jdk1.8.0_311/jreexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$PATH# 使配置文件生效source /etc/profile 测试 12345678910111213# 测试版本号java -version# 返回java version &quot;1.8.0_311&quot;Java(TM) SE Runtime Environment (build 1.8.0_311-b10)Java HotSpot(TM) 64-Bit Server VM (build 25.291-b10, mixed mode)# 查询JAVA_HOMEecho $JAVA_HOME# 返回/usr/local/java/jdk1.8.0_311 2. yum源安装 123456789101112131415161718192021222324252627282930313233# 检查是否已经存在java相关命令rpm -qa|grep javarpm -qa|grep jdkrpm -qa|grep gcj# 如果需要卸载rpm -qa | grep java | xargs rpm -e --nodeps# 检索Java1.8源列表yum list java-1.8*# 安装Java1.8yum install java-1.8.0-openjdk* -y# 查询JAVA_HOMEwhich java# 返回/usr/bin/java# ls -l命令ls -l /usr/bin/java# 返回lrwxrwxrwx 1 root root 22 Nov 13 14:37 /usr/bin/java -&gt; /etc/alternatives/java# ls -l命令ls -l /etc/alternatives/java# 返回lrwxrwxrwx 1 root root 73 Nov 13 14:37 /etc/alternatives/java -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64/jre/bin/java# 则JAVA_HOME路径为：/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://xiaoyuge5201.github.io/tags/jdk/"}]},{"title":"面试常见的趣味题","slug":"interest","date":"2021-06-14T02:09:15.000Z","updated":"2022-03-27T14:06:03.392Z","comments":true,"path":"interest/","link":"","permalink":"https://xiaoyuge5201.github.io/interest/","excerpt":"","text":"8升、5升、3升水桶各一个,如何分成两个4升 以面向对象的思想设计长方形和正方形 方式1：设计接口，然后长方形和正方形各自实现这个接口 12345//形状类：结算面积和周长public interface Shape &#123;truepublic double area();truepublic double perimeter();&#125; 1234567891011121314151617//长方形：实现接口并实现方法public class Rectangle implements Shape &#123;trueprivate double width;trueprivate double height;truepublic Rectangle(double width,double height)&#123;truetruethis.width=width;truetruethis.height=height;true&#125; true@Overridetruepublic double area() &#123;truetruereturn this.width*this.height;true&#125;true@Overridetruepublic double perimeter() &#123;truetruereturn 2*(this.width+this.height);true&#125;&#125; 12345678910111213141516//正方形：实现接口并实现方法public class Square implements Shape &#123;trueprivate double side;truepublic Square(double side)&#123;truetruethis.side=side;true&#125;true@Overridetruepublic double area() &#123;truetruereturn side*side;true&#125; true@Overridetruepublic double perimeter() &#123;truetruereturn 4*side;true&#125;&#125; 方式2：使用extents 因为正方形 is a 长方形，所以可以使用继承来设计正方形，然后在构造函数中使用super函数； 123456789101112public class Square extends Rectangle&#123;trueprivate double side;truepublic Square(double side)&#123;truetruesuper(side,side);truetruethis.side=side;true&#125;truepublic static void main(String[] args) &#123;truetrueSquare s=new Square(2.5);truetrueSystem.out.println(s.perimeter());truetrueSystem.out.println(s.area());true&#125;&#125; java使用递归计算1+2+3+…+n之间的和 1234567891011121314public class SumNumber &#123; public static void main(String[] args) &#123; System.out.println(sumN(10)); &#125; //使用递归的方法计算1+2+3+4+....n的和; 切记注意n不能小于1 public static int sumN(int n) &#123; if (n == 1)&#123; return 1; &#125; return n+ sumN(n-1); &#125;&#125; java读取一篇英文文章，并输出其中出现单词次数最多的3个单词以及次数 文件文章中存在,.以及空格 读取文件内容 对文件进行内容匹配 使用map 保存单词、次数 map排序 输出 1234567891011121314151617181920212223242526272829303132333435363738394041public class WordCount &#123; public static void main(String[] args) &#123; try &#123; //1. 使用流读取文件 BufferedReader reader = new BufferedReader(new FileReader(&quot;d:/n.txt&quot;)); StringBuffer sb = new StringBuffer(); String line; while ((line = reader.readLine()) != null) &#123; sb.append(line); &#125; reader.close(); //替换所有的英文逗号和句号 String temp = sb.toString().replaceAll(&quot;/[\\\\w\\\\,\\\\.]+/&quot;, &quot;&quot;); //2.使用正则表达式匹配 Pattern pattern = Pattern.compile(&quot;/[a-zA-Z\\\\w\\\\,\\\\.]+/&quot;); Matcher matcher = pattern.matcher(temp); Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(16); String word; int count; while (matcher.find()) &#123; word = matcher.group(); if (map.containsKey(word)) &#123; count = map.get(word); map.put(word, count + 1); &#125; else &#123; map.put(word, 1); &#125; &#125; //将map的数据根据count排序； List&lt;Map.Entry&lt;String, Integer&gt;&gt; list = new ArrayList&lt;&gt;(map.entrySet()); Collections.sort(list, Comparator.comparing(Map.Entry::getValue)); int last = list.size() - 1; for (int i = last; i &gt; last - 5; i--) &#123; System.out.println(&quot;key=&quot; + list.get(i).getKey() + &quot; value=&quot; + list.get(i).getValue()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; java 获取字符串第一次出现重复的字符 12345678910public static int findDuplicate(String str)&#123; char[] chars = str.toCharArray(); Set&lt;Character&gt; uniqueChars = new HashSet(chars.length,1); for (int i = 0; i &lt; chars.length; i++) &#123; if (!uniqueChars.add(chars[i]))&#123; return i; &#125; &#125; return -1;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"}]},{"title":"Java内部类初始化","slug":"java-inner-class-01","date":"2021-05-31T16:00:00.000Z","updated":"2022-03-27T14:06:03.357Z","comments":true,"path":"java-inner-class-01/","link":"","permalink":"https://xiaoyuge5201.github.io/java-inner-class-01/","excerpt":"","text":"1. 在同个java文件中，但不是内部类 1234567public class C &#123;&#125;//在同一个Java文件中只能存在一个public类，除内部类外//只允许使用“public”、“abstract”和“final”。class D&#123; &#125; 1234//实例化public static void main(String[] args) &#123; D d = new D();&#125; 2. 常规内部类 要实例化内部类对象，必须先有外部类对象，通过外部类对象.new 内部类();来实例化内部类对象，在其他文件或者其他包内都是这样，只是要能在其他包实例化的话，内部类Inner还得加上修饰符public。 1234567891011121314151617181920212223242526public class Outter &#123; class Inner &#123; &#125; public static void main(String[] args) &#123; Outter out = new Outter(); Outter.Inner in = out.new Inner(); &#125;&#125;//第二种情况：通过提供方法来获取实例对象public class A &#123; public class B&#123; public void test()&#123; System.out.println(111); &#125; &#125; public B getInstance()&#123; return new B(); &#125; public static void main(String[] args) &#123; A a = new A(); B b = a.getInstance(); b.test(); &#125;&#125; 3. 静态内部类 实例化静态内部类和实例化常规内部类有类似的地方，而不同之处在与静态内部类由于是静态的，所以不需要外部类对象就可以实例化，如上例Outter.Inner in = new Outter.Inner(); 在其他Java文件也是这么实例化的 12345678910class Outter &#123; static class Inner &#123;&#125;&#125;public class TestDemo &#123; public static void main(String[] args) &#123; Outter.Inner in = new Outter.Inner(); &#125;&#125; 4. 局部内部类 局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内，所以只能在方法或者该作用域内实例化,局部内部类不能有访问说明符,因为它不是外围类的一部分,但是可以访问当前代码块的常量,以及此外围类的所有成员 12345678910111213141516171819public class A &#123; class B &#123; &#125; public void pint() &#123; class C &#123; &#125; new C(); &#125; public void pint(boolean b) &#123; if (b) &#123; class D &#123; &#125; new D(); &#125; &#125;&#125; 5. 匿名内部类 匿名内部类可以继承一个类或实现一个接口，这里的ClassOrInterfaceName是匿名内部类所继承的类名或实现的接口名。但匿名内部类不能同时实现一个接口和继承一个类，也不能实现多个接口。如果实现了一个接口，该类是Object类的直接子类，匿名类继承一个类或实现一个接口，不需要extends和implements关键字 1234567891011ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;() &#123;&#123; add(&quot;A&quot;); add(&quot;B&quot;); add(&quot;C&quot;);&#125;&#125;;new Thread( new Runnable() &#123; public void run() &#123; ... &#125; &#125;).start();","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"内部类","slug":"内部类","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E9%83%A8%E7%B1%BB/"}]},{"title":"Linux环境下安装Redis","slug":"redis_install","date":"2021-05-13T05:40:44.000Z","updated":"2022-11-26T05:13:32.283Z","comments":true,"path":"redis_install/","link":"","permalink":"https://xiaoyuge5201.github.io/redis_install/","excerpt":"","text":"1. 安装gcc 1yum -y install gcc gcc-c++ 2. 下载安装包 1wget http://download.redis.io/redis-stable.tar.gz 3. 解压 1234tar xvzf redis-stable.tar.gz#移动redis目录，一般都会将redis目录放置到 /usr/local/redis目录mv redis-stable /usr/local/redis 4. 编译 1234567891011cd /usr/local/redismake# 如果执行make命令报错：cc 未找到命令，原因是虚拟机系统中缺少gcc，执行下面命令安装gcc：yum -y install gcc automake autoconf libtool make#如果使用make失败，致命错误:jemalloc/jemalloc.h: 没有那个文件或目录，则需要在make指定分配器为libc make MALLOC=libc//make之后如果出现Hint: To run &#x27;make test&#x27; is a good idea ;//运行make test, 会提示需要安装tcl,执行yum install tcl#执行下面命令安装redis，并指定安装目录make install PREFIX=/usr/local/redis 5. 配置密码以及允许外网ip访问 12345678910#在redis.conf中配置requirepass 密码以及port端口号（非必须）requirepass xxxport 6379 #开启redis允许外网ip访问，在 Linux 中安装了redis 服务，当在客户端通过远程连接的方式连接时，报could not connect错误。错误的原因为：redis采用的安全策略，默认会只准许本地访问。#将所有的bing信息全部屏蔽#bind 192.168.1.100 10.0.0.1#配置redis后台启动，如果不配置的话可以使用hohup启动daemonize yes 6. 启动redis服务 12cd ./srcnohup ./redis-server ../redis.conf &amp; 7. 查看redis进程 1[root@localhost redis]# pstree","categories":[{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"}]},{"title":"在线修改静态文件","slug":"在线修改静态文件","date":"2021-05-13T05:40:44.000Z","updated":"2022-04-17T03:47:28.555Z","comments":true,"path":"在线修改静态文件/","link":"","permalink":"https://xiaoyuge5201.github.io/%E5%9C%A8%E7%BA%BF%E4%BF%AE%E6%94%B9%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6/","excerpt":"","text":"项目运行时，如果需要修改某个css、js、html等文件的时候，需要自己连接到服务器然后修改，更有甚者需要连接vpn、堡垒机等等，特别烦！！！！于是弄了一个在线修改静态文件的工具，在此记录一下。 1. 引入pom 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoyuge5201&lt;/groupId&gt; &lt;artifactId&gt;static-file-modify-online&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt;&lt;/dependency&gt; 2. 添加前后台代码 前台使用的是thymeleaf，根据自己项目的实际情况修改！ 12链接: https://pan.baidu.com/s/1oW38vpj74yKOOtbu5xGCOQ 密码: tcmg","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]},{"title":"Java线程的生命周期状态","slug":"thread-status","date":"2020-06-02T08:04:02.000Z","updated":"2022-06-06T02:38:40.428Z","comments":true,"path":"thread-status/","link":"","permalink":"https://xiaoyuge5201.github.io/thread-status/","excerpt":"","text":"1. Java线程分类 在Java中线程分别对应不同的状态，从创建线程的 NEW 到销毁时的 TERMINATED状态， 我们从Thread类中的内部枚举类State中可以看到线程的6种状态； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public enum State &#123; /** * Thread state for a thread which has not yet started. * 尚未启动的线程的线程状态 */ NEW, /** * Thread state for a runnable thread. A thread in the runnable state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system such as processor. * 可运行线程的线程状态。处于可运行状态的线程正在Java虚拟机中执行，但它可能正在等待来自操作系统的其他资源，例如处理器。 */ RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling Object.wait() . * 等待监视器锁定的被阻止线程的线程状态。处于阻塞状态的线程正在等待监视器锁进入同步块/方法，或在调用对象后重新进入同步块/方法。 */ BLOCKED, /** * Thread state for a waiting thread. A thread is in the waiting state due to calling one of the following methods: * 1.Object.wait() with no timeout * 2.Thread.join() with no timeout * 3.LockSupport.park() * * A thread in the waiting state is waiting for another thread to perform a particular action. * For example, a thread that has called Object.wait() on an object is waiting for another thread to call * Object.notify or Object.notifyAll() on that object. A thread that has called Thread.join() * is waiting for a specified thread to terminate. */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * 1.Thread.sleep() * 2.Object.wait() with timeout * 3.Thread.join() with timeout * 4.LockSupport.parkNanos() * 5.LockSupport.parkUntil() */ TIMED_WAITING, /** * Thread state for a terminated thread. The thread has completed execution. */ TERMINATED;&#125; 1.1 状态1： NEW 当线程被创建出来还没有被调用 start()时候的状态 1官方描述：Thread state for a thread which has not yet started. 示例代码： 1234567public class ThreadStateTest &#123; public static void main(String[] args) &#123; Thread thread = new Thread(&quot;thread1&quot;); System.out.println(thread.getState()); &#125;&#125;//输出： NEW 1.2 状态2： RUNNABLE 当线程被调用start()，且处于等待操作系统分配资源（如CPU）、等待IO连接、正在运行状态，即表示Running状态和Ready状态。 注：调用了start()不一定会立即改变状态，还有一些准备工作，这个时候线程状态是不确定的。 123官方描述：Thread state for a runnable thread. A thread in the runnable state is executing in the Java virtual machine but it maybe waiting for other resources from the operating system such as processor. 示例代码： 123456789public class ThreadStateTest &#123; public static void main(String[] args) &#123; Thread thread = new Thread(&quot;thread1&quot;); thread.start(); System.out.println(thread.getState()); &#125;&#125;//输出： RUNNABLE 1.3 状态3： BLOCKED 等待监视器锁而被阻塞的线程的状态。当进入synchronized块/方法 或者在调用wait()被唤醒/超时之后重新进入synchronized块/方法，但是锁被其他线程占有，这个时候被操作系统挂起，状态为阻塞状态 BLOCKED。 阻塞状态的线程，即使调用interrupt()方法也不会改变其状态 1234官方描述：Thread state for a thread blocked waiting for a monitor lock. A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling Object.wait() .译文：等待监视器锁定的被阻止线程的线程状态。处于阻塞状态的线程正在等待监视器锁进入同步块/方法，或在调用对象后重新进入同步块/方法。 阻塞(BLOCKED)：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。 示例代码： 123456789101112131415161718192021222324252627282930313233343536public class BlockedState &#123; static final String lock = &quot;锁&quot;; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;) &#123; @Override public void run() &#123; synchronized (lock) &#123; //死循环导致thread1一直持有lock对象锁 while (true) ; &#125; &#125; &#125;; thread1.start(); //休眠1秒，让thread1先启动 TimeUnit.SECONDS.sleep(1); Thread thread2 = new Thread(&quot;thread2&quot;) &#123; @Override public void run() &#123; synchronized (lock) &#123; //@1 System.out.println(&quot;thread2&quot;); &#125; &#125; &#125;; thread2.start(); System.out.println(&quot;thread1.state:&quot; + thread1.getState()); System.out.println(&quot;thread2.state:&quot; + thread2.getState()); //while (true) 死循环导致thread1持有lock对象锁一直没有释放，而thread2也想获取lock对象锁，但是锁一直被thread1持有着，导致thread2被阻塞在@1处， //此时thread2就处于BLOCKED状态 &#125;&#125;//输出： thread1.state:RUNNABLE// thread2.state:BLOCKED 查看2个线程的堆栈信息，包括：线程状态、线程目前执行到哪段代码等 jps命令查看需要打印线程栈的进程号 1jps jstack命令生成java虚拟机当前时刻的线程快照 1jstack 46622 #找到BlockedState线程的 输出： 123456789&quot;thread2&quot; #13 prio=5 os_prio=31 tid=0x00007f81c387e800 nid=0xa703 waiting for monitor entry [0x000070000bbbd000] java.lang.Thread.State: BLOCKED (on object monitor) at org.example.thread.BlockedState$2.run(BlockedState.java:26) - waiting to lock &lt;0x0000000715916c40&gt; (a java.lang.String)&quot;thread1&quot; #11 prio=5 os_prio=31 tid=0x00007f81b3d9b800 nid=0x5503 runnable [0x000070000b9b7000] java.lang.Thread.State: RUNNABLE at org.example.thread.BlockedState$1.run(BlockedState.java:14) - locked &lt;0x0000000715916c40&gt; (a java.lang.String) 输出内容释义： thread1：线程名称 #11：当前线程ID，从 main线程开始，JVM 根据线程创建的顺序为线程编号 prio：是 priority 优先级的缩写，表明了当前线程的优先级，取值范围【1～10】，默认为 5，在虚拟机进行线程调度的时候会参考该优先级为线程分配计算资源，数值越小优先级越高，一般不设置直接使用默认的优先级。 os_prio：线程对应系统的优先级 nid： 本地线程编号， NativeID的缩写，对应JVM虚拟机中线程映射在操作系统中的线程编号，可以通过 top 命令查看进程对应的线程情况进行相关映射 1.4 状态4： WAITING 无条件等待，当线程调用wait()/join()/LockSupport.park()不加超时时间的方法之后所处的状态，如果没有被唤醒或等待的线程没有结束，那么将一直等待，当前状态的线程不会被分配CPU资源和持有锁。 1234567891011官方描述：Thread state for a waiting thread. A thread is in the waiting state due to calling one of the following methods:1.Object.wait with no timeout 2.Thread.join with no timeout 3.LockSupport.parkA thread in the waiting state is waiting for another thread to perform a particular action.For example, a thread that has called Object.wait() on an object is waiting for another thread to callObject.notify or Object.notifyAll() on that object. A thread that has called Thread.join()is waiting for a specified thread to terminate. 方式一：Object.wait() 123456789101112131415161718192021public class WaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;)&#123; @Override public void run() &#123; synchronized (WaitingState.class)&#123; try &#123; WaitingState.class.wait(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; thread1.start(); //模拟休眠1秒，让thread1运行到wait方法处 TimeUnit.SECONDS.sleep(1); System.out.println(&quot;thread.state:&quot;+thread1.getState()); &#125;&#125;//输出： thread1.state:WAITING 打印线程thread1堆栈信息 1234567&quot;thread1&quot; #11 prio=5 os_prio=31 tid=0x00007fc57b877800 nid=0x5503 in Object.wait() [0x0000700011529000] java.lang.Thread.State: WAITING (on object monitor)true at java.lang.Object.wait(Native Method)true - waiting on &lt;0x0000000715916c40&gt; (a java.lang.Class for org.example.thread.WaitingState)true at java.lang.Object.wait(Object.java:502)true at org.example.thread.WaitingState$1.run(WaitingState.java:12)true - locked &lt;0x0000000715916c40&gt; (a java.lang.Class for org.example.thread.WaitingState) 方式二：Thread.join() 12345678910111213public class WaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;)&#123; @Override public void run() &#123; while (true); &#125; &#125;; thread1.start(); //join方法会让当前主线程等待thread1结束 thread1.join(); &#125;&#125; 上面的代码导致主线程处于WAITING状态，下面是主线程堆栈信息，第二行显示主线程处于WAITING状态，第五行表示因为调用了Thread.join导致线程WAITING 12345678&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fea7b01b800 nid=0xe03 in Object.wait() [0x0000700008b43000] java.lang.Thread.State: WAITING (on object monitor)trueat java.lang.Object.wait(Native Method)true - waiting on &lt;0x000000071591c4c8&gt; (a org.example.thread.WaitingState$1)trueat java.lang.Thread.join(Thread.java:1252)true - locked &lt;0x000000071591c4c8&gt; (a org.example.thread.WaitingState$1)trueat java.lang.Thread.join(Thread.java:1326)trueat org.example.thread.WaitingState.main(WaitingState.java:17) 方式三：LockSupport.park() 1234567891011121314public class WaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;)&#123; @Override public void run() &#123; LockSupport.park(); &#125; &#125;; thread1.start(); TimeUnit.SECONDS.sleep(1); System.out.println(&quot;thread.state:&quot;+thread1.getState()); &#125;&#125;//输出： thread.state:WAITING 打印线程thread1的堆栈信息如下： 12345&quot;thread1&quot; #11 prio=5 os_prio=31 tid=0x00007f7baf82d000 nid=0x5503 waiting on condition [0x000070000b2b9000] java.lang.Thread.State: WAITING (parking)trueat sun.misc.Unsafe.park(Native Method)trueat java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)trueat org.example.thread.WaitingState$1.run(WaitingState.java:11) 1.5 状态5： TIMED_WAITING 有条件的等待，区别于上面的WAITING(无条件等待)，当线程调用以下方法之后所处的状态，在指定的时间没有被唤醒或者等待线程没有结束，会被系统自动唤醒，正常退出。 sleep(睡眠时间) wait(等待时间) join(等待时间) LockSupport.parkNanos(等待时间) LockSupport.parkUntil(等待时间) TIMED_WAITING： 有期限的等待 12345678官方描述：Thread state for a waiting thread with a specified waiting time. A thread is in the timed waiting state due to calling one of the following methods with a specified positive waiting time:1.Thread.sleep2.Object.wait with timeout3.Thread.join with timeout4.LockSupport.parkNanos5.LockSupport.parkUntil 方式一：Thread.sleep(seconds) 1234567891011121314151617181920public class TimeWaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;) &#123; @Override public void run() &#123; try &#123; //休眠500秒 = 500000毫秒 Thread.sleep(500 * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; thread1.start(); //模拟休眠1秒，让thread1运行到sleep方法处 TimeUnit.SECONDS.sleep(1); System.out.println(&quot;thread1.state:&quot; + thread1.getState()); &#125;&#125;//输出： thread1.state:TIMED_WAITING 打印线程thread1的堆栈信息，可以看出是线程sleep方法(第三行)导致线程等待 1234&quot;thread1&quot; #11 prio=5 os_prio=31 tid=0x00007fddf71ae800 nid=0x5503 waiting on condition [0x000070000b11c000] java.lang.Thread.State: TIMED_WAITING (sleeping)trueat java.lang.Thread.sleep(Native Method)trueat org.example.thread.TimeWaitingState$1.run(TimeWaitingState.java:12) 方式二：Object.wait(seconds) 123456789101112131415161718192021public class TimeWaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;) &#123; @Override public void run() &#123; synchronized (TimeWaitingState.class) &#123; try &#123; TimeWaitingState.class.wait(500 * 100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; thread1.start(); //模拟休眠1秒，让thread1运行到sleep方法处 TimeUnit.SECONDS.sleep(1); System.out.println(&quot;thread1.state:&quot; + thread1.getState()); &#125;&#125;//输出； thread1.state:TIMED_WAITING 打印线程 thread1 堆栈信息，从堆栈信息第三行中可以看出是线程 wait 方法导致线程等待的 123456&quot;thread1&quot; #11 prio=5 os_prio=31 tid=0x00007f80a0129800 nid=0x5503 in Object.wait() [0x000070000856b000] java.lang.Thread.State: TIMED_WAITING (on object monitor)trueat java.lang.Object.wait(Native Method)true- waiting on &lt;0x0000000715916d28&gt; (a java.lang.Class for org.example.thread.TimeWaitingState)trueat org.example.thread.TimeWaitingState$1.run(TimeWaitingState.java:12)true- locked &lt;0x0000000715916d28&gt; (a java.lang.Class for org.example.thread.TimeWaitingState) 方式三：Thread.join(seconds) 1234567891011121314public class TimeWaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;) &#123; @Override public void run() &#123; while(true); &#125; &#125;; thread1.start(); //Thread.join 会让当前主线程等待thread1结束，需要等待500s thread1.join(500 * 1000); &#125;&#125; Thread.join 会让当前主线程等待thread1结束，所以我们查看主线程堆栈信息: 1234567&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fa6d7009000 nid=0xd03 in Object.wait() [0x000070000feb9000] java.lang.Thread.State: TIMED_WAITING (on object monitor)trueat java.lang.Object.wait(Native Method)true- waiting on &lt;0x000000071591c138&gt; (a org.example.thread.TimeWaitingState$1)trueat java.lang.Thread.join(Thread.java:1260)true- locked &lt;0x000000071591c138&gt; (a org.example.thread.TimeWaitingState$1)trueat org.example.thread.TimeWaitingState.main(TimeWaitingState.java:14) 方式四：LockSupport.parkNanos(seconds) 12345678910111213141516public class TimeWaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;) &#123; @Override public void run() &#123; //等待500秒 LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(500)); &#125; &#125;; thread1.start(); //模拟休眠1秒，让thread1运行到parkNanos方法处 TimeUnit.SECONDS.sleep(1); System.out.println(&quot;thread1.state:&quot; + thread1.getState()); &#125;&#125;//输出： thread1.state:TIMED_WAITING 线程 thread1 堆栈信息 12345&quot;thread1&quot; #11 prio=5 os_prio=31 tid=0x00007fb71b07a000 nid=0x5503 waiting on condition [0x0000700001da8000] java.lang.Thread.State: TIMED_WAITING (parking)trueat sun.misc.Unsafe.park(Native Method)trueat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:338)trueat org.example.thread.TimeWaitingState$1.run(TimeWaitingState.java:12) 方式五：LockSupport.parkUntil(seconds) 12345678910111213141516public class TimeWaitingState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;) &#123; @Override public void run() &#123; //等待500秒 LockSupport.parkUntil(System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(500)); &#125; &#125;; thread1.start(); //模拟休眠1秒，让thread1运行到parkNanos方法处 TimeUnit.SECONDS.sleep(1); System.out.println(&quot;thread1.state:&quot; + thread1.getState()); &#125;&#125;//输出： thread1.state:TIMED_WAITING 线程 thread1 堆栈信息 12345&quot;thread1&quot; #11 prio=5 os_prio=31 tid=0x00007ff41d076000 nid=0x5503 waiting on condition [0x00007000094df000] java.lang.Thread.State: TIMED_WAITING (parking)trueat sun.misc.Unsafe.park(Native Method)trueat java.util.concurrent.locks.LockSupport.parkUntil(LockSupport.java:372)trueat org.example.thread.TimeWaitingState$1.run(TimeWaitingState.java:12) 1.6 状态6： TERMINATED 执行完了 run()方法。其实这只是 Java 语言级别的一种状态，在操作系统内部可能已经注销了相应的线程，或者将它复用给其他需要使用线程的请求，而在 Java 语言级别只是通过 Java 代码看到的线程状态而已 12官方描述：Thread state for a terminated thread. The thread has completed execution. 示例代码： 12345678910111213141516public class TerminatedState &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(&quot;thread1&quot;) &#123; @Override public void run() &#123; System.out.println(Thread.currentThread()); &#125; &#125;; thread1.start(); //休眠1秒，等待thread1执行完毕 TimeUnit.SECONDS.sleep(1); System.out.println(&quot;thread1 state:&quot; + thread1.getState()); &#125;&#125;//输出：Thread[thread1,5,main]// thread1 state:TERMINATED 2.状态转化","categories":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"}],"tags":[{"name":"thread","slug":"thread","permalink":"https://xiaoyuge5201.github.io/tags/thread/"}]},{"title":"Java 8学习","slug":"java8特性","date":"2020-04-23T06:04:02.000Z","updated":"2022-03-27T14:06:03.457Z","comments":true,"path":"java8特性/","link":"","permalink":"https://xiaoyuge5201.github.io/java8%E7%89%B9%E6%80%A7/","excerpt":"","text":"1. Optional Optional 类主要解决的问题是臭名昭著的空指针异常（NullPointerException)。 本质上，这是一个包含有可选值的包装类，这意味着 Optional 类既可以含有对象也可以为空 1.1. optional构造方式 Optional.of(T) 该方式的入参不能为null，否则会有NPE，在确定入参不为空时使用该方式。 Optional.ofNullable(T) 该方式的入参可以为null，当入参不确定为非null时使用。 Optional.empty() 这种方式是返回一个空Optional，等效Optional.ofNullable(null) 1.2. 如何正确的使用Optional 尽量避免使用的地方 避免使用Optional.isPresent()来检查实例是否存在，因为这种方式和null != obj没有区别，这样用就没什么意义了。 避免使用Optional.get()方式来获取实例对象，因为使用前需要使用Optional.isPresent()来检查实例是否存在，否则会出现NPE问题。 避免使用Optional作为类或者实例的属性，而应该在返回值中用来包装返回实例对象。 避免使用Optional作为方法的参数，原因同3。 正确使用方式 实例对象存在则返回，否则提供默认值或者通过方法来设置返回值，即使用orElse/orElseGet方式： 12345678910111213141516171819202122//存在则返回User king = new User(1, &quot;king&quot;);Optional&lt;User&gt; userOpt = Optional.of(king);User user = userOpt.orElse(null);System.out.println(user.getName());//不存在提供默认值User user2 = null;Optional&lt;User&gt; userOpt2 = Optional.ofNullable(user2);User user3 = userOpt2.orElse(unknown);System.out.println(user3.getName());//通过方法提供值User user4 = userOpt2.orElseGet(() -&gt; new User(0, &quot;DEFAULT&quot;)); System.out.println(user4.getName()) //不建议下面这种使用if(userOpt.isPresent()) &#123; System.out.println(userOpt.get().getName());&#125; else &#123; //。。。&#125; 使用ifPresent()来进行对象操作，存在则操作，否则不操作。 123//实例存在则操作，否则不操作userOpt.ifPresent(u -&gt; System.out.println(u.getName()));userOpt2.ifPresent(u -&gt; System.out.println(u.getName())); 使用map/flatMap来获取关联数据 1234567891011//使用map方法获取关联数据System.out.println(userOpt.map(u -&gt; u.getName()).orElse(&quot;Unknown&quot;));System.out.println(userOpt2.map(u -&gt; u.getName()).orElse(&quot;Default&quot;));//使用flatMap方法获取关联数据List&lt;String&gt; interests = new ArrayList&lt;String&gt;();interests.add(&quot;a&quot;);interests.add(&quot;b&quot;);interests.add(&quot;c&quot;);user.setInterests(interests);List&lt;String&gt; interests2 = Optional.of(user) .flatMap(u -&gt; Optional.ofNullable(u.getInterests())) .orElse(Collections.emptyList());System.out.println(interests2.isEmpty()); 1.3.Optional判断第三方接口 使用java8的optional可以减少很多的NPE，再也不用当心别人的接口返回值问题了，也不用满屏的if（a != null）这种判断，下面是使用过程中遇到的问题以及如何使用Optional解决。 1.3.1. 接口返回参数问题 在微服务中使用feign调用其他接口，总担心别人返回的参数是否符合标准 参数符合标准后，然后再进行数据判断，先判断是否code为200，然后判断数据存不存在，这样冗余的代码就很多 这是我们期望的返回格式 12345&#123;true&quot;code&quot;: &quot;200&quot;,true&quot;msg&quot;: &quot;调用成功!&quot;,true&quot;data&quot;: []&#125; 12345678//模拟接口调用方法Map&lt;String,Object&gt; map = serviceImpl.queryList();//即使map为空也能正常返回，配合map直接映射数据值return Optional.ofNullable(map).map(r-&gt; r.get(&quot;data&quot;)).orElseGet(ArrayList:: new) //JSONObject 判断是否返回成功，如果成功返回200， 不成功返回400 JSONObject jsonObject = service.updateDate();Optional.ofNullable(jsonObject).map(r-&gt;r.getInteger(&quot;code&quot;)).orElse(400) 1.3.2. 避免判断风暴 对象层层嵌套，为了逻辑严谨必须要进行空判断 1234567891011121314151617181920//对于一个对象里面嵌套对象，那么需要层层去判断非空School school = null;if(school != null)&#123; Clazz clazz = school.getClazz(); if(clazz != null)&#123; Student student = clazz.getStudent(); if(student != null)&#123; String name = student.getName(); if(name == null || &quot;&quot;.equals(name))&#123; name = &quot;学生的姓名为空&quot;; &#125; &#125; &#125;&#125;//使用Optional后 String name = Optional.ofNullable(school) .map(School::getClazz) .map(Clazz::getStudent) .map(Student::getName) .orElse(&quot;学生的姓名为空&quot;); 2. Stream 123//找出某一个字段等于某个值的那一条数据JaponicaRiceCheck1 streamCheck = listItemRice.stream().filter(o -&gt; o.getSYS_PARENTID().equals(check.getSYS_ID())).findAny().orElse(null);","categories":[{"name":"知识整理","slug":"知识整理","permalink":"https://xiaoyuge5201.github.io/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]}],"categories":[{"name":"interface","slug":"interface","permalink":"https://xiaoyuge5201.github.io/categories/interface/"},{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/categories/mysql/"},{"name":"filter","slug":"filter","permalink":"https://xiaoyuge5201.github.io/categories/filter/"},{"name":"tidb","slug":"tidb","permalink":"https://xiaoyuge5201.github.io/categories/tidb/"},{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"apache","slug":"apache","permalink":"https://xiaoyuge5201.github.io/categories/apache/"},{"name":"tomcat","slug":"tomcat","permalink":"https://xiaoyuge5201.github.io/categories/tomcat/"},{"name":"ShardingSphere-jdbc","slug":"ShardingSphere-jdbc","permalink":"https://xiaoyuge5201.github.io/categories/ShardingSphere-jdbc/"},{"name":"经验分享","slug":"经验分享","permalink":"https://xiaoyuge5201.github.io/categories/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"},{"name":"vue","slug":"vue","permalink":"https://xiaoyuge5201.github.io/categories/vue/"},{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/categories/java/"},{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/categories/linux/"},{"name":"swagger","slug":"swagger","permalink":"https://xiaoyuge5201.github.io/categories/swagger/"},{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/categories/nginx/"},{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/categories/Docker/"},{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/categories/hexo/"},{"name":"架构师笔记","slug":"架构师笔记","permalink":"https://xiaoyuge5201.github.io/categories/%E6%9E%B6%E6%9E%84%E5%B8%88%E7%AC%94%E8%AE%B0/"},{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://xiaoyuge5201.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"},{"name":"知识整理","slug":"知识整理","permalink":"https://xiaoyuge5201.github.io/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"},{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"},{"name":"tidb","slug":"tidb","permalink":"https://xiaoyuge5201.github.io/tags/tidb/"},{"name":"kafka","slug":"kafka","permalink":"https://xiaoyuge5201.github.io/tags/kafka/"},{"name":"Canal","slug":"Canal","permalink":"https://xiaoyuge5201.github.io/tags/Canal/"},{"name":"rocketmq","slug":"rocketmq","permalink":"https://xiaoyuge5201.github.io/tags/rocketmq/"},{"name":"linux","slug":"linux","permalink":"https://xiaoyuge5201.github.io/tags/linux/"},{"name":"Apache","slug":"Apache","permalink":"https://xiaoyuge5201.github.io/tags/Apache/"},{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"https://xiaoyuge5201.github.io/tags/rabbitMQ/"},{"name":"分布式","slug":"分布式","permalink":"https://xiaoyuge5201.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"ip","slug":"ip","permalink":"https://xiaoyuge5201.github.io/tags/ip/"},{"name":"vue","slug":"vue","permalink":"https://xiaoyuge5201.github.io/tags/vue/"},{"name":"springboot","slug":"springboot","permalink":"https://xiaoyuge5201.github.io/tags/springboot/"},{"name":"maven","slug":"maven","permalink":"https://xiaoyuge5201.github.io/tags/maven/"},{"name":"gitlab","slug":"gitlab","permalink":"https://xiaoyuge5201.github.io/tags/gitlab/"},{"name":"swagger","slug":"swagger","permalink":"https://xiaoyuge5201.github.io/tags/swagger/"},{"name":"消息中间件","slug":"消息中间件","permalink":"https://xiaoyuge5201.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/tags/Docker/"},{"name":"docker","slug":"docker","permalink":"https://xiaoyuge5201.github.io/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"},{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"},{"name":"集合","slug":"集合","permalink":"https://xiaoyuge5201.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"shutdown","slug":"shutdown","permalink":"https://xiaoyuge5201.github.io/tags/shutdown/"},{"name":"thread","slug":"thread","permalink":"https://xiaoyuge5201.github.io/tags/thread/"},{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/tags/hexo/"},{"name":"守护线程","slug":"守护线程","permalink":"https://xiaoyuge5201.github.io/tags/%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B/"},{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"},{"name":"内存溢出","slug":"内存溢出","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/"},{"name":"ClassLoader","slug":"ClassLoader","permalink":"https://xiaoyuge5201.github.io/tags/ClassLoader/"},{"name":"mycat","slug":"mycat","permalink":"https://xiaoyuge5201.github.io/tags/mycat/"},{"name":"lock","slug":"lock","permalink":"https://xiaoyuge5201.github.io/tags/lock/"},{"name":"ELK","slug":"ELK","permalink":"https://xiaoyuge5201.github.io/tags/ELK/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://xiaoyuge5201.github.io/tags/SpringCloud/"},{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/tags/Java/"},{"name":"jdk","slug":"jdk","permalink":"https://xiaoyuge5201.github.io/tags/jdk/"},{"name":"内部类","slug":"内部类","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E9%83%A8%E7%B1%BB/"}]}