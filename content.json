{"meta":{"title":"小余哥|猿无忧","subtitle":"","description":"小余哥个人博客，致力于分享一些技术教程和有趣的技术实践，以及日常踩坑记录。","author":"小余哥|猿无忧","url":"https://xiaoyuge5201.github.io","root":"/"},"pages":[{"title":"books","date":"2021-12-11T09:44:50.367Z","updated":"2021-12-11T09:44:50.367Z","comments":false,"path":"books/index.html","permalink":"https://xiaoyuge5201.github.io/books/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2021-12-11T08:03:12.075Z","updated":"2021-12-11T08:03:12.075Z","comments":false,"path":"/404.html","permalink":"https://xiaoyuge5201.github.io/404.html","excerpt":"","text":""},{"title":"classification","date":"2021-12-11T09:44:37.101Z","updated":"2021-12-11T09:44:37.101Z","comments":false,"path":"categories/index.html","permalink":"https://xiaoyuge5201.github.io/categories/index.html","excerpt":"","text":""},{"title":"links","date":"2021-12-11T09:44:27.087Z","updated":"2021-12-11T09:44:27.087Z","comments":true,"path":"links/index.html","permalink":"https://xiaoyuge5201.github.io/links/index.html","excerpt":"","text":""},{"title":"about","date":"2021-12-11T09:45:07.672Z","updated":"2021-12-11T09:45:07.672Z","comments":false,"path":"about/index.html","permalink":"https://xiaoyuge5201.github.io/about/index.html","excerpt":"","text":""},{"title":"repositories","date":"2021-12-11T09:44:31.756Z","updated":"2021-12-11T09:44:31.756Z","comments":false,"path":"repository/index.html","permalink":"https://xiaoyuge5201.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-10-10T08:14:05.155Z","updated":"2021-10-10T08:14:05.155Z","comments":false,"path":"tags/index.html","permalink":"https://xiaoyuge5201.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MinIO简介以及Linux安装MinIO","slug":"linux-minio","date":"2022-03-21T05:39:15.000Z","updated":"2022-03-21T09:48:37.239Z","comments":false,"path":"202203/linux_minio.html","link":"","permalink":"https://xiaoyuge5201.github.io/202203/linux_minio.html","excerpt":"","text":"1. 什么是对象存储对象存储服务OSS（Object Storage Service）是一种海量、安全、低成本、高可用的云存储服务，适合存放任意类型的文件。容量和处理能力弹性扩展，多种存储类型提供选择，全面优化存储成本。 最大的优势：可以存储大量的非结构话数据，例如：图片、视频、日志文件、备份数据和容器/虚拟机镜像等。 2. MinIOMinIO 是个基于Golang编写的开源对象存储套件，基于Apache License V2.0开源协议，虽然轻量，却拥有不错的性能，兼容亚马逊S3云存储服务接口。可以很简单的和其他应用结合使用，例如：NodeJS、Redis、mysql等 中文文档： http://docs.minio.org.cn/docs/master/minio-monitoring-guide 2.1 MinIO应用场景可以作为私有云的对象存储服务来使用，也可以作为云对象存储的网关层，无缝对接Amazon S3 或者 MicroSoft Azure 。 2.2 MinIO特点 高性能 作为一款高性能存储，在标准硬件条件下，其读写速率分别可以达到55Gb/s和 35Gb/s。并且MinIO支持一个对象文件是任意大小（几KB到最大5T不等） 可扩展 不同MinIO集群可以组成联邦，并形成一个全局的命名空间，并且支持跨越多个数据中心 云原生 容器化、基于K8S的编排、多租户支持 Amazon S3兼容 使用Amazon S3 V2/V4 API。可以使用Minio SDK，Minio Client，AWS SDK 和 AWS CLI 访问Minio服务器。 可对接多种后端存储 除了Minio自己的文件系统，还支持 DAS、 JBODs、NAS、Google云存储和 Azure Blob存储。 SDK支持 GO SDK： https://github.com/minio/minio-go JavaSDK： https://github.com/minio/minio-java PythonSDK： https://github.com/minio/minio-py Lambda计算 Minio服务器通过其兼容AWS SNS / SQS的事件通知服务触发Lambda功能。支持的目标是消息队列，如Kafka，NATS，AMQP，MQTT，Webhooks以及Elasticsearch，Redis，Postgres和MySQL等数据库 图形化界面 有操作页面 功能简单 不容易出错，快速启动 支持纠删码 MinIO使用纠删码、Checksum来防止硬件错误和静默数据污染。在最高冗余度配置下，即使丢失1/2的磁盘也能恢复数据 2.3 存储机制MinIO 使用纠删码erasure code、校验和checksum。 即使丢一半数据（N/2）的鹰派，仍然可以恢复数据。 校验和checksum 保护数据免受硬件故障和无声数据损坏 纠删码erasure code 纠删码是一种恢复丢失和损坏数据的数据算法，目前纠删码技术在分布式存储系统中的应用主要有三类：阵列纠删码（Array Code : RAID5、RAID6等）、RS（Reed-Solomon）里德-所罗门类纠删码和LDPC（LowDensity Parity Check Code） 低密度奇偶校验纠删码。 Erasure code 是一种编码技术，他可以将N分原始数据，增加m分数据，并通过n+m 份中的任意n份数据，还原为原始数据。即如果有任意小于等于m份的数据失效，仍然能通过剩下的数据还原出来。MinIO 采用Reed-Solomon code将对象拆分成N/2数据和N/2奇偶校验快，这就意味着如果是12块盘，一个对象会分成6个数据块、6个奇偶校验块；可以丢失任意6块盘（不管是存放的数据块还是奇偶校验块），仍可以通过剩下的盘进行数据恢复 3. 安装和使用MinIO3.1 Linux安装MinIO 下载（https://min.io/download#/linux） 1wget https://dl.min.io/server/minio/release/linux-amd64/minio 运行 1234567891011 chmod +x minio ./minio server /usr/software/minio/data #将/usr/software/minio/data 替换为您希望 MinIO 存储数据的驱动器或目录的路径。#或者指定账号密码启动MINIO_ACCESS_KEY=minioadmin MINIO_SECRET_KEY=minioadmin ./minio server --config-dir /usr/software/minio/config /usr/software/minio/data #后台启动nohup ./minio server /usr/software/minio/data &gt; /usr/software/minio/minio.log 2&gt;&amp;1 &amp;##或者指定账号密码启动MINIO_ACCESS_KEY=minioadmin MINIO_SECRET_KEY=minioadmin nohup ./minio server --config-dir /usr/software/minio/config /usr/software/minio/data&gt; /usr/software/minio/minio.log 2&gt;&amp;1 &amp;# 设置启动脚本 123touch minio.sh vi minio.sh 在sh文件中添加以下内容 123456 #指定登录用户名 export MINIO_ACCESS_KEY=username#指定登录密码 export MINIO_SECRET_KEY=password#指定端口以及存储文件夹，并启动服务 nohup sudo /usr/local/minio/minio server --address=0.0.0.0:9000 --config-dir /etc/minio /data/minioData &gt; /usr/local/minio/minio.log 2&gt;&amp;1&amp; 给当前用户加上执行权限 1chmod u+x *.sh 3.2 安装客户端 安装 123wget https://dl.min.io/client/mc/release/linux-amd64/mcchmod +x mc./mc --help 使用命令给客户端添加一个服务端 1./mc alias set minio http://172.21.0.7:9000 minioadmin minioadmin 创建bucket，并查询所有bucket 123456[root@ww minio]# ./mc ls minio[root@ww minio]# ./mc mb minio/mybucketBucket created successfully `minio/mybucket`[root@ww minio]# ./mc ls minio[2020-09-02 03:02:36 CST] 0B mybucket/[root@ww minio]# 页面查询bucket 创建用户 1./mc admin user add minio root rootroot 给用户赋予权限 1./mc admin policy set minio readwrite user=root 3.3 使用MinIO 启动 在浏览器输入： http://localhost:9000 在输入控制打印的默认的AccessKey和SecretKey： AccessKey: minioadmin SecretKey: minioadmin 使用AccessKey 和 SecretKey 登录后台。 进入系统后，我们先要点击右下角的“+”按钮，创建一个文件桶（输入名称后，回车即可），在上传文件到这个文件桶中。Create bucket（创建文件桶）、Upload file（上传文件）。 上传成功 现在我们去服务器，我们启动时指定的目录去看看，文件桶相当于文件目录，这里没有使用纠删码的模式，所以直接就是源文件了。当我们线上运行的项目已经有源文件了，在使用minio的时候，可以直接指定该目录为minio的文件目录就行了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/tags/Linux/"}]},{"title":"Linux系统下查找文件命令总结","slug":"linux-search-file","date":"2022-03-19T05:52:39.000Z","updated":"2022-03-21T05:40:11.698Z","comments":false,"path":"202203/linux-find-file.html","link":"","permalink":"https://xiaoyuge5201.github.io/202203/linux-find-file.html","excerpt":"","text":"1. which查命令绝对路径which 从环境变量PATH中定位/返回与指定名字相匹配的可执行文件所在的路径 原理：执行which命令时，which会在当前环境变量PATH中依次寻找能够匹配所找命令名字的可执行文件名，不加 - a选项，返回第一个匹配的可执行文件路径，否则依次返回满足条件的所有可执行文件的路径名 适用场合： 一般用于查找命令/可执行文件所在的路径。有时候可能在多个路径下存在相同的命令，该命令可用于查找当前所执行的命令到底是哪一个位置处的命令。 2. whereis查找特定文件whereis 命令用来定位指令的二进制程序、源代码文件和man手册页等相关文件的路径， 该命令只能用于程序名的搜索 - b #定位可执行文件 - m #定位帮助文件 - s 定位源代码文件 - u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 - B 指定搜索可执行文件的路径。 - M 指定搜索帮助文件的路径。 - S 指定搜索源代码文件的路径 原理： whereis命令首先会去掉filename中的前缀空格和以.开头的任何字符，然后再在数据库（var/lib/slocate/slocate.db）中查找与上述处理后的filename相匹配的二进制文件、源文件和帮助手册文件,使用之前可以使用updatedb命令手动更新数据库。 适用场合： 二进制文件、源文件和帮助手册文件路径的查找。和find 相比，Whereis 查找的速度非常快，这是因为Linux系统会将系统内的所有文件都记录在一个数据库文件中，当使用whereis (或者locate)会从数据库查找数据，而不是像find命令那样，通过遍历硬盘来查找文件，效率更高！ 3. locate缓存查找文件locate 搜素一个数据库（/var/lib/mlocate/mlocate.db）,这个数据库中国呢包含本地所有文件信息，Linux系统自动创建这个数据库，并且每天更新依次，所以使用locate命令查不到最新变动过的文件，为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库，updatedb命令会根据/etc/updatedb.conf来更新文件。 原理： 默认情况下(当filename中不包含通配符*)，locate会给出所有与 * filename*相匹配的文件的路径。适用场合： 没有文件类型性质的模糊查找（你只记得某个文件的部分名称）。 4. find 遍历文件查找语法： -name #按文件名查找(find /etc/ -name “??????” 查找/etc目录下，开头是6个任意字符的文件， *.log以log结尾的文件；”[1-3].txt”指定范围以txt结尾的文件（包括 1.txt,2.txt,3.txt）) -size #按大小查找（find /etc/ -size +1M 查询大于1M的文件(find /etc/ -size -10K)，注意：如果没有+ -， 则是精确到1M,加上+ - 表示范围； find /etc/ -size +1k -a -size -10k 查找1-10K的文件） -user #按属主查找（find /opt/ -user xiaoyuge 查找/opt属于xiaoyuge用户的文件；注意，系统要存在该用户，否则会报错） -perm #按权限查找（find /opt/ -perm 0644 查找/opt目录权限是644文件） -type #按类型查找（find /usr/bin/ -type f 查找/usr/bin下类型是二进制文件） -time #按天查找 atime n #将n*24小时内访问过的文件列出(access) ctime n #将n*24小时内状态发生改变的文件列出（change） find /etc/ -ctime +7 在7天之前,属性被修改过的文件 mtime n #将n*24小时内被修改过的文件列出(modify) newer file #把比file还要心的文件列出 amin n #将n 分钟内访问过的文件列出(access) find /etc/ -mmin -120 在120分钟内，内容被修改的文件 cmin n #将n 分钟内状态发生改变的文件列出（change） mmin n #将n 分钟内被修改过的文件列出(modify) -inum #按i节点查找 有一些文件的硬链接数量很多，有相同的i节点，查找其中一个文件的i节点号，一次性删除。 -exec #查找后执行命令 原理： 遍历当前工作目录及其子目录，find命令是在硬盘上遍历查找，非常耗硬盘资源，查找效率相比whereis和locate较低。适用场合： 能用which、whereis和locate的时候尽量不要用find. 4中命令对比","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/tags/Linux/"}]},{"title":"docker安装nginx","slug":"docker-nginx","date":"2021-12-09T13:47:19.000Z","updated":"2021-12-16T15:40:24.788Z","comments":false,"path":"202112/docker-03.html","link":"","permalink":"https://xiaoyuge5201.github.io/202112/docker-03.html","excerpt":"","text":"1.查看所有的镜像1docker search nginx 2.拉取最新版本的镜像1234docker pull nginx#或者指定最新版本docker pull nginx:latest 3.使用命令查看本地镜像，确定nginx镜像已下载到本地1docker images 4. 创建挂载目录1mkdir -p /data/nginx/&#123;conf,conf.d,html,logs&#125; 5. 创建配置文件1touch nginx.cnf 6. Nginx详情配置请参考：https://xiaoyuge.work/2021/12/05/nginx-02/7. 查看容器1234docker ps -a# docker stop xxx 停止某个容器运行# docker rm xxx 删除容器 8.启动容器，挂载配置文件1docker run --name mynginx -d -p 80:80 -v /data/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /data/nginx/logs:/var/log/nginx -d docker.io/nginx 可以通过命令docker exec -it nginx-test bash进入容器内容修改配置 9.安装完毕，访问地址 http://localhost:8080，出现如下内容，安装成功！！！ 10.域名解析配置我买的是阿里云的服务器以及域名，上面操作后，忘记在阿里云控制台中去配置 11.配置多个二级域名在第8步的时候将docker容器中的nginx配置映射到了目录/data/nginx/conf下面；修改nginx.conf 123456789101112131415161718192021222324user nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; #引入conf.d下面所有的配置文件 include /etc/nginx/conf.d/*.conf;&#125; 然后在conf.d目录下面创建了两个子域名反向代理配置文件,其他的域名代理相同，只要改server_name和proxy_pass代理端口，配置文件需以.conf结尾 note.xiaoyuge520.vip.conf12345678910111213141516171819202122232425262728293031323334353637383940414243######## Nginx的main(全局配置)文件#指定nginx运行的用户及用户组,默认为nobody#user nobody;#开启的线程数，一般跟逻辑CPU核数一致worker_processes 1;events &#123;#设置工作模式为epoll,除此之外还有select,poll,kqueue,rtsig和/dev/poll模式#use epoll; #定义每个进程的最大连接数,受系统进程的最大打开文件数量限制。 worker_connections 1024;&#125;#######Nginx的Http服务器配置,Gzip配置http &#123; include mime.types; #核心模块指令，智力默认设置为二进制流，也就是当文件类型未定义时使用这种方式 default_type application/octet-stream; #开启高效文件传输模式 sendfile on; keepalive_timeout 65; ########Nginx的server虚拟主机配置 server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name note.xiaoyuge520.vip; #设置访问的语言编码 #charset koi8-r; #设置虚拟主机访问日志的存放路径及日志的格式为main #access_log logs/host.access.log main; #设置虚拟主机的基本信息 location / &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://47.101.130.163:8086/note; # 代理ip:端口 &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; record.xiaoyuge520.vip.conf 1234567891011121314151617181920212223242526worker_processes 1;events &#123; worker_connections 1024;&#125;#######Nginx的Http服务器配置,Gzip配置http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name record.xiaoyuge520.vip; #access_log logs/host.access.log main; location / &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://47.101.130.163:8888/record; # 代理ip:端口 &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 如果挂载之后容器运行正常却依然不能通过域名访问可尝试以下操作 12345678910#查看所有容器,获取nginx的container 名称docker ps -a#向名称为nginx的容器发送脚本命令, mynginx 为容器名称docker exec -it mynginx /bin/bash#重新加载配置命令cd /etc/nginx/conf.dservice nginx reload#检查配置文件路径是否正确 每一次更改配置文件都需要重启容器 12345678# 重启nginx容器docker restart nginx #查看容器状态docker ps #如果挂载失败，查看nginx容器log,显示错误信息，根据错误信息 更改配置文件等docker logs -t nginx 以上配置完成之后能够通过域名访问网站，但是css样式却被nginx解析成text/plain，打开控制台可看到warn信息 解决nginx将css文件解析为text/plain 方法一： ngin.conf中http添加： 12include /etc/nginx/mime.types;default_type application/octet-stream; 注：此办法并不能使我网站的css正确解析，因为在拷贝nginx镜像中的原配置文件时，就已经添加mime.types了。却依然不能正确解析。 方法二：解析成功，原因未知 1将index.html中&lt;!DOCTYPE html&gt;去掉。 通过域名访问：成功！！","categories":[{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/categories/Docker/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"docker安装mysql","slug":"docker-mysql","date":"2021-12-09T13:32:36.000Z","updated":"2021-12-11T09:38:33.382Z","comments":false,"path":"202112/docker-02.html","link":"","permalink":"https://xiaoyuge5201.github.io/202112/docker-02.html","excerpt":"","text":"1.查看所有的镜像1docker search mysql 2.拉取最新版本的镜像1234docker pull mysql#或者指定版本docker pull mysql:8.0.16 3.创建数据目录和配置文件123mkdir -p /usr/mysql/conf /usr/mysql/datachmod -R 777 /usr/mysql/ 4.创建配置文件在上面创建的配置文件目录/usr/mysql/conf下创建MySQL的配置文件my.cnf 123touch my.cnf;vim /usr/mysql/conf/my.cnf; 添加以下内容到上述创建的配置文件中 123456789101112131415161718[client]#socket = /usr/mysql/mysqld.sockdefault-character-set = utf8mb4[mysqld]#pid-file = /var/run/mysqld/mysqld.pid#socket = /var/run/mysqld/mysqld.sock#datadir = /var/lib/mysql#socket = /usr/mysql/mysqld.sock#pid-file = /usr/mysql/mysqld.piddatadir = /usr/mysql/datacharacter_set_server = utf8mb4collation_server = utf8mb4_binsecure-file-priv= NULL# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Custom config should go here!includedir /etc/mysql/conf.d/ 5.启动创建容器1docker run --restart=unless-stopped -d --name mysql -v /usr/mysql/conf/my.cnf:/etc/mysql/my.cnf -v /usr/mysql/data:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=xiaoyuge mysql 参数解释： 123456–name mysql5.7 容器别名-p 3307:3306 映射容器端口号和宿主机端口号（本机3307端口映射容器3306端口）-v /data/mysql/datadir:/var/lib/mysql 目录映射（挂载宿主机目录和 docker容器中的目录，前面是宿主机目录，后面是容器内部目录）-v /data/mysql/conf.d:/etc/mysql/conf.d 目录映射（mysql配置目录）-d 后台运行-e 环境参数，MYSQL_ROOT_PASSWORD设置root用户的密码 执行上述命令后，执行查询容器的命令就可以看到创建的mysql容器 1docker ps -a 常见问题上述虽然安装好了mysql，但是使用远程的Navicat连接时提示错误，不能正确连接mysql，此时需要修改按照下面说的步骤修改一下mysql的密码模式以及主机等内容才可以。修改mysql密码以及可访问主机 进入容器内部 1docker exec -it mysql /bin/bash 连接mysql 1mysql -uroot -p 使用mysql库 1use mysql; 修改访问主机以及密码等，设置为所有主机可访问 123ALTER USER &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;;#注意： mysql_native_password，mysql8.x版本必须使用这种模式，否则navicate无法正确连接 刷新 123flush privileges;exit; 远程使用Navicat连接数据库","categories":[{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/categories/Docker/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"docker安装","slug":"docker-01","date":"2021-12-09T13:20:57.000Z","updated":"2021-12-11T09:38:16.024Z","comments":false,"path":"202112/docker-01.html","link":"","permalink":"https://xiaoyuge5201.github.io/202112/docker-01.html","excerpt":"","text":"新的服务器没有安装docker，使用docker命令时提示：docker: command not found错误信息 1. 更新yum包1yum update 2.安装依赖软件包1yum install -y yum-utils device-mapper-persistent-data lvm2 3.设置yum源1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 4.安装docker12#默认安装最新的docker稳定版本。yum install docker-ce 5.启动docker服务1systemctl start docker 6.设置开机自启动1systemctl enable docker 7. 查看docker版本信息1docker version 至此，解决。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://xiaoyuge5201.github.io/tags/docker/"}]},{"title":"Nginx基础篇（四）Nginx实现反向代理","slug":"nginx-04","date":"2021-12-05T08:52:42.000Z","updated":"2021-12-11T09:37:46.179Z","comments":false,"path":"202112/nginx-04.html","link":"","permalink":"https://xiaoyuge5201.github.io/202112/nginx-04.html","excerpt":"","text":"1. 正向代理和反向代理 正向代理：正向代理类似一个跳板机，代理访问外部资源比如我们国内访问谷歌，直接访问访问不到，我们可以通过一个正向代理服务器，请求发到代理服，代理服务器能够访问谷歌，这样由代理去谷歌取到返回数据，再返回给我们，这样我们就能访问谷歌了 正向代理的用途： （1）访问原来无法访问的资源，如google （2） 可以做缓存，加速访问资源 （3）对客户端访问授权，上网进行认证 （4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 正向代理即是客户端代理, 代理客户端, 服务端不知道实际发起请求的客户端 反向代理：反向代理（Reverse Proxy）实际运行方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器 反向代理的作用： （1）保证内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网 （2）负载均衡，通过反向代理服务器来优化网站的负载 反向代理即是服务端代理, 代理服务端, 客户端不知道实际提供服务的服务端 2. Nginx配置反向代理在http-&gt; server块中配置server_name 1234567891011121314151617server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name http://192.168.44.99; #设置虚拟主机的基本信息 location / &#123; proxy_pass http://192.168.44.1:9096; ###最重要的配置，转发到目标地址， 也可以配置服务器组，然后upstream一个服务器组 proxy_method POST; #设置转发请求的格式 #Nginx在header里面增加一个自定义字段 Host， 用于存放当前客户端IP地址 proxy_set_header Host $host; #获取客户端的真实IP地址设置到header中的字段名为X-Real-IP里面 proxy_set_header X-Real-IP $remote_addr; #获取所有转发请求的IP信息列表 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 那么访问http://192.168.44.99 ， nginx会将请求转发给目标服务器http://192.168.44.1:9096 2.1 location 匹配规则匹配规则从上到下，匹配规则越宽松； 模式 含义 location=/uri = 表示精确匹配，只有完全匹配才能生效 location ^~ /uri ^~ 开头对URL路径进行前缀匹配，并且在正则之前 location ~ pattern 开头表示区分大小写的正则匹配 location ~* pattern 开头表示不区分大小写的正则匹配 location /uri 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后 location / 通用匹配，任何未匹配到其他location的请求都会匹配到，相当于switch中的default","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://xiaoyuge5201.github.io/categories/Nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"Nginx基础篇（三）实现虚拟主机","slug":"nginx-03","date":"2021-12-05T08:31:25.000Z","updated":"2021-12-11T09:37:46.175Z","comments":false,"path":"202112/nginx-install.html","link":"","permalink":"https://xiaoyuge5201.github.io/202112/nginx-install.html","excerpt":"","text":"1. 虚拟主机Virtual Host一种在单一主机或主机群上，实现多网域服务的方法，可以运行多个网站或服务的技术，虚拟主机之间完全独立，并可由用户自行管理虚拟并非指不存在，而是指空间是由实体的服务器延伸而来，其硬件系统可以是基于服务器群，或者单个服务器 使用域名访问虚拟主机，虚拟主机会给一个文件路径，然后部署自己的内容；访问域名时就会访问改文件夹下的某 个资源 2. 使用Nginx配置虚拟主机 在nginx下建立一个ygb的文件夹，里面新建一个index.html 在nginx.conf配置下http -&gt; server块内配置 12345678910111213141516171819202122server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name www.xiaoyuge.work; #设置访问的语言编码 #charset koi8-r; #设置虚拟主机访问日志的存放路径及日志的格式为main #access_log logs/host.access.log main; # 这个是域名反问的虚拟主机的文件路径 root /usr/local/nginx/data/ygb #设置虚拟主机的基本信息 location / &#123; #设置虚拟主机默认访问的网页 index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动,然后在浏览器访问域名www.xiaoyuge.work 1./nginx -c ./nginx.conf","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://xiaoyuge5201.github.io/categories/Nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"Nginx基础篇（二）安装","slug":"nginx-02","date":"2021-12-05T08:10:44.000Z","updated":"2021-12-11T09:37:46.182Z","comments":false,"path":"202112/nginx-install.html","link":"","permalink":"https://xiaoyuge5201.github.io/202112/nginx-install.html","excerpt":"","text":"1.Nginx安装 安装nginx前首先要确认系统中是否安装了gcc 、pcre-devel、zlib-devel、openssl-devel 1234#1、rpm包安装的，可以用 rpm -qa 看到，如果要查找某软件包是否安装，用 rpm -qa | grep &quot;软件或者包的名字&quot;#2、以deb包安装的，可以用 dpkg -l 看到。如果是查找指定软件包，用 dpkg -l | grep &quot;软件或者包的名字&quot;#3、yum方法安装的，可以用 yum list installed 查找，如果是查找指定包，用 yum list installed | grep &quot;软件名或者包名&quot;yum list installed | grep &quot;gcc&quot; 安装依赖包 1yum -y install gcc pcre-devel zlib-devel openssl openssl-devel 下载并解压安装包 1234567//创建nginx存放文件夹cd /usr/localmkdir nginxcd nginx#下载tar包wget http://nginx.org/download/nginx-1.13.7.tar.gztar -xvf nginx-1.13.7.tar.gz 配置 12345cd nginx-1.13.7./configure --prefix=/usr/local/nginxmakemake install 测试是否安装成功 1./sbin/nginx -t 配置nginx.conf 1234567891011121314151617181920vim /usr/local/nginx/cong/nginx.conf#修改如下server &#123; listen 80; server_name localhost; # 注意设定 root路径是有dist的 location / &#123; root /usr/local/webapp/dist; index /index.html; &#125; #跨域 ip和port自行替换 location /adminApi &#123; proxy_pass http://ip:port; &#125;&#125; 启动 123#启动nginxcd /usr/local/nginx/sbin./nginx-02 常用命令： 123456789101112131415161718192021222324252627282930313233343536373839404142#修改配置后重新启动./nginx-02 -s reload#如果出现：nginx: [error] open() ＂/usr/local/nginx/logs/nginx.pid＂ failed/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf#再次启动即可#查看nginx进程是否启动ps -ef|grep nginx#平滑启动nginxkill -HUP#主进程号或进程号文件路径 或者使用/usr/nginx/sbin/nginx -s reload#注意，修改了配置文件后最好先检查一下修改过的配置文件是否正 确，以免重启后Nginx出现错误影响服务器稳定运行。#判断Nginx配置是否正确命令如下：nginx -t -c /usr/nginx/conf/nginx.conf#或者使用/usr/nginx/sbin/nginx -t#重启nginx reload/usr/local/nginx/sbin/nginx -s reload service nginx restart#启动./nginx-02#关闭./nginx-02 -s stop#配置nginx开机自启动vim /etc/rc.d/rc.local#再文件中添加nginx启动地址 touch /var/lock/subsys/local/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf#设置开机自启动nginx/usr/local/nginx/sb/nginx 启动后访问localhost 效果如下： 2.Nginx配置12345678910111213141516171819202122232425...... 全局块events &#123; //events 块&#125;###数据库配置stream &#123; server &#123; listen 3306; proxy_pass db; &#125; upstream db &#123; server 192.168.18.130:3305; server 192.168.18.129:3305; &#125; &#125;http&#123; ##http全局块 server+&#123; location +[] &#125;&#125; 2.1配置内容规则官网配置教程：https://nginx.org/en/docs/dirindex.html变量应用：https://nginx.org/en/docs/varindex.html 用#表示注释 每行配置的结尾需要加上分号 如果配置项值中包括语法符号，比如空格符，那么需要使用单引号或者双引号行括住配置项值，否则ngin x会报语法错误 单位简写： K或者k千字节（kilo byte, KB） M或者m兆字节（megabyte MB） ms(毫秒)，s(秒)， m(分)， h(小时) ， d (天)， w（周）， M（月，包含30天），y（年） 2.2 详细配置内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157######## Nginx的main(全局配置)文件#指定nginx运行的用户及用户组,默认为nobody#user nobody;#开启的线程数，一般跟逻辑CPU核数一致worker_processes 1;#定位全局错误日志文件，级别以notice显示，还有debug,info,warn,error,crit模式，debug输出最多，crir输出最少，根据实际环境而定#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#指定进程id的存储文件位置#pid logs/nginx.pid;#指定一个nginx进程打开的最多文件描述符数目，受系统进程的最大打开文件数量限制#worker_rlimit_nofile 65535events &#123; #设置工作模式为epoll,除此之外还有select,poll,kqueue,rtsig和/dev/poll模式 #use epoll; #定义每个进程的最大连接数,受系统进程的最大打开文件数量限制。 worker_connections 1024;&#125;###数据库的负载均衡stream &#123; upstream mysql_nginx &#123; hash $remote_addr consistent; server 192.168.18.128:3306 weight=5 max_fails=3 fail_timeout=30s; server 192.168.18.129:3306; server 192.168.18.130:3306; ##last_conn; #最小连接 &#125; server &#123; listen 3306; # 数据库服务器监听端口 proxy_connect_timeout 10s; proxy_timeout 300s; # 设置客户端和代理服务之间的超时时间，如果5分钟内没操作将自动断开。 proxy_pass mysql_nginx; &#125;&#125;#######Nginx的Http服务器配置,Gzip配置http &#123; #主模块指令，实现对配置文件所包含的文件的设定，可以减少主配置文件的复杂度，DNS主配置文件中的zonerfc1912,acl基本上都是用include语句。 include mime.types; #核心模块指令，智力默认设置为二进制流，也就是当文件类型未定义时使用这种方式 default_type application/octet-stream; #下面代码为日志格式的设定，main为日志格式的名称，可自行设置，后面引用 #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #引用日志main， main是log-format的格式，在上面配置了；后面可以加上日志缓冲区大小，写满了就flush到磁盘中buffer = 1M; #access_log logs/access.log main; #设置允许客户端请求的最大的单个文件字节数 #client_max_body_size 20M; #指定来自客户端请求头的headebuffer大小 #client_header_buffer_size 32k; #指定连接请求试图写入缓存文件的目录路径 #client_body_temp_path /dev/shm/client_body_temp; #指定客户端请求中较大的消息头的缓存最大数量和大小，目前设置为4个32KB #large client_header_buffers 4 32k; #开启高效文件传输模式 sendfile on; #开启防止网络阻塞 #tcp_nopush on; #开启防止网络阻塞 #tcp_nodelay on; #设置客户端连接保存活动的超时时间 #keepalive_timeout 0; keepalive_timeout 65; #设置客户端请求读取超时时间 #client_header_timeout 10; #设置客户端请求主体读取超时时间 #client_body_timeout 10; #用于设置相应客户端的超时时间 #send_timeout ####HttpGZip模块配置 #httpGzip modules #开启gzip压缩 #gzip on; #设置允许压缩的页面最小字节数 #gzip_min_length 1k; #申请4个单位为16K的内存作为压缩结果流缓存 #gzip_buffers 4 16k; #设置识别http协议的版本，默认为1.1 #gzip_http_version 1.1; #指定gzip压缩比，1-9数字越小，压缩比越小，速度越快 #gzip_comp_level 2; #指定压缩的类型 #gzip_types text/plain application/x-javascript text/css application/xml; #让前端的缓存服务器进过gzip压缩的页面 #gzip_vary on; #########Nginx的server虚拟主机配置 server &#123; #监听端口为 80 listen 80; #设置主机域名 server_name localhost; #设置访问的语言编码 #charset koi8-r; #设置虚拟主机访问日志的存放路径及日志的格式为main #access_log logs/host.access.log main; #设置虚拟主机的基本信息 location / &#123; #设置虚拟主机的网站根目录 root html; #设置虚拟主机默认访问的网页 index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125;&#125; 2.3 日志在nginx同级目录下logs文件夹 access.log 正常日志 error.log 错误日期 需要在nginx.conf中的http模块配置access_log","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"Nginx基础篇（一）扫盲","slug":"nginx-md","date":"2021-12-05T06:56:36.000Z","updated":"2021-12-11T09:41:52.529Z","comments":false,"path":"202112/Nginx-Basics-I-literacy.html","link":"","permalink":"https://xiaoyuge5201.github.io/202112/Nginx-Basics-I-literacy.html","excerpt":"","text":"1.Nginx发展史作者：logo Sysoev 2000年地洞，c语言编写 2004年开源 2011年成立商业公司 2013 发布商业版本Nginx plus 2019.5月F5 Networks收购nginx 2019.12被Rambler集团起诉 2.Nginx与其他web服务器对比 Nginx与Apache HTTP server project区别用来响应用户请求的web服务器 Nginx 和tomcat区别Nginx是HTTP Server，主要是用于访问一些静态资源，可以用做代理服务器Tomcat是Application Server应用服务器，用来存放和运行程序； HTTP Server 和Application Server区别与联系 3. HTTP知识3.1 IP和端口120.77.38.160:80 0为A类，10为B类，110为C类，1110为D类，1111为E类。D类地址供组播使用，E类地址保留。 端口是：0～65535 3.2 域名协议、子域名、顶级域名、域名类型、资源路径、参数 12345678#https 协议默认端口443 可以省略https://www.baidu.com:443#user：子域名， com为域名类型（cn中国， us美国...）； 3623252831 为资源路径https://user.qzone.qq.com/3623252831#？号后面为参数https://baike.baidu.com/item/测试/232323?fr=asdfasdf 域名(domainName)和IP的关系以及域名的组成 域名：https://www.baidu.com:443/member/query?far=adsfad http/ https: 协议 baidu: 顶级域名 Com： 域名类型 www: 子域名，可以有多级：user.qzone.qq.com/232323 far=asdfa: 参数 member/query: 资源路径DNS(domain name server)将域名转化为ip+port 3.3 HTTP协议的特点 简单快速 灵活 无连接（一次请求，连接关闭） 无状态（每次请求都和之前的请求无关） 3.4 HTTP协议的请求格式12345Request URL: https://prtas.videocc.net/v2/view?pid=1638687363047X1327470&amp;vid=8c8d9388d0b4c16f41ef557fba23dede_8&amp;uid=8c8d9388d0&amp;flow=0&amp;ts=1638688553584&amp;href=aHR0cHM6Ly9rZS5ndXBhb2VkdS5jbi9wbGF5LzI4OD9waGFzZUlkPTU&amp;duration=1278&amp;cts=789&amp;sign=fcf19468eff088e983796d5826268f2d&amp;sd=1190&amp;pd=788&amp;pn=HTML5&amp;pv=v1.15.0&amp;sid=ZDIzZGM4ODUtNDM2My00MTQ3LWJmYTktY2M3MDgwM2U0NDc5&amp;param1=&amp;param2=MTc2MjEyODQ5OTg&amp;param3=&amp;cataid=1591268435818Request Method: GETStatus Code: 200 Remote Address: 221.231.81.238:443Referrer Policy: strict-origin-when-cross-origin 请求行 请求类型 Request Method GET: 请求指定的页面细腻，并返回尸体主题 HEAD: 类似于GET请求，只不过返回的相应中没有具体的内容，用于获取报头 POST：想指定资源提交数据进行处理请求，数据被高喊在请求体中 PUT: 从客户端想服务器传送的数据取代指定的文档的内容 DELETE: 请求服务器删除指定的页面 CONNECT: HTTP/1.1协议中预留给能够将连接方式改为管道方式的代理服务器 OPTIONS: 允许客户端查看服务器的性能 TRACE: 回显服务器收到的请求，主要用于测试后诊断 请求头 空行和请求数据 3.5 HTTP协议的返回格式状态行、小洗头、空行和响应正文 1234567891011HTTP/1.1 200Server: nginx/1.20.1Date: Sun, 05 Dec 2021 07:24:45 GMTContent-Type: application/json;charset=UTF-8Transfer-Encoding: chunkedConnection: keep-aliveAccess-Control-Allow-Origin: https://ke.gupaoedu.cnAccess-Control-Allow-Credentials: trueAccess-Control-Allow-Methods: PUT,POST,GET,DELETE,OPTIONS,PATCHAccess-Control-Allow-Headers: DNT,web-token,app-token,Authorization,Accept,Origin,Keep-Alive,User-Agent,X-Mx-ReqToken,X-Data-Type,X-Auth-Token,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,token,showerrAccess-Control-Max-Age: 86400 Http格式响应状态码有哪些 1xx: informational(信息性状态码) 接受的请求正在处理 2xx: success(成功状态码) 请求正常处理完毕 3xx：redirection（重定向状态码）需要进行复检操作以完成请求 4xx：client error（客户端错误状态码） 服务器无法处理请求 5xx: server error（服务器错误错误状态码） 服务器处理请求出错 3.6 通用头字段Common Header 字段 含义 Cache-control 控制缓存的行为 Connection 控制不再转发给代理的收不字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主题的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 3.7 响应头字段Response Header 字段 含义 Accept-Ranges 是否接收字节范围请求 Age 推算资源创建经过的时间 ETag 资源的匹配信息 Location 另客户端重定向至指定的URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 3.8 实体头字段 Entity Header 字段 含义 Allow 资源科支持的http方法 Connect-Encoding 实体主体适用的编码格式 Content-Language 实体主体的自然语言 Content-length 实体主体的大小 Content-Location 替代敌营资源的URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://xiaoyuge5201.github.io/categories/Nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"}]},{"title":"Mysql添加/修改/删除字段","slug":"mysql-column","date":"2021-11-15T13:13:42.000Z","updated":"2021-12-11T09:34:27.907Z","comments":false,"path":"202111/mysql-operate-column.html","link":"","permalink":"https://xiaoyuge5201.github.io/202111/mysql-operate-column.html","excerpt":"","text":"1. 添加字段1.1 在末尾添加字段1）语法： 1ALTER TABLE &lt;表名&gt; ADD &lt;字段名&gt; &lt;数据类型&gt; [约束条件]; 语法格式的说明： &lt;表名&gt; 为数据表的名字； &lt;字段名&gt; 为所要添加的字段的名字； &lt;数据类型&gt; 为所要添加的字段能存储数据的数据类型； [约束条件] 是可选的，用来对添加的字段进行约束。 这种语法格式默认在表的最后位置（最后一列的后面）添加新字段 2）示例：在user表末尾添加字段phone 1ALTER TABLE user ADD phone VARCHAR(11) DEFAULT NULL COMMENT &#x27;电话号码&#x27;; 1.2 在开头添加字段1）语法： 1ALTER TABLE &lt;表名&gt; ADD &lt;字段名&gt; &lt;数据类型&gt; [约束条件] FIRST; FIRST 关键字一般放在语句的末尾2）示例：在user表开头添加字段user_id 1ALTER TABLE user ADD user_id VARCHAR(32) NOT NULL COMMENT &#x27;用户主键&#x27; FIRST; 1.3 在中间添加字段1）语法： 1ALTER TABLE &lt;表名&gt; ADD &lt;字段名&gt; &lt;数据类型&gt; [约束条件] AFTER &lt;已经存在的字段名&gt;; AFTER 的作用是将新字段添加到某个已有字段后面。注意：只能在某个已有字段的后面添加新字段，不能在它的前面添加新字段 2）示例：在user表的user_id字段后添加username字段 1ALTER TABLE user ADD username VARCHAR(30) DEFAULT NULL COMMENT &#x27;用户名&#x27; AFTER `user_id`; 2. 修改字段2.1 修改字段属性1）语法： 1ALTER TABLE &lt;表名&gt; MODIFY &lt;字段名&gt; &lt;数据类型&gt; [约束条件]; 2）示例1：修改字段属性 12-- 将email字段VARCHAR(50)修改成VARCHAR(200)ALTER TABLE user MODIFY email VARCHAR(200) NOT NULL DEFAULT &#x27;email@163.com&#x27;; 注意：修改时如果不带完整性约束条件，原有的约束条件将丢失，如果想保留修改时就得带上完整性约束条件 3）示例2： 将email移到phone后面 1ALTER TABLE user MODIFY email VARCHAR(50) AFTER `phone`; 4）示例3：放置第一个，保留原完成性约束条件 1ALTER TABLE user`MODIFY email VARCHAR(50) NOT NULL DEFAULT &#x27;test@163.com&#x27; FIRST; 5）示例4：修改成大小写敏感，即查询区分大小写 1ALTER TABLE user MODIFY username VARCHAR(30) BINARY CHARACTER SET utf8 COLLATE utf8_bin DEFAULT NULL COMMENT &#x27;用户名&#x27;; 2.2 修改字段名称和属性1）语法： 1ALTER TABLE &lt;表名&gt; CHANGE &lt;原字段名&gt; &lt;新字段名&gt; &lt;数据类型&gt; [约束条件]; 2）示例：将username字段修改成user_name 1ALTER TABLE user CHANGE username user_name VARCHAR(30) DEFAULT NULL COMMENT &#x27;用户名&#x27;; 2.3 添加、删除默认值1）语法： 12345-- 添加默认值ALTER TABLE &lt;表名&gt; ALTER &lt;字段名&gt; SET DEFAULT &lt;默认值&gt;;-- 删除默认值ALTER TABLE &lt;表名&gt; ALTER &lt;字段名&gt; DROP DEFAULT; 2）示例：给sex添加默认值 1ALTER TABLE USER ALTER sex SET DEFAULT &#x27;难&#x27;; 3）示例：删除sex默认值 1ALTER TABLE user ALTER sex DROP DEFAULT; 2.4 添加、删除主键 语法：12345-- 添加主键ALTER TABLE &lt;表名&gt; ADD [CONSTRAINT &lt;约束名&gt;] PRIMARY KEY (&lt;字段名称,...&gt;);-- 删除主键ALTER TABLE &lt;表名&gt; DROP PRIMARY KEY; 2）示例：添加主键1ALTER TABLE user ADD PRIMARY KEY (user_id) 3）示例：添加复合主键 1ALTER TABLE user_role ADD PRIMARY KEY (user_id, role_id); 4）示例：删除主键 1ALTER TABLE user DROP PRIMARY KEY; 5）示例：删除带自增长属性的主键 1234-- 先用MODIFY删除自增长属性，注意MODIFY不能去掉主键属性ALTER TABLE test MODIFY id INT UNSIGNED;-- 再来删除主键ALTER TABLE test DROP PRIMARY KEY; 2.5 添加、删除唯一索引1）语法： 12345-- 添加唯一性约束ALTER TABLE &lt;表名&gt; ADD [CONSTANT &lt;约束名&gt;] UNIQUE [INDEX | KEY] [索引名称](&lt;字段名称,...&gt;)-- 删除唯一性约束ALTER TABLE &lt;表名&gt; DROP [INDEX | KEY] [索引名称]; 2）示例：为username添加唯一性约束，如果没有指定索引名称，系统会以字段名建立索引 1ALTER TABLE user ADD UNIQUE(username); 3）示例：为username添加唯一性约束，并指定索引名称 1ALTER TABLE user ADD UNION KEY uni_username(username); 4）示例：查看索引 1SHOW CREATE TABLE user; 5）示例：添加联合UNIQUE 1ALTER TABLE user ADD UNIQUE INDEX uni_nickname_username(nickname, username); 6）示例：删除索引 123ALTER TABLE user DROP INDEX username;ALTER TABLE user DROP KEY uni_username;ALTER TABLE user DROP INDEX uni_nickname_username; 2.6 修改表的存储引擎1）语法： 1ALTER TABLE &lt;表名&gt; ENGINE=&lt;存储引擎名称&gt; 2）示例： 12ALTER TABLE user ENGINE=MyISAM;ALTER TABLE user ENGINE=INNODB; 2.7 修改自增长值1）语法： 1ALTER TABLE &lt;表名&gt; AUTO_INCREMENT=[值]; 2）示例： 1ALTER TABLE user AUTO_INCREMENT= 100; 博客原文链接：https://www.cnblogs.com/Jimc/p/12979319.html如有侵权，请联系删除！","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"TIDB设置sql_mode","slug":"sql-model","date":"2021-11-15T12:57:46.000Z","updated":"2021-12-11T09:34:52.725Z","comments":false,"path":"202111/tidb-set-sql-mode.html","link":"","permalink":"https://xiaoyuge5201.github.io/202111/tidb-set-sql-mode.html","excerpt":"","text":"1. 使用命令查询当前sql_mode123select @@sql_mode-- 或者select @@GLOBAL.sql_mode sql_mode常用值： ONLY_FULL_GROUP_BY对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中 NO_AUTO_VALUE_ON_ZERO该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。如果用户希望插入的值为0，而该列又是自增长的，那么这个选项就有用了。 STRICT_TRANS_TABLES在该模式下，如果一个值不能插入到一个事务中，则中断当前的操作，对非事务表不做限制 NO_ZERO_IN_DATE在严格模式下，不允许日期和月份为零 NO_ZERO_DATE设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告 ERROR_FOR_DIVISION_BY_ZERO在insert或update过程中，如果数据被零除，则产生错误而非警告。如果未给出该模式，那么数据被零除时Mysql返回NULL NO_AUTO_CREATE_USER禁止GRANT创建密码为空的用户 NO_ENGINE_SUBSTITUTION如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常 PIPES_AS_CONCAT将”||”视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样是，也和字符串的拼接函数Concat想类似 ANSI_QUOTES启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符 2. 临时设置（新session仍然使用之前的sql_mode）1set sql_mode=‘ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES’; 3. 全局设置（新session仍然使用修改后的sql_mode）1set @@global.sql_mode=&#x27;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE‘；","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"tidb","slug":"tidb","permalink":"https://xiaoyuge5201.github.io/tags/tidb/"}]},{"title":"Java中将List列表转换为字符串","slug":"list-to-string","date":"2021-10-10T09:48:19.000Z","updated":"2022-03-19T05:26:01.842Z","comments":false,"path":"202110/list_to_string.html","link":"","permalink":"https://xiaoyuge5201.github.io/202110/list_to_string.html","excerpt":"","text":"1. toString() 方法List.toString()是最简单的，但它在开头和结尾添加方括号，每个字符串用逗号分隔符分隔。缺点是我们不能用另一个分隔符替换逗号，也不能去掉方括号 12345678910111213141516171819public class ListToStringUsingToStringExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // converting List&lt;String&gt; to String using toString() method String stringFromList = list.toString(); // priting the string System.out.println(&quot;String : &quot;+stringFromList); &#125;&#125;// 输出：String : [One, Two, Three, Four, Five] 2. Java 8 String.join()java 8 String添加了一个特殊的方法String.join()以将集合转换为具有给定分隔符的字符串 123456789101112131415161718192021222324252627public class ListToStringUsingString_JoinExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // converting List&lt;String&gt; to String using toString() method String stringFromList = String.join(&quot;~&quot;, list); // priting the string System.out.println(&quot;String with tilde delimiter: &quot;+stringFromList); // delimiting with pipe | symbol. String stringPipe = String.join(&quot;|&quot;, list); // printing System.out.println(&quot;String with pipe delimiter : &quot;+stringPipe); &#125;&#125;//输出：// String with tilde delimiter: One~Two~Three~Four~Five// String with pipe delimiter : One|Two|Three|Four|Five 3. Collectors.joining()Collectors.join()方法来自 java 8 stream api。Collctors.joining()方法将分隔符、前缀和后缀作为参数。此方法将列表转换为具有给定分隔符、前缀和后缀的字符串。 查看以下有关使用不同分隔符的 join() 方法的示例。但是，String.join() 方法不提供前缀和后缀选项。 123456789101112131415161718192021222324public class ListToStringUsingString_JoinExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // using java 8 Collectors.joining with delimiter, prefix and suffix String joiningString = list.stream().collect(Collectors.joining(&quot;-&quot;, &quot;&#123;&quot;, &quot;&#125;&quot;)); // printing System.out.println(&quot;Collectors.joining string : &quot;+joiningString); String joiningString3 = list.stream().collect(Collectors.joining(&quot;@&quot;, &quot;&quot;, &quot;&quot;)); // printing System.out.println(&quot;Collectors.joining string with @ separator : &quot;+joiningString3); &#125;&#125;//输出：//Collectors.joining string : &#123;One-Two-Three-Four-Five&#125;//Collectors.joining string with @ separator : One@Two@Three@Four@Five 4. Apache Commons StringUtils.join()使用来自 apache commons 包的外部库。该库有一个方法StringUtils.join() ，它采用类似于 String.join() 方法的列表和分隔符 12345678910111213141516171819202122232425public class ListToStringUsingStringUtils_JoinExample &#123; public static void main(String args) &#123; // creating a list with strings. List&lt;String&gt; list = Arrays.asList(&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;); // using java 8 Collectors.joining with delimiter, prefix and suffix String joiningString = StringUtils.join(list, &quot;^&quot;); // printing System.out.println(&quot;StringUtils.join string with ^ delimiter : &quot;+joiningString); String joiningString3 = StringUtils.join(list, &quot;$&quot;); // printing System.out.println(&quot;StringUtils.join string with @ separator : &quot;+joiningString3); &#125;&#125;//输出：// StringUtils.join string with ^ delimiter : One^Two^Three^Four^Five// StringUtils.join string with @ separator : One$Two$Three$Four$Five","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"集合","slug":"集合","permalink":"https://xiaoyuge5201.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"linux关机命令","slug":"shutdown","date":"2021-10-02T03:39:17.000Z","updated":"2022-03-19T05:43:37.354Z","comments":false,"path":"202110/Linux-shutdown-command.html","link":"","permalink":"https://xiaoyuge5201.github.io/202110/Linux-shutdown-command.html","excerpt":"","text":"1. shutdown命令shutdown会给系统计划一个时间关机。它可以被用于停止、关机、重启机器。你可以指定一个时间字符串（通常是 now或者用hh:mm 指定小时/分钟）作为第一个参数。 shutdown命令示例： 12345678910111213shutdownshutdown now #立即关机shutdown 13:20 # 下午13：20关机shutdown -p now ### 关闭机器shutdown -H now ### 停止机器 shutdown -r09:35 ### 在 09:35am 重启机器shutdown -c ## 取消关机 2. halt 命令halt通知硬件来停止所有的 CPU 功能，但是仍然保持通电。你可以用它使系统处于低层维护状态。注意在有些情况会它会完全关闭系统。 halt 命令示例： 12345halt ### 停止机器halt -p ### 关闭机器halt --reboot ### 重启机器 3.poweroff 命令poweroff会发送一个 ACPI 信号来通知系统关机 12345poweroff ### 关闭机器poweroff --halt ### 停止机器poweroff --reboot ### 重启机器 4.reboot 命令reboot 通知系统重启。 12345reboot ### 重启机器reboot --halt ### 停止机器reboot -p ### 关闭机器 5. init 命令一. init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。内核会在过去曾使用过init的几个地方查找它，它的正确位置（对Linux系统来说）是/sbin/init。如果内核找不到init，它就会试着运行/bin/sh，如果运行失败，系统的启动也会失败。 二. init一共分为7个级别，这7个级别的所代表的含义如下 0：停机或者关机（千万不能将initdefault设置为0） 1：单用户模式，只root用户进行维护 2：多用户模式，不能使用NFS(Net File System) 3：完全多用户模式（标准的运行级别） 4：安全模式 5：图形化（即图形界面） 6：重启（千万不要把initdefault设置为6）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"}],"tags":[{"name":"shutdown","slug":"shutdown","permalink":"https://xiaoyuge5201.github.io/tags/shutdown/"}]},{"title":"安装Centos系统以及配置IP","slug":"Installing-CentOS-system","date":"2021-10-01T08:47:11.000Z","updated":"2022-03-21T02:35:02.694Z","comments":false,"path":"202110/installing-centOS-system-and-configuring-IP.html","link":"","permalink":"https://xiaoyuge5201.github.io/202110/installing-centOS-system-and-configuring-IP.html","excerpt":"","text":"1. 系统安装 安装 选择语言 设置时区以及软件安装 选择GNOME桌面，开发工具。然后点击左上角的完成 配置分区，选址本地标准磁盘，并且在分区中勾选”我要配置分区”,”我想让额外空间可用”；初学者可以使用自动配置分区 开始安装 设置Root账户 等待安装成功,安装成功后会提示重启； 2. 永久关闭防火墙1234567891011121314151617一、下面是red hat/CentOs7关闭防火墙的命令!#1:查看防火状态systemctl status firewalldservice iptables status#2:暂时关闭防火墙systemctl stop firewalldservice iptables stop#3:永久关闭防火墙systemctl disable firewalldchkconfig iptables off#4:重启防火墙systemctl enable firewalldservice iptables restart 3. 配置SELinuxSELinux是Linux 内核中提供的强制访问控制系统。selinux有disabled、permissive、enforcing 三种选择： disabled ：不启用控制系统。 permissive：开启控制系统，但是处于警告模式。即使你违反了策略的话它让你继续操作，但是把你的违反的内容记录下来。 Enforcing：开启控制系统，处于强制状态。一旦违反了策略，就无法继续操作下去 使用命令： 12cd /etc/sysconfig/vim selinux 4.修改ip配置文件 进入文件目录 1cd /etc/sysconfig/network-scripts/ #进入配置文件 写入配置信息并保存退出 1vim ifcfg-ens33 #编辑配置文件ifcfg-ens33 如果要设置固定IP的话，常见设置属性有：BOOTPROTO、ONBOOT、IPADDR、NETMASK、GATEWAY 12345678910111213141516171819202122#以下为配置文件的内容TYPE=&quot;Ethernet&quot; #网卡类型（通常是Ethemet以太网）PROXY_METHOD=&quot;none&quot; #代理方式：为关闭状态BROWSER_ONLY=&quot;no&quot; #只是浏览器：否BOOTPROTO=&quot;static&quot; #网卡的引导协议【static：静态IP(指定静态后IP地址就固定了,不建议采用动态分配) dhcp：动态IP none：不指定，不指定容易出现各种各样的网络受限】DEFROUTE=&quot;yes&quot; #默认路由IPV4_FAILURE_FATAL=&quot;no&quot; #是否开启IPV4致命错误检测IPV6INIT=&quot;yes&quot; #IPV6是否自动初始化：是（现在还未用到IPV6，不会有任何影响）IPV6_AUTOCONF=&quot;yes&quot; #IPV6是否自动配置：是（现在还未用到IPV6，不会有任何影响）IPV6_DEFROUTE=&quot;yes&quot; #IPV6是否可以为默认路由：是（现在还未用到IPV6，不会有任何影响）IPV6_FAILURE_FATAL=&quot;no&quot; #是否开启IPV6致命错误检测IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot; #IPV6地址生成模型NAME=&quot;ens33&quot; #网卡物理设备名称UUID=&quot;ab60d501-535b-49f5-a76b-3336a4120f64&quot; #通用唯一识别码，每一个网卡都会有，不能重复，否则两台linux机器只有一台可上网,可不写DEVICE=&quot;ens33&quot; #网卡设备名称，必须和‘NAME’值一样ONBOOT=&quot;yes&quot; #是否开机启动(如果yes则开机后自动加载使用当前配置文件)，要想网卡开机就启动或通过 `systemctl restart network`控制网卡,必须设置为 `yes`IPADDR=192.168.1.111 # 本机IP 设置固定IP 对应上面的BOOTPROTONETMASK=255.255.255.0 #子网掩码 ,可不写GATEWAY=192.168.137.2 #默认网关 ,可不写DNS1=8.8.8.8 # 可不写DNS2=8.8.8.5 # 可不写ZONE=public # 可不写 重启网络服务 1service network restart #重启网卡 查看IP 1ip addr 重启系统 1reboot","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"}],"tags":[{"name":"Centos","slug":"Centos","permalink":"https://xiaoyuge5201.github.io/tags/Centos/"}]},{"title":"LockSupport一个很灵活的线程工具类","slug":"locksupport","date":"2021-09-25T04:59:36.000Z","updated":"2021-12-11T09:32:21.239Z","comments":false,"path":"202109/locksupport-learning.html","link":"","permalink":"https://xiaoyuge5201.github.io/202109/locksupport-learning.html","excerpt":"","text":"LockSupport是一个编程工具类， 主要是为了阻塞和唤醒线程用的。所有的方法都是静态方法，可以让线程在任意位置阻塞，也可以在任意位置唤醒 主要的方法： park(阻塞线程) 和 unpark(启动唤醒线程) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151//源码package java.util.concurrent.locks;import sun.misc.Unsafe; public class LockSupport &#123; private LockSupport() &#123;&#125; // Cannot be instantiated. private static void setBlocker(Thread t, Object arg) &#123; // Even though volatile, hotspot doesn&#x27;t need a write barrier here. UNSAFE.putObject(t, parkBlockerOffset, arg); &#125; /** * @param thread the thread to unpark, or &#123;@code null&#125;, in which case * this operation has no effect */ public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread); &#125; /** * 阻塞当前线程 * blocker是用来记录线程被阻塞时被谁阻塞的。用于线程监控和分析工具来定位原因的。 * @param blocker the synchronization object responsible for this * thread parking * @since 1.6 */ public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); //setBlocker作用是记录t线程是被broker阻塞的 setBlocker(t, blocker); //UNSAFE是一个非常强大的类，他的的操作是基于底层的 UNSAFE.park(false, 0L); setBlocker(t, null); &#125; /** * 暂停当前线程，有超时时间 * blocker是用来记录线程被阻塞时被谁阻塞的。用于线程监控和分析工具来定位原因的。 * @param blocker the synchronization object responsible for this * thread parking * @param nanos the maximum number of nanoseconds to wait * @since 1.6 */ public static void parkNanos(Object blocker, long nanos) &#123; if (nanos &gt; 0) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, nanos); setBlocker(t, null); &#125; &#125; /** * 暂停当前线程，知道某个时间 * blocker是用来记录线程被阻塞时被谁阻塞的。用于线程监控和分析工具来定位原因的。 * @param blocker the synchronization object responsible for this * thread parking * @param deadline the absolute time, in milliseconds from the Epoch, * to wait until * @since 1.6 */ public static void parkUntil(Object blocker, long deadline) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(true, deadline); setBlocker(t, null); &#125; /** * Returns the blocker object supplied to the most recent * invocation of a park method that has not yet unblocked, or null * if not blocked. The value returned is just a momentary * snapshot -- the thread may have since unblocked or blocked on a * different blocker object. * * @param t the thread * @return the blocker * @throws NullPointerException if argument is null * @since 1.6 */ public static Object getBlocker(Thread t) &#123; if (t == null) throw new NullPointerException(); return UNSAFE.getObjectVolatile(t, parkBlockerOffset); &#125; /** * 无期限暂停当前线程 */ public static void park() &#123; UNSAFE.park(false, 0L); &#125; /** * 暂停当前线程，不过有超时时间限制 */ public static void parkNanos(long nanos) &#123; if (nanos &gt; 0) UNSAFE.park(false, nanos); &#125; /** * 暂停当前线程，知道某个时间 * @param deadline 暂停结束时间 */ public static void parkUntil(long deadline) &#123; UNSAFE.park(true, deadline); &#125; /** * Returns the pseudo-randomly initialized or updated secondary seed. * Copied from ThreadLocalRandom due to package access restrictions. */ static final int nextSecondarySeed() &#123; int r; Thread t = Thread.currentThread(); if ((r = UNSAFE.getInt(t, SECONDARY)) != 0) &#123; r ^= r &lt;&lt; 13; // xorshift r ^= r &gt;&gt;&gt; 17; r ^= r &lt;&lt; 5; &#125; else if ((r = java.util.concurrent.ThreadLocalRandom.current().nextInt()) == 0) r = 1; // avoid zero UNSAFE.putInt(t, SECONDARY, r); return r; &#125; // Hotspot implementation via intrinsics API private static final sun.misc.Unsafe UNSAFE; private static final long parkBlockerOffset; private static final long SEED; private static final long PROBE; private static final long SECONDARY; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; tk = Thread.class; parkBlockerOffset = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;parkBlocker&quot;)); SEED = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSeed&quot;)); PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomProbe&quot;)); SECONDARY = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSecondarySeed&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125;&#125; 与wait / notify对比LockSupport是用来阻塞和环线线程的，wait/notify同样也是，那么两者的区别是什么？ wait和notify都是Object中的方法，在调用这两个方法前必须获得锁对象，但是park不需要获取某个对象的锁就可以锁住线程 notify只能随机选择一个线程唤醒，无法唤醒指定的线程，unpark可以唤醒一个指定的线程 LockSupport使用1. 先interrupt在park12345678910111213141516171819202122232425public class LockSupportTest &#123; public static class MyThread extends Thread&#123; @Override public void run() &#123; System.out.println(getName() + &quot;进入线程&quot;); LockSupport.park(); System.out.println(&quot;运行结束&quot;); System.out.println(&quot;是否中断：&quot;+Thread.currentThread().isInterrupted()); &#125; &#125; public static void main(String[] args) &#123; MyThread thread = new MyThread(); thread.start(); System.out.println(&quot;线程启动了，但是在内部进行了park&quot;); thread.interrupt(); System.out.println(&quot;main 线程结束&quot;); &#125;&#125;//输出// 线程启动了，但是在内部进行了park// main 线程结束// Thread-0进入线程// 运行结束 2. 先park在interrupt1234567891011121314151617181920public static class MyThread extends Thread&#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(getName() + &quot;进入线程&quot;); LockSupport.park(); System.out.println(&quot;运行结束&quot;); &#125;&#125;/** * 输出： * 线程启动了，但是在内部进行了park * main 线程结束 * Thread-0进入线程 * 运行结束 */ 趣味题用两个线程，一个输出字母，一个输出数字交替输出如：1A2B3C4D… 1234567891011121314151617181920212223242526public class ThreadDemoTest &#123; static Thread t1 = null, t2 = null; public static void main(String[] args) &#123; char[] a = &quot;1234567&quot;.toCharArray(); char[] b = &quot;ABCDEFG&quot;.toCharArray(); t1 = new Thread(() -&gt; &#123; for (char i : a) &#123; System.out.print(i); LockSupport.unpark(t2); LockSupport.park(); &#125; &#125;, &quot;t1&quot;); t2 = new Thread(() -&gt; &#123; for (char i : b) &#123; LockSupport.park(); System.out.print(i); LockSupport.unpark(t1); &#125; &#125;, &quot;t1&quot;); t1.start(); t2.start(); &#125;&#125;//输出： 1A2B3C4D5E6F7G 使用自旋锁也可以实现上面的结果 12345678910111213141516171819202122232425262728public class CasTest &#123; //定义枚举，包含两个变量 enum ReadyToRun&#123;T1, T2&#125;; static volatile ReadyToRun r = ReadyToRun.T1; public static void main(String[] args) &#123; char[] a = &quot;1234567&quot;.toCharArray(); char[] b = &quot;ABCDEFG&quot;.toCharArray(); new Thread(()-&gt;&#123; for (char c : a)&#123; //当r不为T1时， 空转占着cpu等待，然后输出字符，将r的值设置为T2 while (r != ReadyToRun.T1)&#123;&#125; System.out.print(c+&quot; &quot;); r = ReadyToRun.T2; &#125; &#125;,&quot;t1&quot;).start(); new Thread(()-&gt;&#123; for (char c : b)&#123; while (r != ReadyToRun.T2)&#123;&#125; System.out.print(c+&quot; &quot;); r = ReadyToRun.T1; &#125; &#125;,&quot;t2&quot;).start(); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xiaoyuge5201.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"mysql行列转置","slug":"mysql行列转置","date":"2021-08-25T02:36:37.000Z","updated":"2021-12-11T09:31:39.449Z","comments":false,"path":"202108/MySQL-row-column-transpose.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/MySQL-row-column-transpose.html","excerpt":"","text":"数据表： 行转列结果为：数据库表语句： 1234567891011121314151617181920create table t_score( id int primary key auto_increment, name varchar(20) not null, #名字 Subject varchar(10) not null, #科目 Fraction double default 0 #分数);INSERT INTO `t_score`(name,Subject,Fraction) VALUES (&#x27;王海&#x27;, &#x27;语文&#x27;, 86), (&#x27;王海&#x27;, &#x27;数学&#x27;, 83), (&#x27;王海&#x27;, &#x27;英语&#x27;, 93), (&#x27;陶俊&#x27;, &#x27;语文&#x27;, 88), (&#x27;陶俊&#x27;, &#x27;数学&#x27;, 84), (&#x27;陶俊&#x27;, &#x27;英语&#x27;, 94), (&#x27;刘可&#x27;, &#x27;语文&#x27;, 80), (&#x27;刘可&#x27;, &#x27;数学&#x27;, 86), (&#x27;刘可&#x27;, &#x27;英语&#x27;, 88), (&#x27;李春&#x27;, &#x27;语文&#x27;, 89), (&#x27;李春&#x27;, &#x27;数学&#x27;, 80), (&#x27;李春&#x27;, &#x27;英语&#x27;, 87); 方法一：使用if 12345678910111213141516171819select name as 名字 , sum(if(Subject=&#x27;语文&#x27;,Fraction,0)) as 语文, sum(if(Subject=&#x27;数学&#x27;,Fraction,0))as 数学, sum(if(Subject=&#x27;英语&#x27;,Fraction,0))as 英语, round(AVG(Fraction),2) as 平均分, SUM(Fraction) as 总分from t_score group by name-- 如果不用求总分的话，不需要下面的unionunion( select name as 名字 , sum(语文) Chinese,sum(数学) Math,sum(英语) English,round(AVG(总分),2)as 平均分,sum(总分) score from( select &#x27;TOTAL&#x27; as name, sum(if(Subject=&#x27;语文&#x27;,Fraction,0)) as 语文, sum(if(Subject=&#x27;数学&#x27;,Fraction,0))as 数学, sum(if(Subject=&#x27;英语&#x27;,Fraction,0))as 英语, SUM(Fraction) as 总分 from t_score group by Subject )t GROUP BY t.`name`) 方法二：使用case 1234567891011121314151617select name as name,sum(case when Subject = &#x27;语文&#x27; then Fraction end) as Chinese,sum(case when Subject = &#x27;数学&#x27; then Fraction end) as Math,sum(case when Subject = &#x27;英语&#x27; then Fraction end) as English,sum(fraction)as scorefrom t_score group by name-- 如果不用求总分的话，不需要下面的unionUNION ALL( select name as Name,sum(Chinese) as Chinese,sum(Math) as Math,sum(English) as English,sum(score) as score from( select &#x27;TOTAL&#x27; as name, sum(case when Subject = &#x27;语文&#x27; then Fraction end) as Chinese, sum(case when Subject = &#x27;数学&#x27; then Fraction end) as Math, sum(case when Subject = &#x27;英语&#x27; then Fraction end) as English, sum(fraction)as score from t_score group by Subject,name)t GROUP BY t.`name`) 方法三：使用with rollup在group分组字段的基础上在进行统计数据； 12345678select -- coalesce(name,&#x27;TOTAL&#x27;) name, ifnull(name,&#x27;TOTAL&#x27;) name, sum(if(Subject=&#x27;语文&#x27;,Fraction,0)) as 语文, sum(if(Subject=&#x27;英语&#x27;,Fraction,0)) as 英语, sum(if(Subject=&#x27;数学&#x27;,Fraction,0))as 数学, sum(Fraction) 总分from t_score group by name with rollup","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"转换成小写字母","slug":"algoright-2","date":"2021-08-22T05:15:12.000Z","updated":"2021-12-11T09:30:29.894Z","comments":false,"path":"202108/algorithm-02.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/algorithm-02.html","excerpt":"","text":"实现函数 ToLowerCase()，该函数接收一个字符串参数 str，并将该字符串中的大写字母转换成小写字母，之后返回新的字符串。 1234567示例 1：输入: &quot;Hello&quot;输出: &quot;hello&quot;示例2：输入: &quot;LOVELY&quot;输出: &quot;lovely&quot; 方法一： ASCCII码解题思路：通过ascii码表操作字符串即可,a和A相差32； a-z: 97 - 122 A-Z: 65 - 90 0-9: 48 - 57123456789101112131415public static String toLowerCase(String str) &#123; if (str == null || str.length() == 0) &#123; return str; &#125; StringBuilder sb = new StringBuilder(); for (char ch : str.toCharArray()) &#123; // a-z：97-122 A-Z：65-90 0-9：48-57 if (ch &gt;= &#x27;A&#x27; &amp;&amp; ch &lt;= &#x27;Z&#x27;) &#123; sb.append((char)(ch + 32)); &#125; else &#123; sb.append(ch); &#125; &#125; return sb.toString();&#125; 或者：123456789101112public static String toLowerCase(String str) &#123; if (str == null || str.length() == 0) &#123; return str; &#125; char[] ch = str.toCharArray(); for (int i = 0; i &lt; str.length(); i++) &#123; if (ch[i] &gt;= &#x27;A&#x27; &amp;&amp; ch[i] &lt;= &#x27;Z&#x27;) &#123; ch[i] += 32; &#125; &#125; return String.valueOf(ch);&#125; 方法二： 位运算解题思路： 大写变小写、小写变大写：字符 ^= 32; 大写变小写、小写变小写：字符 |= 32; 大写变大写、小写变大写：字符 &amp;= 33; ASCII码表中大写的A是65，小写的a是97，它们的差是3265 | 32 转为二进制（按8位来算）可以得到 0100 0001 | 0010 0000 = 0110 0001 = 97 = a 12345678910public String toLowerCase(String str) &#123; if (str == null || str.length() == 0) &#123; return str; &#125; char[] ch = str.toCharArray(); for (int i = 0; i &lt; str.length(); i++) &#123; ch[i] |= 32; &#125; return String.valueOf(ch);&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"}]},{"title":"mysqldumpslow分析慢查询日志","slug":"mysqldumpslow分析慢查询日志","date":"2021-08-21T08:16:02.000Z","updated":"2021-12-11T09:31:06.432Z","comments":false,"path":"202108/mysqldumpslow-query-log.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/mysqldumpslow-query-log.html","excerpt":"","text":"按照平均查询输出5行慢查询记录 1mysqldumpslow -s at -t 5 /phpstudy/data/slowquery.log -s 排序方式，可选值有c（记录次数）、t（查询时间）、l（锁定时间）、r（返回记录）、a（平均） -t 显示的记录数Spawn failed解决方式 -g 后面跟正则表达式（如 left join），不区分大小写。 -r 正序排序，即从小到大排序。 -d 调试 debug -v 查看版本 按照平均查询时间排序且只显示含有left join的记录 1mysqldumpslow -s at -g &#x27;left join&#x27; /phpstudy/data/slowquery.log","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"mysql索引","slug":"mysql-index","date":"2021-08-20T07:12:00.000Z","updated":"2021-12-11T09:20:20.137Z","comments":false,"path":"202108/mysql_02.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/mysql_02.html","excerpt":"","text":"拿汉语字典的目录页（索引）打比方，我们可以按拼音、笔画、偏旁部首等排序的目录（索引）快速查找到需要的字。索引分单列索引和组合索引。 单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。 组合索引，即一个索引包含多个列。 创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。建立索引会占用磁盘空间的索引文件。 1.普通索引 创建索引 12-- 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。CREATE INDEX indexName on table_name (column_name ) 添加索引（修改表结构） 12-- 表结构已经存在了，然后使用alter修改表结构添加索引alter table table_name add INDEX indexName(column_name ) 创建表指定 12345CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引 1drop index [indexName] on table_name 2. 唯一索引他和普通索引类似，不同的是：索引列的值必须唯一，但允许有控制。如果是组合索引，则列值的组合必须唯一。 创建索引 1CREATE UNIQUE INDEX indexName ON table_name (column_name (length )) 修改表结构 1ALTER table mytable ADD UNIQUE [indexName] (column_name(length)) 创建表的时候指定 12345CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 3.组合索引 修改表结构指定索引 1ALTER TABLE table_name ADD INDEX indexName (column_name1 , column_name2,...) 创建表的时候指定 12345CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, KEY [indexName] (column_name1 , column_name2,...) ); 3.1 组合索引查询问题 问题描述：在mysql中有张表test_a，有3个字段id,name,num；对这三个字段建立组合索引，那么查询时使用其中某两个或者一个作为查询条件，是否还会走索引根据查询字段的位置不同来决定，如查询id、id,num、id,num,name、 id, name 都可以走索引的，其他条件的查询不能走索引。 组合索引 有“最左前缀”原则。就是只从最左面的开始组合，并不是所有只要含有这三列存在的字段的查询都会用到该组合索引 12-- 添加组合索引ALTER TABLE test_a ADD INDEX &#x27;lianhe&#x27;(id, num, name) 使用三个字段id, num, name查询 123-- 只要三个条件都有，可以随意变换位置，结果都会走索引-- 优化器会将条件顺序优化成上面三种情况后执行EXPLAIN SELECT * FROM test_a WHERE id=1 AND num=&#x27;001&#x27; AND name = &#x27;1#&#x27; 从执行结果上可以看到是从走索引进行查询的 使用num, name 查询 123EXPLAIN SELECT * FROM test_a WHERE name = &#x27;1#&#x27;EXPLAIN SELECT * FROM test_a WHERE num=&#x27;001&#x27; 使用id, name或者id, num 查询 1234-- 只要包括id，可以随意变换位置，结果都会走索引-- 优化器会将条件顺序优化成上面三种情况后执行--如果只有两个字段，只有id条件命中，num或者name 条件不走联合索引。EXPLAIN SELECT * FROM test_a WHERE id=1 AND name = &#x27;1#&#x27; 需要避免索引失效的情况，如：LIKE %xxx，或者条件中使用函数等。4. 使用id查询 1EXPLAIN SELECT * FROM test_a WHERE id=1 使用name或者num查询123EXPLAIN SELECT * FROM test_a WHERE name = &#x27;1#&#x27;EXPLAIN SELECT * FROM test_a WHERE num = &#x27;001&#x27; 3.2 创建组合索引选择规则 经常用的列优先（最左匹配原则） 离散度高的列优先（离散度高原则） 宽度小的列优先（最少空间原则） 4.使用alter命令添加索引1234567891011-- 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): -- 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。ALTER TABLE tbl_name ADD UNIQUE index_name (column_list):-- 添加普通索引，索引值可出现多次。ALTER TABLE tbl_name ADD INDEX index_name (column_list):--该语句指定了索引为 FULLTEXT ，用于全文索引。ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"二分查找","slug":"algorithm","date":"2021-08-19T14:54:43.000Z","updated":"2021-12-11T09:28:49.481Z","comments":false,"path":"202108/binary-search.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/binary-search.html","excerpt":"","text":"二分法查找是一种基于比较目标值和数组中间元素的算法 如果目标值 = 中间值，则找到目标值 如果目标值 &lt; 中间值，则在左侧继续搜索 如果目标值 &gt; 中间值，则在右侧继续搜索 解题思路： 初始化指针left = 0, right=n-1; 当left &lt;= right： 比较中间元素nums[pivot]和目标值target1.target = nums[pivot], 返回pivot2.target &gt; nums[pivot], 则在右侧继续搜索left = pivot+13.target &lt; nums[pivot], 则在左侧继续搜索right = pivot+1 1234567891011121314public int search(int[] nums, int target)&#123; int pivot, left =0, right = nums.length - 1; while (left &lt;= right)&#123; pivot = left + (right - left) / 2; if (nums[pivot] == target)&#123; return pivot; &#125;else if (nums[pivot] &lt; target)&#123; left = pivot + 1; &#125; else&#123; right = pivot - 1; &#125; &#125; return -1;&#125; 复杂度分析： 时间复杂度：O(logN) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"}]},{"title":"springboot读取yml配置的方式","slug":"springboot-yml","date":"2021-08-18T13:41:24.000Z","updated":"2021-12-11T09:22:59.355Z","comments":false,"path":"202108/springboot-yaml.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/springboot-yaml.html","excerpt":"","text":"springboot项目中默认的配置文件是application.properties； 1.yml文件规则 树状结构，结构清晰 不支持tab缩进 可以使用”_”或”-“消协字母代替大写字母；如userName 与user-name， user_name含义是一样的（宽松绑定原则 relaxed binding）; key: value格式书写，value前面有个空格 2. 数据格式 普通的值（数字，字符串，布尔）如： 123port: 123 name: abc flag: true 字符串默认不用加上单引号或者双引号； “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思,name: “zhangsan \\n lisi”：输出；zhangsan 换行 lisi ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据,name: ‘zhangsan \\n lisi’：输出；zhangsan \\n lisi 对象、Map(属性和值)如： 1234567#k: v：在下一行来写对象的属性和值的关系；注意缩进(不支持tab,使用空格)server: port: 8123 tomcat: uri-encoding: utf-8 servlet: context-path: /app 数组（list， set） 1234#用- 值表示数组中的一个元素hands: - left - right 3. 读取方式 @Value注解 12server: port: 8081 12@Value(&quot;$&#123;server.port&#125;&quot;)public String port; 此处的port所在的类需要是一个组件,如果是实体类需要加上@Component @ConfigurationProperties 需要一个JavaBean 来专门映射配置的话,我们一般会使用@ConfigurationProperties来读取. 使用的使用需要@EnableConfigurationProperties注解让类被springboot扫描到； 1234567spring: datasource: druid: url: jdbc:mysql://localhost:3307/app?useUnicode=yes&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;useLegacyDatetimeCode=false driver-class-name: com.mysql.jdbc.Driver username: root password: root 1234567891011//prefix 指定前缀@ConfigurationProperties(prefix = &quot;spring.datasource&quot;)public class MyDataSourceProperties &#123; private String type; private String driverClassName; private String url; private String username; private String password; //省略getter setter方法&#125; 前缀定义了哪些外部属性将绑定到类的字段上 根据 Spring Boot 宽松的绑定规则，类的属性名称必须与外部属性的名称匹配 我们可以简单地用一个值初始化一个字段来定义一个默认值 类本身可以是包私有的 类的字段必须有公共 setter 方法 Environment Spring Environment bean 123456789101112@RestController@RequestMapping(&quot;/test&quot;)public class TestC &#123; @Autowired private Environment env; @RequestMapping(value = &quot;index&quot;, method = RequestMethod.GET) public String index() &#123; return &quot;environment : &quot;+ env.getProperty(&quot;spring.datasource.druid.url&quot;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://xiaoyuge5201.github.io/tags/springboot/"}]},{"title":"Hexo部署出现错误Error Spawn failed解决方式","slug":"hexo-spawn-failed","date":"2021-08-15T10:28:42.000Z","updated":"2022-03-21T02:37:27.732Z","comments":false,"path":"202108/error-spawn-failed.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/error-spawn-failed.html","excerpt":"","text":"部署过程中可能会出现错误: 123456789101112remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: unable to access &#x27;https://github.com/xiaoyuge5201/xiaoyuge5201.github.io.git/&#x27;: The requested URL returned error: 403FATAL &#123; err: Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (/Users/xiaoyuge/workspace/mybolg/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (events.js:315:20) at Process.ChildProcess._handle.onexit (internal/child_process.js:277:12) &#123; code: 128 &#125;&#125; Something&#x27;s wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.htmlxiaoyuge@xiaoyugedeMacBook-Pro mybolg % hexo clean ####解决方式一： 1234567891011##进入站点根目录cd cd /Users/xiaoyuge/workspace/mybolg##删除git提交内容文件夹rm -rf .deploy_git/##执行git config --global core.autocrlf false##最后hexo clean &amp;&amp; hexo g &amp;&amp; hexo d ####解决方式二：有可能是你的git repo配置地址不正确,可以将http方式变更为ssh方式（我的就是这个问题）github在2021-08-13正式启用personal access token后，原来的用户名+密码方式部署会报错，需要采用最新的token登录方式进行部署 。具体方式参考：https://cloud.tencent.com/developer/article/1861466 1remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead. 查看_config.yml文件， 12345deploy: type: git #repo:https://github.com/xiaoyuge5201/xiaoyuge5201.github.io.git 这是原来的路径，现在改成了下面这种 repo: git@github.com:xiaoyuge5201/xiaoyuge5201.github.io.git branch: master","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://xiaoyuge5201.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/tags/hexo/"}]},{"title":"Java守护线程和非守护线程","slug":"thread-01","date":"2021-08-15T06:14:56.000Z","updated":"2021-12-11T09:25:04.129Z","comments":false,"path":"202108/thread-01.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/thread-01.html","excerpt":"","text":"用户线程：我们平常创建的普通线程。 守护线程：用来服务于用户线程；不需要上层逻辑介入 java线程分为守护线程和非守护线程，当java jvm检测主线程或其他子线程执行完之后，守护线程也会马上停止执行，我们可以使用Thread.setDaemon(ture或false)来设置一个线程是守护线程还是非守护线程，默认为false，可以通过Thread.isDaemon()方法查询该线程是否是守护线程 守护线程是所有的用户线程结束生命周期，守护线程才会结束生命周期，只要有一个用户线程存在，那么守护线程就不会结束，例如Java中的垃圾 回收器就是一个守护线程，只有应用程序中所有的线程结束，它才会结束。 123456789101112131415161718192021public class DaemonThread &#123; public static void main(String[] args) &#123; Thread thread = new Thread(DaemonThread::print); thread.setDaemon(true); thread.start(); System.out.println(&quot;主线程main 结束&quot;); &#125; public static void print() &#123; int counter = 1; //写一个死循环的方法来测试 while (true) &#123; try &#123; System.out.println(&quot;Counter:&quot; + counter++); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 输出： 12主线程main 结束Counter:1 如果我们将daemon设置为非守护线程，代码如下: 1thread.setDaemon(false); 这个时候就不会退出while(true)循环了，会一直执行下去，结果如下： 1234567主线程main 结束Counter:1Counter:2Counter:3Counter:4Counter:5.... 总结：守护线程是为用户线程服务的，当用户线程全部结束，守护线程会自动结束。 注意事项： thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。 在Daemon线程中产生的新线程也是Daemon的。 守护线程不能用于去访问固有资源，比如读写操作或者计算逻辑。因为它会在任何时候甚至在一个操作的中间发生中断。 Java自带的多线程框架，比如ExecutorService，会将守护线程转换为用户线程，所以如果要使用后台线程就不能用Java的线程池。 意义以及应用场景: 当主线程结束时，结束其余的子线程（守护线程）自动关闭，就免去了还要继续关闭子线程的麻烦。如：Java垃圾回收线程就是一个典型的守护线程；内存资源或者线程的管理，但是非守护线程也可以。","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"守护线程","slug":"守护线程","permalink":"https://xiaoyuge5201.github.io/tags/%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B/"}]},{"title":"redis常见使用场景","slug":"redis-usage-scenario","date":"2021-08-14T09:51:30.000Z","updated":"2021-12-11T09:23:11.610Z","comments":false,"path":"202108/redis-usage-scenario.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/redis-usage-scenario.html","excerpt":"","text":"1. 缓存String类型例如：热点数据缓存、对象缓存、全页缓存可以提升热点数据的访问效率 2. 数据共享分布式String类型，因为redis是分布式的独立服务，可以在多个应用服务之间共享，例如分布式session 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 3. 分布式锁String类型 setnx方法，只有不存在时才能添加成功返回true 1234567891011public static boolean getLock(String key) &#123; Long flag = jedis.setnx(key, &quot;1&quot;); if (flag == 1) &#123; jedis.expire(key, 10); &#125; return flag == 1;&#125;public static void releaseLock(String key) &#123; jedis.del(key);&#125; 4. 全局IDint 类型， incrby, 利用原子性 1incrby userid 1000 分库分表的场景，一次性拿一段。 5. 计数器int 类型，incr方法例如：文章的阅读量、微博点赞数；允许一定的延迟，先写入redis在定时同步到数据库 第一种方法 12345678910111213141516171819202122232425@Servicepublic class TestService &#123; @Resource RedisTemplate&lt;String,Object&gt; redisTemplate; @Resource(name=&quot;redisTemplate&quot;) private ValueOperations&lt;String,Object&gt; ops; public int testRedis() &#123; try &#123; //此方法会先检查key是否存在，存在+1，不存在先初始化，再+1 ops.increment(&quot;success&quot;, 1); //return (int) ops.get(&quot;success&quot;); //使用这个会出现错误，报错信息 Caused by: org.springframework.core.serializer.support.SerializationFailedException: Failed to deserialize payload. Is the byte array a result of corresponding serialization for DefaultDeserializer?; nested exception is java.io.EOFException。 return Integer.valueOf(redisTemplate.boundValueOps(&quot;success&quot;).get(0, -1)); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125; return 0 ; &#125; &#125; 第二种方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Servicepublic class TestService &#123; @Resource RedisTemplate&lt;String,Object&gt; redisTemplate; @Resource(name=&quot;redisTemplate&quot;) private ValueOperations&lt;String,Object&gt; ops; public int testRedis() &#123; try &#123; //此方法会先检查key是否存在，存在+1，不存在先初始化，再+1 ops.increment(&quot;success&quot;, 1); //return (int) ops.get(&quot;success&quot;); //return Integer.valueOf(redisTemplate.boundValueOps(&quot;success&quot;).get(0, -1)); return (int) getKey(&quot;success&quot;); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125; return 0 ; &#125; public long getKey(final String key) &#123; return redisTemplate.execute(new RedisCallback&lt;Long&gt;() &#123; @Override public Long doInRedis(RedisConnection connection) throws DataAccessException &#123; RedisSerializer&lt;String&gt; redisSerializer = redisTemplate.getStringSerializer(); byte[] rowkey = redisSerializer.serialize(key); byte[] rowval = connection.get(rowkey); try &#123; String val = redisSerializer.deserialize(rowval); return Long.parseLong(val); &#125; catch (Exception e) &#123; return 0L; &#125; &#125; &#125;); &#125; &#125; 设置每天零点过期，重新计数 1234567//当天时间Date date = new Date();//当天零点date = DateUtils.truncate(date, Calendar.DAY_OF_MONTH);//第二天零点date = DateUtils.addDays(date, +1);redisTemplate.expireAt(&quot;success&quot;, date); 6. 限流int类型，incr方法以访问者的IP和其他信息作为key,访问一次增加一次次数，超过次数 则返回false 7. 位统计String类型的bitcount字符是以8位二进制存储的 1234567891011set k1 asetbit k1 6 1setbit k1 7 0get k1 /* 6 7 代表的a的二进制位的修改a 对应的ASCII码是97，转换为二进制数据是01100001b 对应的ASCII码是98，转换为二进制数据是01100010因为bit非常节省空间（1 MB=8388608 bit），可以用来做大数据量的统计。*/ 例如：在线用户统计，留存用户统计 123setbit onlineusers 01 setbit onlineusers 11 setbit onlineusers 20 支持按位与、按位或等等操作 1234BITOPANDdestkeykey[key...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。 BITOPORdestkeykey[key...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 BITOPXORdestkeykey[key...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 BITOPNOTdestkeykey ，对给定 key 求逻辑非，并将结果保存到 destkey 。 计算出7天都在线的用户 1BITOP &quot;AND&quot; &quot;7_days_both_online_users&quot; &quot;day_1_online_users&quot; &quot;day_2_online_users&quot; ... &quot;day_7_online_users&quot; 8. 购物车String 或hash。所有String可以做的hash都可以hash类型是一个String类型的field和value的映射表，每个hash都可以存储2^32 -1键值对使用hash做购物车：以用户id为key, 商品id为field，商品数量为value。 9. 用户消息时间线timelinelist，双向链表，直接作为timeline就好了。插入有序 10. 消息队列List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间 blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低 队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列 栈：先进后出：rpush brpop 11. 抽奖自带一个随机获得值 1spop myset 12. 点赞、签到、打卡假如上面的微博ID是t1001，用户ID是u3001 用 like:t1001 来维护 t1001 这条微博的所有点赞用户 点赞了这条微博：sadd like:t1001 u3001 取消点赞：srem like:t1001 u3001 是否点赞：sismember like:t1001 u3001 点赞的所有用户：smembers like:t1001 点赞数：scard like:t1001 13. 商品标签用 tags:i5001 来维护商品所有的标签。 sadd tags:i5001 画面清晰细腻 sadd tags:i5001 真彩清晰显示屏 sadd tags:i5001 流程至极 14.商品筛选123456// 获取差集sdiff set1 set2// 获取交集（intersection ）sinter set1 set2// 获取并集sunion set1 set2 1234567sadd brand:apple iPhone11sadd brand:ios iPhone11sad screensize:6.0-6.24 iPhone11sad screentype:lcd iPhone 11 筛选商品，苹果的、ios的、屏幕在6.0-6.24之间的，屏幕材质是LCD屏幕 1sinter brand:apple brand:ios screensize:6.0-6.24 screentype:lcd 15. 用户关注、推荐模型12345## follow 关注 fans 粉丝sadd 1:follow 2sadd 2:fans 1sadd 1:fans 2sadd 2:follow 1 我关注的人也关注了他(取交集)： 1sinter 1:follow 2:fans 可能认识的人： 12345## 用户1可能认识的人(差集)：sdiff 2:follow 1:follow## 用户2可能认识的人：sdiff 1:follow 2:follow 16. 排行榜id 为6001 的新闻点击数加1：zincrby hotNews:20190926 1 n6001获取今天点击最多的15条：zrevrange hotNews:20190926 0 15 withscores redis不适用的场景Redis是一种缓存技术，主要用来提高应用的性能，更多的应用场景是对数据库读数据进行缓存，减轻数据库的IO的访问压力，以下场景不太适合使用Redis: 数据规模大小角度 Redis是将数据放在内存进行缓存的，内存相对于磁盘来锁价格是比较贵的。如果成本是需要考虑的重要因素，那么大规模的数据就不太适合； 数据冷热程度角度 很多业务数据可以根据数据读的频繁程度分为热数据和冷数据；频繁使用的热数据一般适合用redis，冷数据一般不太适合用redis,如果大量的冷数据进行了缓存，那是对内存资源的浪费，所以在应用场景上区分冷热数据，将热数据放在内存中，进而提高性能。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"}]},{"title":"MVCC多版本并发控制","slug":"mvcc","date":"2021-08-14T03:03:40.000Z","updated":"2021-12-11T09:20:30.874Z","comments":false,"path":"202108/mvcc.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/mvcc.html","excerpt":"","text":"1. MVCC全称Multi-Version Concurrency Control即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中是心啊事务内存。MVCC在mysql Innodb中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使读写冲突时，也能做到不加锁，非阻塞并发读 2. 当前读和快照读 当前读 像select lock in share mode（共享锁），select for update， update, insert,delete(排他锁)这些操作都是一种当前读；当前读就是读取记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。 快照读 像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别（串行级别快照读会变成当前读）；快照读的实现是基于多版本并发控制（即MVCC）；可以任务MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销； 既然是基于多版本，即快照读可能读到的并不一定是最新版本的数据，有可能是之前的历史版本 MVCC就是为了实现读（快照读）-写冲突不加锁，当前读实际上是一种加锁的操作，是悲观锁的实现。 3. 当前读、快照读和MVCC的关系MVCC多版本并发控制指的是”维持一个数据的多个版本，使得读写操作没有冲突”；Mysql通过快照读的方式去实现MVCC理想模型的其中一个具体非阻塞读功能，相对而言，当前读就是悲观锁的具体功能实现 MVCC模型在Mysql中具体实现有3个隐式字段：undo日志、Read View等去完成的 4. MVCC的作用与好处数据库并发场景分为以下三种： 读-读：没有问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，（脏读、幻读、不可重复读） 写-写：有线程安全问题，可能会存在更新丢失问题 MVCC带来的好处： MVCC是一种用来解决读-写冲突的无所并发控制（在MVCC提出之前采用的是采用悲观锁），也就是事务分配增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务前的数据库快照，主要解决以下问题： 在并发读写数据库时，可以做到在读操作是不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能； 解决脏读、幻读、不可重复读等事务隔离性问题，但不能解决更新丢失问题 MVCC组合方法 MVCC + 悲观锁： MVCC解决读写冲突，悲观锁解决写写冲突 MVCC + 乐观锁： MVCC解决读写冲突，乐观锁解决写写冲突，这种方式可能最大程度的提高数据库并发性能，并解决读写冲突和写写冲突导致的问题 5. MVCC的实现原理实现原理主要是依赖记录中的 3个隐式字段、undo日志 、ReadView 来实现的 在Mysql的InnoDB引擎中就是指在已提交读(READ COMMITTD)和可重复读(REPEATABLE READ)这两种隔离级别下的事务对于SELECT操作会访问版本链中的记录的过程这就使得别的事务可以修改这条记录，反正每次修改都会在版本链中记录。SELECT可以去版本链中拿记录，这就实现了读-写，写-读的并发执行，提升了系统的性能。 5.1 版本链123456begin;#触发分配TRX_IDselect * from t_role;#指定TRX_MYSQL_THREAD_ID=当前CONNECTION_ID,表示查询当前连接select TRX_ID, ROLL_PTR, ROW_ID from INFORMATION_SCHEMA.INNODB_TRX where TRX_MYSQL_THREAD_ID = CONNECTION_ID();commit; 在InnoDB引擎表中，它的聚簇索引记录中有两个必要的隐藏列： TRX_ID 6byte，这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id roll_pointer 每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本) ROW_ID 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引 实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了 比如现在有个事务id是60的执行的这条记录的修改语句 此时在undo日志中就存在版本链 5.2 ReadView已提交读和可重复读的区别就在于它们生成ReadView的策略不同ReadView中主要就是有个列表来存储我们系统中当前活跃着的读写事务，也就是begin了还未提交的事务。通过这个列表来判断记录的某个版本是否对当前事务可见。假设当前列表里的事务id为[80,100]。 如果你要访问的记录版本的事务id为50，比当前列表最小的id80小，那说明这个事务在之前就提交了，所以对当前活动的事务来说是可访问的。 如果你要访问的记录版本的事务id为90,发现此事务在列表id最大值和最小值之间，那就再判断一下是否在列表内，如果在那就说明此事务还未提交，所以版本不能被访问。如果不在那说明事务已经提交，所以版本可以被访问。 如果你要访问的记录版本的事务id为110，那比事务列表最大id100都大，那说明这个版本是在ReadView生成之后才发生的，所以不能被访问。这些记录都是去版本链里面找的，先找最近记录，如果最近这一条记录事务id不符合条件，不可见的话，再去找上一个版本再比较当前事务的id和这个版本事务id看能不能访问，以此类推直到返回可见的版本或者结束。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"java缓存一致性问题","slug":"cache-consistency","date":"2021-08-11T05:31:52.000Z","updated":"2021-12-11T09:09:04.816Z","comments":false,"path":"202108/java-cache-consistency-problem.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/java-cache-consistency-problem.html","excerpt":"","text":"","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"}]},{"title":"volatile关键字","slug":"volatile","date":"2021-08-02T10:20:38.000Z","updated":"2021-12-11T09:26:05.602Z","comments":false,"path":"202108/volatile1.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/volatile1.html","excerpt":"","text":"1.volatile作用 volatile保证有序性，可见性，不能保证原子性 禁止指令重排 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量值，这个新值对其他线程立即可见的 不能保证原子性(线程不安全) 2. 实现原理 通过插入内存屏障指令禁止编译器和CPU对程序进行重排序。 当对声明了volatile的变量进行写操作时，JVM就会向处理器发送一条Lock前缀的指令，这条Lock前缀指令产生如下两个作用： Lock前缀指令会引起处理器缓存回写到系统内存，并使用缓存一致性机制来确保回写的原子性。 一个处理器的缓存回写到系统内存会导致其他处理器的缓存无效。处理器使用MESI控制协议去维护内部缓存和其他处理器缓存的一致性。处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充3.synchronized与volatile比较 volatile关键字是线程同步的轻量级实现，性能较synchronized好；但是volatile关键字只能用于变量，而synchronized关键字可以修饰方法以及代码块 synchronized关键字在java1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其他各种优化之后执行效率有了显著的提升； 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞 volatile关键字保证数据的可见性，但是不能保证数据的原子性；synchronized关键字两者都能保证（synchronized保证原子性，有序性，可见性） volatile关键字主要用于解决变量在多个线程之间的可见性，而synchronized关键字解决的是多个线程之间访问资源的同步性。 synchronized是同步锁，同步快内的代码相当于同一时刻单线程执行 4. 可见性问题Java虚拟机规范中定义了一种Java内存 模型（Java Memory Model，即JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果。Java内存模型的主要目标就是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的细节。 JMM中规定所有的变量都存储在主内存（Main Memory）中，每条线程都有自己的工作内存（Work Memory），线程的工作内存中保存了该线程所使用的变量的从主内存中拷贝的副本。线程对于变量的读、写都必须在工作内存中进行，而不能直接读、写主内存中的变量。同时，本线程的工作内存的变量也无法被其他线程直接访问，必须通过主内存完成整体内存模型如下： 4.1 synchronizedsynchronized关键字的语义JMM（Java Main Memory）有两个规定，保证其实现内存可见性： - 线程解锁前，必须把共享变量的最新值刷新到主内存中 - 线程加锁前，将清空工作内存中共享变量的值，从主内存中重新取值 4.2 volatile 当对volatile变量执行写操作后，JMM会把工作内存中的最新变量值强制刷新到主内存 写操作会导致其他线程中的缓存无效这样，其他线程使用缓存时，发现本地工作内存中此变量无效，便从主内存中获取，这样获取到的变量便是最新的值，实现了线程的可见性。","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xiaoyuge5201.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java内存泄漏排查","slug":"outOfMemoryError","date":"2021-08-01T11:25:57.000Z","updated":"2021-12-11T09:21:13.082Z","comments":false,"path":"202108/java-memory-leak-troubleshooting.html","link":"","permalink":"https://xiaoyuge5201.github.io/202108/java-memory-leak-troubleshooting.html","excerpt":"","text":"1.内存溢出java.lang.OutOfMemoryError：是指程序在申请内存是，没有足够的内存克难攻坚供其使用，出现OutOfMemoryError 产生原因 JMM内存过小 程序不严谨，产生了过多的垃圾 具体表现在以下集中情况 内存中加载的数据量过于庞大，如一次从数据库取出过多的数据 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收 代码中存在死循环或循环过多产生过多重复的对象实体 使用第三方软件的bug 启动参数内存值设定过小 常见错误提示 tomcat:java.lang.OutOfMemoryError: PermGen space tomcat:java.lang.OutOfMemoryError: Java heap space weblogic:Root cause of ServletException java.lang.OutOfMemoryError resin:java.lang.OutOfMemoryError java:java.lang.OutOfMemoryError 解决方法 增加JVM的内存大小对于tomcat容器，找到tomcat在电脑中的安装目录，进入这个目录，然后进入bin目录中，在window环境下找到bin目录中的catalina.bat，在linux环境下找到catalina.sh。编辑catalina.bat文件，找到JAVA_OPTS（具体来说是 set “JAVA_OPTS=%JAVA_OPTS% %LOGGING_MANAGER%”）这个选项的位置，这个参数是Java启动的时候，需要的启动参数。也可以在操作系统的环境变量中对JAVA_OPTS进行设置，因为tomcat在启动的时候，也会读取操作系统中的环境变量的值，进行加载。如果是修改了操作系统的环境变量，需要重启机器，再重启tomcat，如果修改的是tomcat配置文件，需要将配置文件保存，然后重启tomcat，设置就能生效了 优化程序，释放垃圾主要思路就是避免程序体现上出现的情况。避免死循环，防止一次载入太多的数据，提高程序健壮型及时释放。因此，从根本上解决Java内存溢出的唯一方法就是修改程序，及时地释放没用的对象，释放内存空间 2. 内存泄漏Memory Leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存，迟早会被占光。在Java中，内存泄漏就是存在一些被分配的对象，这些对象有下面两个特点：1）首先，这些对象是可达的，即在有向图中，存在通路可以与其相连；2）其次，这些对象是无用的，即程序以后不会再使用这些对象。如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。关于内存泄露的处理页就是提高程序的健壮型，因为内存泄露是纯代码层面的问题 3.内存溢出和内存泄漏的联系内存泄露会最终会导致内存溢出。相同点：都会导致应用程序运行出现问题，性能下降或挂起。不同点： 1) 内存泄露是导致内存溢出的原因之一，内存泄露积累起来将导致内存溢出。 2) 内存泄露可以通过完善代码来避免，内存溢出可以通过调整配置来减少发生频率，但无法彻底避免。 4.排查案例Java的内存泄露多半是因为对象存在无效的引用，对象得不到释放，如果发现Java应用程序占用的内存出现了泄露的迹象，那么我们一般采用下面的步骤分析： 用工具生成java应用程序的heap dump（如jmap） 使用Java heap分析工具（如MAT），找出内存占用超出预期的嫌疑对象 根据情况，分析嫌疑对象和其他对象的引用关系。 分析程序的源代码，找出嫌疑对象数量过多的原因。 实际操作如下：1.登录linux服务器，获取tomcat的pid 1ps -ef|grep java 2.利用jmap初步分析内存映射 1jmap -histo:live pid | head -7 第2行是我们业务系统的对象，通过这个对象的引用可以初步分析出到底是哪里出现了引用未被垃圾回收收集，通知开发人员优化相关代码 3.如果上面一步还无法定位到关键信息，那么需要拿到heap dump，生成离线文件，做进一步分析 1jmap -dump:live,format=b,file=heap.hprof 3514 4. 拿到heap dump文件，利用eclipse插件MAT来分析heap profile。 1.安装MAT插件 2.在eclipse里切换到Memory Analysis视图 3.用MAT打开heap profile文件。直接看到下面Action窗口，有4种Action来分析heap profile，介绍其中最常用的2种: Histogram：这个使用的最多，跟上面的jmap -histo 命令类似，只是在MAT里面可以用GUI来展示应用系统各个类产生的实例。Shllow Heap排序后发现 Cms_Organization 这个类占用的内存比较多（没有得到及时GC），查看引用分析引用栈，找到无效引用，打开源码查看源码！！！","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"内存溢出","slug":"内存溢出","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/"}]},{"title":"JAVA类加载过程","slug":"classLoad","date":"2021-07-31T03:04:02.000Z","updated":"2022-03-21T02:37:56.414Z","comments":false,"path":"202107/java-class-loading-process.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/java-class-loading-process.html","excerpt":"","text":"1.类加载机制JVM将类描述数据从.class文件中加载到内存，并对数据进行解析、初始化，最终形成被JVM直接使用的Java类型；类从被加载到JVM中开始，到卸载为止，整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载7个阶段 加载 加载时jvm做了三件事 1)通过一个类的全限定名获取该类的二进制流 2)将这个字节流的静态存储结构转化为方法区运行时数据结构 3)在内存堆中生成一个代表该类的java.lang.class对象，最为该类数据的访问入口 验证 验证、准备、解析这三步可以看作是一个连接的过程，将类的字节码连接到JVM的运行黄台之中; 验证是为了确保class文件的字节流中包含的信息符合当前虚拟机的要求，不会威胁到jvm的安全。验证内容如下： 文件格式的验证： 验证字节流是否符合class文件袋额规范，是否能被当前版本的虚拟机处理 元数据验证： 对字节码描述的信息进行语义分析，确保符合Java语言规范 字节码验证：通过数据流和控制流分析，确定寓意是否合法，符合逻辑的 符号引用验证：这个娇艳在解析阶段发生 准备 为类的静态变量分配内存，设置初始值，对于final static修饰的变量，直接赋值为用户的定义值。 12//准备阶段过后的初始值为0， 而不是7 public static int a = 7; 解析 解析是将常量池内的符号引用转化为直接引用（如物理内存地址指针） 初始化 初始化阶段，jvm才开始真正执行类中定义的Java代码 执行类构造器()方法的过程，类构造器方法是有编译器自动手机类中所有类变量的赋值动作和静态语句块（static块）中的语句合并产生的 当初始化一个类的时候，如果发现其父类还没有进行过初始化，需有限触发其父类的初始化 虚拟机会保证一个类的()方法在多线程环境被正确加锁和同步 2.类加载器类加载器的主要任务：对类加载过程中的加载操作（根据一个类的全限定名读取该类的二进制字节流到JVM内部，然后转换为一个对应的java.lang.Class对象实例） 类加载器的分类 启动类加载器Bootstrap ClassLoader:在HotSpot虚拟机中，Bootstrap ClassLoader用C++语言编写并嵌入JVM内部，主要负载加载JAVA_HOME/lib目录中的所有类，或者加载由选项-Xbootcalsspath指定的路径下的类 拓展类加载器/ExtClassLoader：ExtClassLoader继承ClassLoader类，负载加载JAVA_HOME/lib/ext目录中的所有类型，或者由参数-Xbootclasspath指定路径中的所有类型 应用程序类加载器/AppClassLoader:ExtClassLoader继承ClassLoader类，负责加载用户类路径ClassPath下的所有类型，一般情况下为程序的默认类加载器 自定义加载器:Java虚拟机规范将所有继承抽象类java.lang.ClassLoader的类加载器，定义为自定义类加载器 3. 双亲委派模型如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式 。 除了启动类加载器以外，每个类加载器拥有一个父类加载器，用户的自定义类加载器的父类加载器是AppClassLoader； 双亲委派模型可以保证全限名指定的类，只被加载一次； 双亲委派模型不具有强制性约束，是Java设计者推荐的类加载器实现方式； 3.1 双亲委派模式优势 采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次 java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改 如果我们在classpath路径下自定义一个名为java.lang.SingleInterge类(该类是胡编的)呢？该类并不存在java.lang中，经过双亲委托模式，传递到启动类加载器中，由于父类加载器路径下并没有该类，所以不会加载，将反向委托给子类加载器加载，最终会通过系统类加载器加载该类。但是这样做是不允许，因为java.lang是核心API包，需要访问权限，强制加载将会报出如下异常 3.2 双庆委派模型实现源码可以打开 java.lang.ClassLoader 类，其 loadClass方法如下： 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 实现方式很简单，首先会检查该类是否已经被加载过了，若加载过了直接返回（默认resolve取false）；若没有被加载，则调用父类加载器的 loadClass方法，若父类加载器为空则默认使用启动类加载器作为父加载器。如果父类加载失败，则在抛出 ClassNotFoundException 异常后，在调用自己的 findClass 方法进行加载 4.自定义类加载器 加密 我们知道Java字节码是可以进行反编译的，在某些安全性高的场景，是不允许这种情况发生的。那么我们可以将编译后的代码用某种加密算法进行加密，加密后的文件就不能再用常规的类加载器去加载类了。而我们自己可以自定义类加载器在加载的时候先解密，然后在加载 动态创建 比如很有名的动态代理。 从非标准的来源加载代码我们不用非要从class文件中获取定义此类的二进制流，还可以从数据库，从网络中，或者从zip包等。 4.1 自定义类加载器方法 类加载时根据双亲委派模型会先一层层找到父加载器，如果加载失败，则会调用当前加载器的 findClass() 方法来完成加载。因此我们自定义类加载器，有两个步骤： 1、继承 ClassLoader 2、覆写 findClass() 方法","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"ClassLoader","slug":"ClassLoader","permalink":"https://xiaoyuge5201.github.io/tags/ClassLoader/"}]},{"title":"mysql数据库锁","slug":"mysql数据库锁","date":"2021-07-24T08:57:10.000Z","updated":"2021-12-11T09:20:10.718Z","comments":false,"path":"202107/mysql_04.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/mysql_04.html","excerpt":"","text":"当数据库有事物的时候，可能会产生数据的不一致，这时就需要一些机制来保证访问的次序，这就是锁的机制；锁的作用：用于挂你对共享资源的并发访问，保证数据库的完整性和一致性。##1. 不同引擎的锁以及锁分类Mysql数据库中，InnoDB支持表、行级锁，而MyISAM支持表级锁Mysql大致可以归纳为以下3种锁： 表级锁：开销小，加锁块，不会出现死锁，发生锁冲突的概率最高，并发度最低。 行级锁：开销大，加锁慢，会出现死锁，发生锁冲突的概率最低，并发度最高。 页面锁：开销和加锁的时间介于表级锁和行级锁之间，会出现死锁，锁粒度介于两者之间；并发度一般，一次锁定相邻一组记录 Mysql表级锁两种模式: 表共享锁（Table Read Lock）和 表独占写锁（Table Write Lock），表现如下： 对一个表的读操作，不会阻塞其他用户对同一表请求，但会阻塞对同一表的写请求； 对MyISAM的写操作，则会则色其他用户对同一表的读和写操作； MyISAM表的读操作和写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作，其他线程的读、写操作都会等待。 ##2.加表级锁MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要直接用LOCK TABLE命令给MyISAM表显式加锁。给MyISAM表显式加锁，一般是为了一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。例如，有一个订单表orders，其中记录有订单的总金额total，同时还有一个订单明细表order_detail，其中记录有订单每一产品的金额小计subtotal，假设我们需要检查这两个表的金额合计是否相等，可能就需要执行如下两条SQL","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"mycat学习","slug":"mycat","date":"2021-07-23T08:16:49.000Z","updated":"2021-12-11T09:23:26.826Z","comments":false,"path":"202107/mycat_learning.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/mycat_learning.html","excerpt":"","text":"Mycat(分库分表中间件)1. 数据库优化策略 重启：释放资源 SQL与索引 表与存储引擎（字段类型选择，长度设置，是否需要分表、分区） 数据库与应用架构（考虑使用缓存服务器，减轻是数据库压力；可以数据库分布式，读写分离，主从复制） 数据库与操作系统配置（修改mysql配置，使用单独服务器部署数据库） 硬件 2. 数据库演化根据业务需要、数据量变化，随之而来的数据库的变化 数据库与应用部署在同一台服务器 单体应用架构，单数据库（数据库服务器和应用服务器分离，但是业务系统越做越大） 多应用单数据库（应用解耦） 多应用 独立数据库 但应用多数据库(分表) 3. 如何分库分表 垂直切分 单库 多库 水平切分 按照月分表或者分成实时、历史表等 分成多库 4. 分库分表带来的问题 跨库关联查询 增加冗余字段（违反了第三范式：表中的所有数据元素不但要能唯一地被主关键字所标识,而且它们之间还必须相互独立,不存在其他的函数关系） 跨数据库的同步（canal、Mq（最好）、ETL、kettle、ogg）(在某个库中同步其他数据库中表的数据，避免跨库关联查询) 全局表(广播表)：比如行政区划表，所有的系统都是一样的； API 分布式事务 Local 排序、翻页、函数计算 - 全局主键 雪花算法leaf redis(int 类型可以设置incby) ZookKeeper uuid(数据过长， 影响索引存储) 多数据源连接（动态数据源） 5. Mycat分库分表中间件官网地址：http://www.mycat.org.cn/ 从阿里cobar升级而来，完全实现了mysql协议，可以当作一个mysql数据库来使用，通过JDBC支持其他数据库实现分库分表，解决了多表join、分布式事务、全局序列号、翻页查询、函数计算的问题 一个彻底开源的，面向企业应用开发的大数据库集群 支持事务、ACID、可以替代MySQL的加强版数据库 一个可以视为MySQL集群的企业级数据库，用来替代昂贵的Oracle集群 一个融合内存缓存技术、NoSQL技术、HDFS大数据的新型SQL Server 结合传统数据库和新型分布式数据仓库的新一代企业级数据库产品 一个新颖的数据库中间件产品 华为云的DDM其实也是根据mycat做的 5.1 核心概念 5.2 Mycat安装与配置5.2.1 Mycat安装从官网下载安装版本，解压到文件(官网建议安装在/usr/local/Mycat)后页面如下图所示： 目录解释如下： bin：存放window版和linux版本除了提供封装成服务的版本之外，也提供了nowrap的shell脚本命令，方便选择和修改；Linux下运行:./mycat console， 首先要chmod + x*;(mycat支持的命令console、start、stop、restart、status、dump) conf：server.xml是mycat服务器参数调整和用户授权的配置文件，schema.xml是逻辑库定义和表以及分片定义的配置文件，rule.xml是分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件，也在这个目录下，配置文件修改，需要重启mycat或者通过9066端口reload **lib:**主要存放mycat依赖的一些jar文件 logs:日志存放在mycat.log中，每天一个文件，日志的配置是在conf/log4j.xml中，根据自己的需要，可以调整输出级别为debug，方便排查问题；注意Linux下部署安装mysql，默认不忽略，需要手动到/etc/my.cnf下配置lower_case_table_names=1使Linux环境下MySQL忽略表明大小写，否则使用mycat的时候会提示找不到表的错误 5.2.2 服务启动与配置Mycat在Linux中部署启动时，首先需要在Linux系统的环境变量中配置MYCAT_HOE,操作方式如下： vi /etc/profile，在系统环境变量文件中增加MYCAT_HOME=/usr/lib/tools/mycat 执行 source/etc/profile命令，使环境变量生效。如果是多台Linux系统中组件Mycat集群，那需要在mycat Server所在的服务器配置对其他ip和主机名的映射，配置方式如下： 经过以上两个步骤的配置，就可以到/usr/lib/tools/mycat/bin目录下执行./mycat start启动mycat服务；使用mycat status查看mycat的运行状态；如下图 5.2.2.1 安装遇到的问题 schema TESTDB refered by user root is not exist! 解决方式： 12345678&lt;!--在conf/server.xml文件中schemas中配置schema.xml文件中的schema的name值--&gt;&lt;!--user中的name为mycat服务的用户名--&gt; &lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;!--这个是mycat服务连接的密码--&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;xiaoyuge&lt;/property&gt;&lt;/user&gt; 5.2.3日志分析mycat的日志文件配置为MYCAT_HOME/conf/log4j.xml 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE log4j:configuration SYSTEM &quot;log4j.dtd&quot;&gt; &lt;log4j:configuration xmlns:log4j=&quot;http://jakarta.apache.org/log4j/&quot;&gt; &lt;appender name=&quot;ConsoleAppender&quot; class=&quot;org.apache.log4j.ConsoleAppender&quot;&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;MM-dd HH:mm:ss.SSS&#125; %5p [%t] (%F:%L) -%m%n&quot; /&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name=&quot;FILE&quot; class=&quot;org.apache.log4j.RollingFileAppender&quot;&gt; &lt;!--日志文件存放的目录--&gt; &lt;param name=&quot;file&quot; value=&quot;$&#123;MYCAT_HOME&#125;/logs/mycat.log&quot; /&gt; &lt;param name=&quot;Append&quot; value=&quot;false&quot;/&gt; &lt;param name=&quot;MaxFileSize&quot; value=&quot;10000KB&quot;/&gt; &lt;param name=&quot;MaxBackupIndex&quot; value=&quot;10&quot;/&gt; &lt;param name=&quot;encoding&quot; value=&quot;UTF-8&quot; /&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;MM/dd HH:mm:ss.SSS&#125; %5p [%t] (%F:%L) -%m%n&quot; /&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;root&gt; &lt;!--level是日志级别，生产环境下加以将级别调整为info/ware，如果是研究测试，碰到异常设置为debug--&gt; &lt;level value=&quot;debug&quot; /&gt; &lt;appender-ref ref=&quot;ConsoleAppender&quot; /&gt; &lt;/root&gt;&lt;/log4j:configuration&gt; 5.2.3.1 warpper日志目前mycat的启动时经过warpper封装成启动脚本，所以日志也会有其相关的日志文件：${MYCAT_HOME}/logs/warapper.log， 在启动的时候如果系统环境配置错误或缺少配置时，导致mycat无法启动，可以通过查看wrapper.log查看具体错误原因。 正常启动 1234567STATUS | wrapper | 2015/04/12 15:05:00 | --&gt; Wrapper Started as DaemonSTATUS | wrapper | 2015/04/12 15:05:00 | Launching a JVM...INFO | jvm 1 | 2015/04/12 15:05:01 | Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.orgINFO | jvm 1 | 2015/04/12 15:05:01 | Copyright 1999-2006 Tanuki Software, Inc. AllRights Reserved.INFO | jvm 1 | 2015/04/12 15:05:01 |INFO | jvm 1 | 2015/04/12 15:05:01 | log4j 2015-04-12 15:05:01 [./conf/log4j.xml]load completed.INFO | jvm 1 | 2015/04/12 15:05:02 | MyCAT Server startup successfully. see logs in logs/mycat.log 启动异常 1234567891011STATUS | wrapper | 2015/02/14 01:43:44 | --&gt; Wrapper Started as DaemonSTATUS | wrapper | 2015/02/14 01:43:44 | Launching a JVM...INFO | jvm 1 | 2015/02/14 01:43:45 | Error: Exception thrown by the agent : java.rmi.server.ExportException:Port already in use: 1984; nested exception is:INFO | jvm 1 | 2015/02/14 01:43:45 | java.net.BindException: Address already in useERROR | wrapper | 2015/02/14 01:43:45 | JVM exited while loading the application. # 日志显示异常原因为 java.net.BindException: Address already in use,也就是端口占用，很有可能是原有服务未停止，或者 Mycat 默认端口被其他程序占用，正常启动成功后会有 mycat.log 日志，如果服务未启动成功不会有对应的日志。 也可以去修改 conf 文件夹里的 wrapper.conf 里的 wrapper.java.additional.7=-Dcom.sun.management.jmxremote.port=1984，server.xml 的&lt;property name=&quot;serverPort&quot;&gt;8066&lt;/property&gt;和&lt;property name=&quot;managerPort&quot;&gt;9066&lt;/property&gt;，这方法适合一台机器上两个 mycat 或者 1984,8066,9066 端口被其它应用占用的情况 5.2.3.2 mycat日志5.2.4 mycat防火墙设置白名单和SQL黑名单说明： 12345678910111213&lt;!--在 server.xml 中配置：--&gt;&lt;firewall&gt; &lt;!--ip 白名单列表，可以配置多个--&gt; &lt;whitehost&gt; &lt;!--ip 白名单 用户对应的可以访问的 ip 地址--&gt; &lt;host user=&quot;mycat&quot; host=&quot;127.0.0.1&quot;&gt;&lt;/host&gt; &lt;/whitehost&gt; &lt;!-是否开启检查黑名单列表--&gt; &lt;blacklist check=&quot;true&quot;&gt; &lt;!--黑名单允许的 权限 后面为默认--&gt; &lt;property name=&quot;selelctAllow&quot;&gt;false&lt;/property&gt; &lt;/blacklist&gt;&lt;/firewall&gt; 黑名单配置拦截明细如下： 配置项 缺省值 描述 rollbackAllow true 是否允许执行 roll back 操作,如果把 selectIntoAllow、deleteAllow、updateAllow、insertAllow、mergeAllow 都设置为 false，这就是一个只读数据源了。 selectAllow true 是否运行执行SELECT语句 selectAllColumnAllow true 是否允许执行 SELECT * FROM T 这样的语句。如果设置为 false，不允许执行 select * from t，但 select * from (select id, name from t) a。这个选项是防御程序通过调用 select *获得数据表的结构信息 selectIntoAllow true SELECT 查询中是否允许 INTO 字句 deleteAllow true 是否允许执行 DELETE 语句 updateAllow true 是否允许执行 UPDATE 语句 insertAllow true 是否允许执行 INSERT 语句 replaceAllow true 是否允许执行 REPLACE 语句 mergeAllow true 是否允许执行 MERGE 语句，这个只在 Oracle 中有用 callAllow true 是否允许通过 jdbc 的 call 语法调用存储过程 setAllow true 是否允许使用 SET 语法 truncateAllow true truncate 语句是危险，缺省打开，若需要自行关闭 createTableAllow true 是否允许创建表 alterTableAllow true 是否允许执行 Alter Table 语句 dropTableAllow true 是否允许修改表 commentAllow false 是否允许语句中存在注释，Oracle 的用户不用担心，Wall 能够识别 hints和注释的区别 noneBaseStatementAllow false 是否允许非以上基本语句的其他语句，缺省关闭，通过这个选项 就能够屏蔽 DDL。 multiStatementAllow false 是否允许一次执行多条语句，缺省关闭 useAllow true 是否允许执行 mysql 的 use 语句，缺省打开 describeAllow true 是否允许执行 mysql 的 describe 语句，缺省打开 showAllow true 是否允许执行 mysql 的 show 语句，缺省打开 commitAllow true 是否允许执行 commit 操作 拦截配置=-永真条件： 配置项 缺省值 描述 selectWhereAlwayTrueCheck true 检查 SELECT 语句的 WHERE 子句是否是一个永真条件 selectHavingAlwayTrueCheck true 检查 SELECT 语句的 HAVING 子句是否是一个永真条件 deleteWhereAlwayTrueCheck true 检查 DELETE 语句的 WHERE 子句是否是一个永真条件 deleteWhereNoneCheck false 检查 DELETE 语句是否无 where 条件，这是有风险的，但不是 SQL 注入类型的风险 updateWhereAlayTrueCheck true 检查 UPDATE 语句的 WHERE 子句是否是一个永真条件 updateWhereNoneCheck false 检查 UPDATE 语句是否无 where 条件，这是有风险的，但不是SQL 注入类型的风险 conditionAndAlwayTrueAllow false 检查查询条件(WHERE/HAVING 子句)中是否包含 AND 永真条件 conditionAndAlwayFalseAllow false 检查查询条件(WHERE/HAVING 子句)中是否包含 AND 永假条件 conditionLikeTrueAllow true 检查查询条件(WHERE/HAVING 子句)中是否包含 LIKE 永真条件 其他拦截配置： 配置项 缺省值 描述 selectIntoOutfileAllow false SELECT … INTO OUTFILE 是否允许，这个是 mysql 注入攻击的常见手段，缺省是禁止的 selectUnionCheck true 检测 SELECT UNION selectMinusCheck true 检测 SELECT MINUS selectExceptCheck true 检测 SELECT EXCEPT selectIntersectCheck true 检测 SELECT INTERSECT mustParameterized false 是否必须参数化，如果为 True，则不允许类似 WHERE ID = 1 这种不参数化的 SQL strictSyntaxCheck true 是否进行严格的语法检测，Druid SQL Parser 在某些场景不能覆盖所有的，SQL 语法，出现解析 SQL 出错，可以临时把这个选项设置为 false，同时把 SQL 反馈给 Druid 的开发者 conditionOpXorAllow false 查询条件中是否允许有 XOR 条件。XOR 不常用，很难判断永真或者永假，缺省不允许。 conditionOpBitwseAllow true 查询条件中是否允许有”&amp;”、”~”、” conditionDoubleConstAllow false 查询条件中是否允许连续两个常量运算表达式 minusAllow true 是否允许 SELECT * FROM A MINUS SELECT * FROM B 这样的语句 intersectAllow true 是否允许 SELECT * FROM A INTERSECT SELECT * FROM B 这样的语句 constArithmeticAllow true 拦截常量运算的条件，比如说 WHERE FID = 3 - 1，其中”3 - 1”是常量运算表达式。 limitZeroAllow false 是否允许 limit 0 这样的语句 禁用对象检测配置： 配置项 缺省值 描述 tableCheck true 检测是否使用了禁用的表 schemaCheck true 检测是否使用了禁用的 Schema functionCheck true 检测是否使用了禁用的函数 objectCheck true 检测是否使用了“禁用对对象” variantCheck true 检测是否使用了“禁用的变量” readOnlyTables 空 指定的表只读，不能够在 SELECT INTO、DELETE、UPDATE、INSERT、MERGE 中作为”被修改表”出现 5.2.5 mycat配置文件5.2.5.1 schema.xml配置schema.xml作为mycat中重要的配置文件之一，管理者mycat的逻辑库、表、分片规则、DataNode以及DataSource。 5.2.5.2 scheme标签1&lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt;&lt;/schema&gt; schema标签用于定义mycat实例中的逻辑库，mycat可以由多个逻辑库，每个逻辑库都有自己的相关配置，可以使用schema标签来划分这些不同的逻辑库。如果不配置schema标签，所有的表配置，会属于同一个默认的逻辑库。 1234567891011&lt;!--逻辑库TESTDB--&gt;&lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;travelrecord&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; &gt;&lt;/table&gt;&lt;/schema&gt;&lt;!--USERDB--&gt;&lt;schema name=&quot;USERDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;company&quot; dataNode=&quot;dn10,dn11,dn12&quot; rule=&quot;auto-sharding-long&quot; &gt;&lt;/table&gt;&lt;/schema&gt;&lt;!-- 逻辑库的概念和MySQL数据库中的database概念相同，我们在查询这两个不同的逻辑库中表的时候需要切换到该逻辑库下才可以查询到所需要的表--&gt; 在server.xml中可以配置不同的用户能够使用的schema 123456789101112131415161718192021222324&lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;property name=&quot;defaultSchema&quot;&gt;TESTDB&lt;/property&gt; &lt;!--No MyCAT Database selected 错误前会尝试使用该schema作为schema，不设置则为null,报错 --&gt; &lt;!-- 表级 DML 权限设置 --&gt; &lt;!-- &lt;privileges check=&quot;false&quot;&gt; &lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt; &lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt; &lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt;&lt;/user&gt;&lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;user&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;defaultSchema&quot;&gt;TESTDB&lt;/property&gt;&lt;/user&gt; schema标签的相关属性： 属性名 值 数量限制 dataNode 任意string （0..1） checkSQLschema Boolean （1） sqlMaxLimit Integer （1） 5.2.5.2.1 dataNode该属性用于绑定逻辑库到某个具体的database上，1.3版本如果配置了dataNode,则不可以配置分片表，1.4可以配置默认分片，只需要配置需要分片的表即可，具体配置如下： 1&lt;!--1.3版本配置--&gt;&lt;schema name=&quot;USERDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;dn1&quot;&gt;&lt;!—里面不能配置任何表--&gt;&lt;/schema&gt;&lt;!--1.4版本配置--&gt;&lt;schema name=&quot;USERDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;dn2&quot;&gt;&lt;!—配置需要分片的表--&gt; &lt;table name=“tuser” dataNode=”dn1”/&gt;&lt;/schema&gt;&lt;!-- 那么现在tuser就绑定到dn1所配置的具体database上，可以直接访问这个database，没有配置的表则会走默认的节点dn2，这里注意没有配置在分片里面的表工具查看无法显示，但是可以正常使用。--&gt; 5.2.5.2.2 checkSQLschema当改制设置为true时，我们执行“SELECT * FROM TESTDB.travelrecord；”则mycat会把语句修改为“SELECT * FROM travelrecord;”即把表示schema的字符去掉，避免发送到后端数据库执行报ERROR 1146：Table ‘testdb.travelrecord’ doest’t exist.不过，即使设置该值为 true ，如果语句所带的是并非是 schema 指定的名字，例如：select * from db1.travelrecord; 那么 MyCat 并不会删除 db1 这个字段，如果没有定义该库的话则会报错，所以在提供 SQL语句的最好是不带这个字段。 5.2.5.2.3 sqlMaxLimit当该值设置为某个数值时。每条执行的 SQL 语句，如果没有加上 limit 语句，MyCat 也会自动的加上所对应的值。例如设置值为 100，执行**select * from TESTDB.travelrecord;的效果为和执行select * from TESTDB.travelrecord limit 100;**相同。 设置该值的话，MyCat 默认会把查询到的信息全部都展示出来，造成过多的输出。所以，在正常使用中，还是建议加上一个值，用于减少过多的数据返回。 当然 SQL 语句中也显式的指定 limit 的大小，不受该属性的约束。 需要注意的是，如果运行的 schema 为非拆分库的，那么该属性不会生效。需要手动添加 limit 语句。 5.2 分配规则 范围分片：根据某个字设置auto-sharding-long，如果这个primaryKey超出了范围会报错 取模分片： ER分片（将父子表有关联的数据放在一个data-node里面） 全局表：所有dataNode存储相同的数据，查询的时候是随机查询某个表 type=global，查询的时候随机从某个datanode获取 非分片表：只在某个dataNode上存储,指定一个dataNode并且不写分片规则 单库分表：有个bug在实际数据库中必须要创建mycat中一摸一样的数据表，而且truncat的时候要现在dataNode先删除，才能删除的掉mycat的数据 5.3 全局ID 文件方式—0 数据库方式—1 本地时间戳—-2 ZK方式—-3 6. Mycat分片策略详解连续分片与离散分片 连续分片： 范围分片 日期/事件 缺点： 存在数据热点的可能性 并发访问能力受限于单一或少量DataNode（访问集中），并不能分摊数据库访问的压力 离散： 取模（partioncount 的总数必须和分片总数相同） 枚举 一致性哈希(qs-murmur) 固定分片哈希 partitionCount: 2, 1表示有三个分片必须和节点数量一致，否则会报错，前面两个一样长 partitionLength: 256, 512表示长度为256和512 综合在一起就是前面2个分片长度为256， 最后一个为512，结果如下图所示（注意partitionCount和partitionLength的数量一定要一致） 取模范围(sharting-by-pattern)：先取模PartitionByPattern后分片 范围取模: PartitionByRangeMod(partition-rane-mod.txt) ```txt 0-2000=1 #范围在2000以内的在第一个节点（取模的结果还是本身） 2001-4000=2 #范围在2001到4000以内的再模2，结果为0在第一个节点，结果为1在第三个节点 12345678910111213141516171819202122232425262728293031323334353637- 其他优点：- 并发访问能力增强（负载到不同的节点）- 范围条件查询性能提升（并行计算）缺点：- 数据扩容比较困难，设计到数据迁移问题- 数据库连接消耗比较多分片策略的选择：1） 确定分片表2） 找出分片键3） 考虑容量、增速、业务用户如果在查询语句中没有携带分片建，那么mycat会将sql发布到所有的节点上## 7. Mycat扩缩容### 7.1 在线不停机扩缩容（双写）![image-20201107205855474](./mycat/image-20201107205855474.png)### 7.2 离线扩缩容#### 7.2.1Mysql Dump```shellmysqldump -uroot -p123456 -h127.0.0.1 -p3306 -c -t --skip-extended-insert 数据库名称 &gt; mysql.11.11.sql 7.2.2 Mycat自带工具 mycat所在环境安装mysql客户端程序 mycat的lib目录下添加mysql的jdbc驱动包（mysql-connector-java-5.7.1.jar） 对扩容缩容的表所有节点数据进行备份 复制schema.xml、rule.xml并重命名为newSchema.xml、newRule.xml 修改newSchema.xml和newRule.xml配置文件为扩容缩容后的参数 在conf/migrateTable.properties配置文件中配置分片库和分片表如：imall=table_test1 dataMigrate.sh配置mysqldump路径 停止mycat服务 执行bin/dataMigrate.sh脚本（不能用openjdk） 替换schema.xml、rule.xml 注意事项： 保证分片表迁移数据前后路由规则一致（取模–&gt;取模） 保证分片表歉意数据前后分片字段一致 全局表将被忽略 不要将非分片表配置到migrateTables.properties文件中 暂时只支持分片表使用Mysql作为数据源的扩容缩容 8. Mycat读写分离8.1 主从复制 数据备份回复 负载均衡（读写分离） 高可用HA 8.2 主从复制形式; binlog(Binary log 二进制日志)12--查看binglog: SHOW binlog events in &#x27;mysql-bin.000001&#x27;--show variables like &#x27;max_blog_max&#x27; binlog配置 STATEMENT: 记录每一天修改数据的sql语句（减少日志量，节约IO） ROW: 记录哪条数据被修改了，修改成什么样子了（5.7以后默认） MIXED: 结合两种方式，一般语句用STATEMENT,函数之类的使用ROW binlog格式（mysql-bin.00001等） 查看binlog 1show binlog events in &#x27;mysql-bin.00001&#x27;; 主从复制原理SQL Thread是单线程的， 这也是所有的主从复制延迟的原因，那么relay log接受master节点的sql语句主要是用于缓冲 mycat读写分离配置 8.5 Mycat注解（hint）注解用法： 12345/*!mycat:sql=注解sql语句*/真正执行的SQL比如说在mycat上创建表无法创建成功，可以使用注解/*!mycat:sql=select * from table_1 where id = 1*/create table test2(id int);主要注解sql可以确认mycat可以路由到子结点上，就可以执行后面的真正执行的sql语句 注解用途： 跨库关联查询 DDL或存储过程 自定义分片 读写分离 分布式事务基于XA协议的两阶段提交 XA角色 XA实现 9. Mycat核心流程9.1 架构图 9.2 启动流程 MycatServer启动，解析配置文件，包括服务器、分片规则等 创建工作线程，建立前端连接和后端连接 9.3 执行SQL流程 前端连接接收mysql命令 解析MySQL，mycat用的是Druid的DruidParser 获取路由 改写MySQL，例如两个条件在两个节点上，则变成两条单独的sql 与后端数据库建立连接 发送sql语句到MySQL执行 获取返回结果 处理返回结果，例如排序、计算等等 返回给客户端 Mycat高可用","categories":[{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"mycat","slug":"mycat","permalink":"https://xiaoyuge5201.github.io/tags/mycat/"}]},{"title":"mysql事务","slug":"mysql-transcation","date":"2021-07-23T08:00:57.000Z","updated":"2021-12-11T09:20:15.738Z","comments":false,"path":"202107/mysql_03.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/mysql_03.html","excerpt":"","text":"事务的定义事务是数据管理系统DBMS执行过程中的一个逻辑单位，有一个有限的数据库操作序列构成 事务四大特性 原子性atomicity：依赖undo log做到全部失败 隔离性isolation：实现方式LBCC 和 MVCC 持久性durability ：实现方式redo log和double write 一致性consistency：通过上面的三种方式实现 数据恢复： redo log 崩溃恢复 双写缓冲（double write） Mysql中insert、delete、update 自带事务 1234show veriables like ‘autocommit’;set session autocommit = on;update xxx where set xx =1 ;commit; 结束事务两种方式：rollback commit 事务并发的三大问题数据并发的三大问题其实都是数据库读一致性问题，必须有数据库提供一定的事务隔离机制来解决。 脏读 不可重复读 幻读 事务隔离级别http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt MVCC思想 Read View（一致性试图）存储内容 Read View判断规则 RC与RR read View 的区别 所以RC解决不了脏读的问题 Mysql InnoDb所得基本类型InnoDB支持行锁 MyiSAM支持行锁 表锁和行锁的区别 锁力度：表锁 &gt; 行锁 加锁效率：表锁 &gt; 行锁 冲突概率：表锁 &gt; 行锁 并发性能：表锁 &lt; 行锁 表锁 一个事务能够给一张表加上锁的前提是：没有其他任何一个事务锁定了这张表的任意一行数据。如果没有意向锁的话，那么加表锁需要扫描表中的每行数据，大大的浪费时间； 如果在添加行锁的时候，会在表上添加意向锁，那么在添加表锁的时候就不需要去扫描所有表数据了，只需要看下表上是否由意向锁就可； 行锁共享锁shared locks 排它锁Exclusive locks Innodb行锁锁定的是什么锁定的是index索引，如果表中没有索引，那么Innodb会把隐藏列DB_ROW_ID当作聚集索引 加锁一定要加上条件，不然会锁表 记录锁Rcord Lock 锁定记录 间隙锁Gap Lock 锁定范围专门用于阻塞插入，间隙锁如果没有命中的话，会锁定最后一个值到正无穷，那么在最后一个值和正无穷之间的插入都不能成功。 临健锁Next-key Lock ：锁定范围加记录 为了解决幻读的问题 事务隔离级别的实现 事务隔离级别的选择","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"mysql知识总结","slug":"mysql","date":"2021-07-23T08:00:57.000Z","updated":"2021-12-11T09:19:00.858Z","comments":false,"path":"202107/mysql_01.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/mysql_01.html","excerpt":"","text":"mysql 初识1. 版本历史 1996年 mysql.10发布 1996年10月3.11.1发布 2000年ISAM升级成MyISAM引擎，mysql开源 2003年 Mysql4.0发布集成InnoDB存储引擎 2005年 MySQL 5.0版本发布，提供了试图，存储过程等功能 2010年MySQL5.5发布，InnoDB成为默认的存储引擎 2016年发布8.0.0版本 2. 流行分支 Maria DB Percona Server 3. SQL 执行流程通信类型 同步 异步 连接方式 长连接 短连接 超时时间 非交互式超时时间，如JDBC程序，单位s 1SHOW GLOBAL VARIABLES LIKE &#x27;wait_timeout&#x27; 交互式超时间，如数据库工具 1SHOW GLOBAL variables LIKE &#x27;interactive_timeout&#x27; 查看连接1show GLOBAL STATUS LIKE &#x27;Thread%&#x27; 连接名称 描述 Threads_cached 缓存中的线程 Threads_connected 连接中线程 Threads_created 创建过的线程 Threads_running 正在执行的线程 查看所有的线程如果是root权限，可以看到所有用户发起的线程，否则只能看到自己的线程 1show processlist id ：一个表示，kill一个语句的时候可以使用 user：显示当前用户，如果不是root，这个命令就只显示你权限范围内的sql语句 host：显示这个语句是从哪个ip的端口上发出的，可以用来追踪出问题语句的用户 db：显示这个进程目前连接的是哪个数据库 commmand：显示当年连接的执行命令，一般分为休眠slee、查询query、连接connect time：此状态持续的时间，单位是秒 state： 显示使用当年连接的sql语句状态，state只是语句执行中的某一个状态，如查询：需要经过copying to tmp table、sorting result、sending data等转台才可以完成 info：显示这个sql语句，因为长度有限，所以长的sql语句就显示不全 查看最大连接数1show variables LIKE &#x27;max_connections&#x27;; //一般默认是151，最大可以是2的14次方 mysql变量级别 global全局 1234在mysql中修改全局变量global有两种方法：1. 修改my.ini配置文件（永久有效）2. 在不修改配置文件的基础上，使用关键字global设置全局变量 set global autocommit = 1;将autocommit变量的值设置为ON，需要注意的是此方法对global全局变量的设计进对于新开启的会话有效，对已开启的会话无效，同理，如果修改回哈session变量，可以使用session关键字，如set session autocommit = 1；这个仅对本session的变量配置有效，对其他的session无效；（在MySQL服务重启之后，数据库的配置重新按照my.ini文件 初始化，global和session 的配置都会失效） session当前会话 通信协议 Unix Socket TCP/IP Named Pipes命名管道 Share Memory共享内存 通信方式 单工 半双工 全双工 MySQL 缓存12SHOW VARIABLES LIKE &#x27;query_cache%&#x27;#默认关闭，是因为mysql要保证两次执行的sql完全一致，连空格，大小写都一致，而且当数据表中的任何一条数据发生变化，整个缓存会失效； #2. 删除数据 1. 数据删除方式 DELETE Truncate Drop 2. 执行速度drop &gt; truncate &gt; delete 2.1 DELETE1DELETE FROM table_name WHERE XXX DELETE 数据数据库DML操作语言，只删除数据不删除表的结构，会走事务，执行时会触发trigger 在InnoDB中，delete其实并不会真的把数据删除，mysqL实际上只是给删除的数据打个标记为删除，因此delete删除表中的数据，表文件在磁盘所占的控件不会变小，存储控件不会被释放，只是把删除的数据设置为不可见。虽然未释放磁盘控件，但是下次插入数据的时候，仍然可以重用这部分空间（重用-&gt;覆盖） delete执行时，会先把所删除数据缓存到rollback segement中，事务commit之后生效 delete from table_name 删除表的全部数据对于MyISAM会释放磁盘控件，Innodb不会释放磁盘空间 对于DELETE from table_name where xxx带条件的删除，不管是Innodb还是MyISAM都不会释放磁盘控件 delete 操作以后使用optimize table table_name会里级释放磁盘空间（不管是Innodb还是MyISAM） 123456--查看表占用磁盘空间大小select concat(round(sum(DATA_LENGTH/1024/1024),2),&#x27;M&#x27;) as table_sizefrom information_schema.tables where table_schema=&#x27;demo_db&#x27; AND table_name=&#x27;demo_table&#x27;;-- 执行空间优化语句，以及执行后的表size变化optimize table demo_table delete 操作时一行一行执行删除的，并且同时将该行的删除操作日志记录在redo和undo表空间中以便进行回滚（rollback）和重做操作，生成大量日志也会占用磁盘空间 2.2 Truncate123--删除表数据， 不带where条件--与不带where的delete ：只删除数据，而不删除表的结构 Truncate table table_name Truncate数据数据库DDL定义语言，不走事务，原数据不放到rollback segement中，操作不触发trigger，执行后里级生效，无法找回； truncate table table_name里级释放磁盘空间不管是Innodb 和MyISAM；truncate table其实有点类似余drop table然后create，只不过这个crate table的过程做了优化，比如表结构文件之前已经有了等，所以速度上应该是接近drop table的速度 truncate 能快速清空一个表，并且重置auto_increment的值 ​ 但是对于不同的类型存储引擎需要注意的地方是： 对于MyISAM：truncate会重置auto_increment（自增序列）的值为1，而delete后表仍然保持auto_increment。 对于Innodb：truncate会重置auto_increment（自增序列）的值为1， 而delete后表仍然保持auto_increment。但是在做delete整个表之后重启mysql的话，而重启后的auto_increment会被置为1 也就是说，Innodb的表本身是无法持久保存auto_increment。delete表之后auto_increment仍然保存在内存，但是重启后就丢失了，只能从1开始，实质上重启后的auto_increment会从SELETE 1+MAX(ai_col) FROM t开始 小心使用 truncate，尤其没有备份的时候，如果误删除线上的表，记得及时联系中国民航，订票电话：400-806-9553 2.3 Drop12-- 删除表结构以及表数据Drop table table_name drop：属于数据库DDL定义语言，同Truncate； 执行后立即生效，无法找回！ 执行后立即生效，无法找回！ 执行后立即生效，无法找回！ **drop table table_name 立刻释放磁盘空间 ，不管是 InnoDB 和 MyISAM; **drop 语句将删除表的结构被依赖的约束(constrain)、触发器(trigger)、索引(index); 依赖于该表的存储过程/函数将保留,但是变为 invalid 状态。 小心使用 drop ，要删表跑路的兄弟，请在订票成功后在执行操作！订票电话：400-806-9553 3. 总结可以这么理解，一本书，delete是把目录撕了，truncate是把书的内容撕下来烧了，drop是把书烧了","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"锁优化","slug":"lock01","date":"2021-07-23T06:04:02.000Z","updated":"2021-12-11T09:23:36.313Z","comments":false,"path":"202107/lock-optimization.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/lock-optimization.html","excerpt":"","text":"1. 优化思路以及方法 减少锁持有时间 减小锁粒度 锁分离 锁粗化 锁消除 1.1 减少锁持有时间12345public synchronized void syncMethod()&#123; othercode1(); mutextMethod(); othercode2();&#125; 像上述代码，在进入方法前就要得到锁，其他线程就要在外面等待。 分析：锁里面的资源在同一时间只允许一个线程执行，我们不仅要减少其他线程等待的时间，也要尽力减少线程在锁里面的执行时间，所以，尽量只有在有线程安全要求的程序代码上加锁。 1234567public void syncMethod()&#123; othercode1(); synchronized(this)&#123; metextMethod(); &#125; othercode2();&#125; 1.2 减小锁粒度将大对象（这个对象可能会被很多线程访问）拆成小对象，大大增加并行度。 降低锁竞争，那么偏向锁、轻量级锁成功率才会提高。 最最典型的减小锁粒度的案例就是ConcurrentHashMap。在HashMap的基础上进行优化，使用了cas与synchronized来确保安全性，在保证安全性的基础上为了充分利用线程资源，更是巧妙的设计了多线程同扩容的模式。 1.3 锁分离最常见的锁分离就是读写锁ReadWriteLock，根据功能进行分离成读锁和写锁。这样读读不互斥，读写互斥，写写互斥。既保证了线程安全，又提高了性能。 分析：读写分离这种思想可以延伸到我们其他的设计中，只要操作上互不影响，那锁就可以进行分离，比如：LinkedBlockingQueue 从头部获取数据，从尾部放入数据，使用两把锁。 1.4 锁粗化通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁，只有这样，等待在这个锁上的其他线程才能尽早的获取资源执行任务；但是凡事都有一个度，如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化。 123456789public void demoMethod()&#123; synchronized&#123; //dow sth. &#125; //....做其他不需要同步的工作，但能很快执行完毕 synchronized&#123; //do sth. &#125;&#125; 这种情况，根据锁粗化的思想，应该合并： 1234567public void demoMethod()&#123; //整合成一次锁请求,前提时中间哪些不需要同步的工作很快就执行完成 synchronized(lock)&#123; //do sth. //....做其他不需要同步的工作，但能很快执行完毕 &#125;&#125; 再举一个极端的例子： 12345for(int i =0; i &lt; circle; i++)&#123; synchronized(lock)&#123; //..... &#125;&#125; 在一个循环内不同得获得锁。虽然JDK内部会对这个代码做些优化，但是还不如直接写成： 1234synchronized(lock)&#123; for(int i =0; i &lt; circle; i++)&#123; &#125;&#125; 当然如果有需求说，这样的循环太久，需要给其他线程不要等待太久，那只能写成上面那种。如果没有这样类似的需求，还是直接写成后者那种比较好。分析: 锁粗化是JVM默认启动的一种机制，锁粗化针对的是对连续的区域进行分段加锁这种场景，JVM会自发进行优化。但作为开发者而言在满足业务的情况下，应该减少锁的使用。 1.5 锁消除锁消除是在编译器级别的事情。在即时编译器(JIT)时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作。也许你会觉得奇怪，既然有些对象不可能被多线程访问，那为什么要加锁呢？写代码时直接不加锁不就好了。但是有时，这些锁并不是程序员所写的，有的是JDK实现中就有锁的，比如Vector和StringBuffer这样的类，它们中的很多方法都是有锁的。当我们在一些不会有线程安全的情况下使用这些类的方法时，达到某些条件时，编译器会将锁消除来提高性能。 1234567891011121314public static void main(String args[]) throws InterrruptedException&#123; long start = System.currentTimeTimeMillis(); for(int i = 0;i &lt; 20000; i++)&#123; createStringBuffer(&quot;JVM&quot;,&quot;asdfasdfasdf&quot;); &#125; long bufferCost = System.currentTimeTimeMillis() - start; System.out.println(&quot;createStringBuffer:&quot;+bufferCost+&quot;ms&quot;);&#125;public static String createStringBuffer(String s1, String s2)&#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString();&#125; 上述代码中的StringBuffer.append是一个同步操作，但是StringBuffer却是一个局部变量，并且方法也并没有把StringBuffer返回，所以不可能会有多线程去访问它。那么此时StringBuffer中的同步操作就是没有意义的。开启锁消除是在JVM参数上设置的，当然需要在server模式下： 1-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks 并且要开启逃逸分析。 逃逸分析的作用呢，就是看看变量是否有可能逃出作用域的范围。比如上述的StringBuffer，上述代码中craeteStringBuffer的返回是一个String，所以这个局部变量StringBuffer在其他地方都不会被使用。如果将craeteStringBuffer改成 123456public static StringBuffer createStringBuffer(String s1, String s2)&#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb;&#125; 那么这个 StringBuffer被返回后，是有可能被任何其他地方所使用的（譬如被主函数将返回结果put进map啊等等）。那么JVM的逃逸分析可以分析出，这个局部变量 StringBuffer逃出了它的作用域。所以基于逃逸分析，JVM可以判断，如果这个局部变量StringBuffer并没有逃出它的作用域，那么可以确定这个StringBuffer并不会被多线程所访问，那么就可以把这些多余的锁给去掉来提高性能。当JVM参数为： 1-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks 输出： 1createStringBuffer: 302ms JVM参数为： 1-server -XX:+DoEscapeAnalysis -XX:-EliminateLocks 输出： 1createStringBuffer: 660ms 显然，锁消除的效果还是很明显的。","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"lock","slug":"lock","permalink":"https://xiaoyuge5201.github.io/tags/lock/"}]},{"title":"ElasticSearch安装","slug":"ElasticSearch","date":"2021-07-23T05:41:24.000Z","updated":"2021-12-11T09:35:20.381Z","comments":false,"path":"202107/elastic-search-install.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/elastic-search-install.html","excerpt":"","text":"1. JDK14安装 下载jdk14： https://jdk.java.net/14/ 将文件存放在linux系统某文件夹内 解压 1tar -zxvf openjdk-14.0.2_linux-x64_bin.tar.gz 配置环境变量 123456vim /etc/profile##在文件最末尾添加，其中JAVA_HOME是jdk解压后的文件路径JAVA_HOME=/usr/lib/tools/jdk-14.0.2PATH=$JAVA_HOME/bin:$PATHCLASSPATH=$JAVA_HOME/jre/lib/ext:$JAVA_HOME/lib/tools.jarexport PATH JAVA_HOME CLASSPATH 保存后，更新配置文件 1source /etc/profile 查看JDK是否配置完成 1java -version 出现下图表示安装成功！ 2. ElasticSearch安装 解压tar.gz包 1tar -zxvf elasticsearch-7.8.0-linux-x86_64.tar.gz 添加elasticsearch用户 1useradd elastic 赋予elastic search操作文件夹的权限 1chown -R elastic:elastic /usr/lib/tools/elasticsearch-7.8.0/* 查看本机的hostname 12hostname#localhost.localdomain 修改elastic search配置 12 cd ./elasticsearch-7.8.0/configvim elasticsearch.yml elasticsearch.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#集群名称，默认可以不修改，此处 xiaoyugecluster.name: xiaoyuge# ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#节点名称，必须修改 ，默认修改为当前机器名称，若是多实例则需要区分node.name: xiaoyuge-local1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):##数据目录与日志目录，默认在当前运行程序下，生产环境需要指定#path.data: /path/to/data## Path to log files:##path.logs: /path/to/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:#内存交换锁定，此处需要操作系统设置才生效#bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#IP 地址，默认是 local，仅限本机访问，外网不可访问，设置 0.0.0.0 通用做法network.host: 192.168.135.111## Set a custom port for HTTP:#访问端口，默认 9200，9300，建议明确指定http.port: 9200transport.port: 9300## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]## 集群发现配置discovery.seed_hosts: [&quot;192.168.135.111:9300&quot;]## Bootstrap the cluster using an initial set of master-eligible nodes:#cluster.initial_master_nodes: [&quot;192.168.135.111:9300&quot;]## For more information, consult the discovery and cluster formation module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##防止批量删除索引action.destructive_requires_name: true#设置密码xpack.security.enabled: truexpack.license.self_generated.type: trialxpack.security.transport.ssl.enabled: truehttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;http.cors.allow-headers: Authorization 切换为elastic search用户，然后启动elastic search 12su elastic #切换用户./bin/elasticsearch -d #后台启动 设置密码 12345678910111213141516171819202122232425./bin/elasticsearch-setup-passwords interactive#执行设置用户名和密码的命令,这里需要为4个用户分别设置密码，elastic, kibana, logstash_system,beats_systemInitiating the setup of passwords for reserved users elastic,kibana,logstash_system,beats_system.You will be prompted to enter passwords as the process progresses.Please confirm that you would like to continue [y/N]yEnter password for [elastic]:passwords must be at least [6] characters longTry again.Enter password for [elastic]:Reenter password for [elastic]:Passwords do not match.Try again.Enter password for [elastic]:Reenter password for [elastic]:Enter password for [kibana]:Reenter password for [kibana]:Enter password for [logstash_system]:Reenter password for [logstash_system]:Enter password for [beats_system]:Reenter password for [beats_system]:Changed password for user [kibana]Changed password for user [logstash_system]Changed password for user [beats_system]Changed password for user [elastic] 常见异常： 1234 #java.lang.RuntimeException: can not run elasticsearch as root #切换为elastic search用户，不能用root项目启动 su elastic 12345#Exception in thread &quot;main&quot; java.nio.file.AccessDeniedException: /usr/lib/tools/elasticsearch-7.8.0/config/elasticsearch.keystore#elastic search用户没有操作该文件夹的权限 su rootchown -R elastic:elastic /usr/lib/tools/elasticsearch-7.8.0/* 123456789101112131415161718ERROR: [2] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] #分配内存不够#1. 修改 /etc/security/limits.confsudo vi /etc/security/limits.conf#在文件末尾加上* soft nofile 65536* hard nofile 65536* soft nproc 4096* hard nproc 4096#2. 修改 /etc/sysctl.confsudo vi /etc/sysctl.conf#在文件末尾增加vm.max_map_count=262144#3. 配置重新生效sysctl -p 效果如下： 3. Kibana安装 解压文件 1tar -zxvf kibana-7.8.0-linux-x86_64.tar.gz 修改配置文件 1vim ./config/kibana.yml kibana.yml: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Kibana is served by a back end server. This setting specifies the port to use.##访问端口，默认无需修改server.port: 5601# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.# The default is &#x27;localhost&#x27;, which usually means remote machines will not be able to connect.# To allow connections from remote users, set this parameter to a non-loopback address.#访问地址 IP，默认本地 ;如果需要外网访问，则配置0.0.0.0server.host: &quot;0.0.0.0&quot;# Enables you to specify a path to mount Kibana at if you are running behind a proxy.# Use the `server.rewriteBasePath` setting to tell Kibana if it should remove the basePath# from requests it receives, and to prevent a deprecation warning at startup.# This setting cannot end in a slash.#server.basePath: &quot;&quot;# Specifies whether Kibana should rewrite requests that are prefixed with# `server.basePath` or require that they are rewritten by your reverse proxy.# This setting was effectively always `false` before Kibana 6.3 and will# default to `true` starting in Kibana 7.0.#server.rewriteBasePath: false# The maximum payload size in bytes for incoming server requests.#server.maxPayloadBytes: 1048576# The Kibana server&#x27;s name. This is used for display purposes.#server.name: &quot;your-hostname&quot;# The URLs of the Elasticsearch instances to use for all your queries.# ES 服务指向，集群下配置多个elasticsearch.hosts: [&quot;http://192.168.135.111:9200&quot;]# When this setting&#x27;s value is true Kibana uses the hostname specified in the server.host# setting. When the value of this setting is false, Kibana uses the hostname of the host# that connects to this Kibana instance.#elasticsearch.preserveHost: true# Kibana uses an index in Elasticsearch to store saved searches, visualizations and# dashboards. Kibana creates a new index if the index doesn&#x27;t already exist.# Kibana 元数据存储索引名字，默认.kibana 无需修改#kibana.index: &quot;.kibana&quot;# The default application to load.#kibana.defaultAppId: &quot;home&quot;# If your Elasticsearch is protected with basic authentication, these settings provide# the username and password that the Kibana server uses to perform maintenance on the Kibana 启动 1234 # 当前窗口内启动 ./bin/kibana# #后台进程启动nohup ./bin/kibana &amp; 效果如下 遇见问题： root启动报错 12#切换到elastic账户su xiaoyuge elastic用户权限不足 Babel could not write cache to file: /usr/share/kibana/optimize/.babel_register_cache.json 1234567#切换到root用户su root #赋予elastic账户 xiaoyuge操作权限chown -R xiaoyuge /usr/local/kibana-7.7.1-linux-x86_64#切换为elastic账户su xiaoyuge#再次启动即可","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://xiaoyuge5201.github.io/tags/ELK/"}]},{"title":"vue学习","slug":"vue","date":"2021-07-23T03:40:44.000Z","updated":"2021-12-11T09:46:13.906Z","comments":false,"path":"202107/vue-learning.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/vue-learning.html","excerpt":"","text":"Object.freeze()，这会阻止修改现有的 property，也意味着响应系统无法再追踪变化。 1. export 用于规定模块的对外接口，export输出变量和方法、类 变量 1234567// profile.jsexport var firstName = &#x27;Michael&#x27;;export var lastName = &#x27;Jackson&#x27;;export var year = 1958;//简写--优先使用export &#123;firstName, lastName, year&#125; 方法 123//如果想为输入的变量重新命名， 可以使用AS 关键字重新命名import &#123; buildMenus as buildMenus&#125; from &#x27;@/api/menu&#x27;;//import命令接受一对大括号，里面指定要从其他模块导入的变量名。大括号里面的变量名，必须与被导入模块（profile.js）对外接口的名称相同 2. export default为模块指定默认输出， 使用import命令的时候，用户需要知道所要加载的变量名和函数名，否则无法加载；了解模块有哪些方法和属性比较麻烦，使用export default命令，为模块指定默认输出 1234// export-default.jsexport default function () &#123; console.log(&#x27;foo&#x27;);&#125; 上面代码是一个模块文件export-default.js。默认输出1个函数； 与export命令的区别：其他模块加载该模块是，import命令可以为该匿名函数指定任意名字 123// import-default.jsimport customName from &#x27;./export-default&#x27;;customName(); // &#x27;foo&#x27; 上面代码的import命令，可以用任意名称指向export-default.js输出的方法，这时就不需要知道原模块输出的函数名。需要注意的是，这时import命令后面，不使用大括号。 本质上，export default就是输出一个叫做default的变量或方法，然后系统允许你为它取任意名字。所以，下面的写法是有效的。 123456789101112// modules.jsfunction add(x, y) &#123; return x * y;&#125;export &#123;add as default&#125;;// 等同于// export default add;// app.jsimport &#123; default as foo &#125; from &#x27;modules&#x27;;// 等同于// import foo from &#x27;modules&#x27;; 正是因为export default命令其实只是输出一个叫做default的变量，所以它后面不能跟变量声明语句。 总结： export命令对外接口是有名称的且import命令从模块导入的变量名与被导入模块对外接口的名称相同，而export default命令对外输出的变量名可以是任意的，这时import命令后面，不使用大括号。 export default命令用于指定模块的默认输出。显然，一个模块只能有一个默认输出，因此export default命令只能使用一次。所以，import命令后面才不用加大括号，因为只可能唯一对应export default命令。 12345678910111213141516171819202122232425262728293031323334//menu.js//get请求获取所有的菜单信息export function buildMenus() &#123; return request(&#123; url: &#x27;api/menus/build&#x27;, method: &#x27;get&#x27; &#125;)&#125;//post 请求保存数据export function add(data) &#123; return request(&#123; url: &#x27;api/menus&#x27;, method: &#x27;post&#x27;, data &#125;)&#125;//delete 请求删除数据export function del(id) &#123; return request(&#123; url: &#x27;api/menus/&#x27; + id, method: &#x27;delete&#x27; &#125;)&#125;//put请求修改数据export function edit(data) &#123; return request(&#123; url: &#x27;api/menus&#x27;, method: &#x27;put&#x27;, data &#125;)&#125;//app.vueimport &#123; buildMenus &#125; from &#x27;@/api/menu&#x27;; 3. Const、var、let ES5 中作用域有：全局作用域、函数作用域。没有块作用域的概念。 ES6 中新增了块级作用域。块作用域由 { } 包括，if语句和 for语句里面的{ }也属于块作用域 12345678910111213141516171819202122232425&#123; var a = 1; console.log(a); // 1&#125;console.log(a); // 1// 通过var定义的变量可以跨块作用域访问到。(function A() &#123; var b = 2; console.log(b); // 2&#125;)();// console.log(b); // 报错，// 可见，通过var定义的变量不能跨函数作用域访问到if(true) &#123; var c = 3;&#125;console.log(c); // 3for(var i = 0; i &lt; 4; i ++) &#123; var d = 5;&#125;;console.log(i); // 4 (循环结束i已经是4，所以此处i为4)console.log(d); // 5// if语句和for语句中用var定义的变量可以在外面访问到，// 可见，if语句和for语句属于块作用域，不属于函数作用域 三者的区别： var定义的变量，没有块的概念，可以跨块访问, 不能跨函数访问。 let定义的变量，只能在块作用域里访问，不能跨块访问，也不能跨函数访问。 const用来定义常量，使用时必须初始化(即必须赋值)，只能在块作用域里访问，而且不能修改。 1234567891011121314151617181920212223242526272829303132// 块作用域&#123; var a = 1; let b = 2; const c = 3; // c = 4; // 报错 var aa; let bb; // const cc; // 报错 console.log(a); // 1 console.log(b); // 2 console.log(c); // 3 console.log(aa); // undefined console.log(bb); // undefined&#125;console.log(a); // 1// console.log(b); // 报错// console.log(c); // 报错// 函数作用域(function A() &#123; var d = 5; let e = 6; const f = 7; console.log(d); // 5 console.log(e); // 6 console.log(f); // 7 &#125;)();// console.log(d); // 报错// console.log(e); // 报错// console.log(f); // 报错 注意：const定义的对象属性是否可以改变 123456const person = &#123; name : &#x27;jiuke&#x27;, sex : &#x27;男&#x27;&#125;person.name = &#x27;test&#x27;console.log(person.name)//person对象的name属性确实被修改了 因为对象是引用类型的，person中保存的仅是对象的指针，这就意味着，const仅保证指针不发生改变，修改对象的属性不会改变对象的指针，所以是被允许的。也就是说const定义的引用类型只要指针不发生改变，其他的不论如何改变都是允许的。 然后我们试着修改一下指针，让person指向一个新对象，果然报错 123456789const person = &#123; name : &#x27;jiuke&#x27;, sex : &#x27;男&#x27;&#125;person = &#123; name : &#x27;test&#x27;, sex : &#x27;男&#x27;&#125;//报错 4. promisepromise用途：异步编程的一种解决方案。 优点：比传统的解决方案——回调函数和事件——更合理和更强大。 三种状态：pending（进行中）、fulfilled（已成功）和rejected（已失败）。 123456789101112131415161718//基本用法：const promise = new Promise(function(resolve, reject) &#123; resolve(value);//表示异步操作成功 reject(error);//表示异步操作失败&#125;);//promise常用的几个方法//1. 异步状态为成功时调用第一个函数，为失败时调用第二个函数。then方法的第二个参数可选。promise.then(value =&gt; &#123;&#125;,error =&gt; &#123;&#125;);//2. 异步状态为失败时调用。promise.catch(error =&gt; &#123;&#125;);//3. promise异步状态为失败时或then方法中抛出错误都会执行catch方法。promise.then(value =&gt; &#123;&#125;,error =&gt; &#123;&#125;).catch(error =&gt; &#123;&#125;);//4. 不管状态如何都会执行的操作。promise.finally(() =&gt; &#123;&#125;); 5. 生命周期 6. 模版语法v-once执行一次性插值，当数据变化的时候，该内容不会更新；可能会影响该节点其他的数据绑定 1&lt;span v-once&gt;这个将不会改变: &#123;&#123; msg &#125;&#125;&lt;/span&gt; v-html双大括号会将数据解释为普通文本，而非 HTML 代码。为了输出真正的 HTML，你需要使用v-html; 1234var rawHtml = &quot;&lt;span&gt;这是个使用v-htmls&lt;/span&gt;&quot;&lt;p&gt;Using mustaches: &#123;&#123; rawHtml &#125;&#125;&lt;/p&gt;&lt;p&gt;Using v-html directive: &lt;span v-html=&quot;rawHtml&quot;&gt;&lt;/span&gt;&lt;/p&gt; AttributeMustache ({}) 语法不能作用在 HTML attribute 上，遇到这种情况应该使用 v-bind 指令： 12345&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt;//isButtonDisabled 的值是 null、undefined 或 false，则 disabled attribute 甚至不会被包含在渲染出来的 &lt;button&gt; 元素中&lt;button v-bind:disabled=&quot;isButtonDisabled&quot;&gt;Button&lt;/button&gt; 三元表达式1234567891011121314&#123;&#123; number + 1 &#125;&#125;&#123;&#123; ok ? &#x27;YES&#x27; : &#x27;NO&#x27; &#125;&#125;&#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;&lt;div v-bind:id=&quot;&#x27;list-&#x27; + id&quot;&gt;&lt;/div&gt;//这些表达式会在所属 Vue 实例的数据作用域下作为 JavaScript 被解析。有个限制就是，每个绑定都只能包含单个表达式，所以下面的例子都不会生效。&lt;!-- 这是语句，不是表达式 --&gt;&#123;&#123; var a = 1 &#125;&#125;&lt;!-- 流控制也不会生效，请使用三元表达式 --&gt;&#123;&#123; if (ok) &#123; return message &#125; &#125;&#125; 7. 指令Directives指令 (Directives) 是带有 v- 前缀的特殊 attribute。指令 attribute 的值预期是单个 JavaScript 表达式 (v-for 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。 12//v-if 指令将根据表达式 seen 的值的真假来插入/移除 &lt;p&gt; 元素。&lt;p v-if=&quot;seen&quot;&gt;现在你看到我了&lt;/p&gt; 参数一些指令能够接收一个“参数”，在指令名称之后以冒号表示。例如，v-bind 指令可以用于响应式地更新 HTML attribute 1234//href 是参数，告知 v-bind 指令将该元素的 href attribute 与表达式 url 的值绑定&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt; 动态参数 2.6.0 开始，可以用方括号括起来的 JavaScript 表达式作为一个指令的参数 12345&lt;a v-bind:[attributeName] = &quot;url&quot;&gt;&lt;/a&gt;&lt;!-- 这里的attributeName会被作为一个javascript表达式进行动态赋值，求得的值会作为最终的参数来使用如果VUE实例有一个data. property. attributeName， 其值为href， 那么绑定将等价于v-bind:href---&gt; 绑定处理函数： 1&lt;a v-on:[eventName]=&quot;dosomething&quot;&gt;&lt;/a&gt; 对动态参数的值的约束 动态参数预期会求出一个字符串，异常情况下值为 null。这个特殊的 null 值可以被显性地用于移除绑定。任何其它非字符串类型的值都将会触发一个警告。 对动态参数表达式的约束 动态参数表达式有一些语法约束，因为某些字符，如空格和引号，放在 HTML attribute 名里是无效的。例如： 修饰符修饰符（modifier）是以半角句号. 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定；例如 .prevent修饰符告诉v-on指令对触发的事件调用event.preventDefault(); 123&lt;form v-on:submit.prevent = &quot;onSubmit&quot;&gt; &lt;/form&gt; 缩写123456789101112131415161718&lt;!-- 完整语法 --&gt;&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a :href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;!-- 动态参数的缩写 (2.6.0+) --&gt;&lt;a :[key]=&quot;url&quot;&gt; ... &lt;/a&gt;&lt;!-- 完整语法 --&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a @click=&quot;doSomething&quot;&gt;...&lt;/a&gt;&lt;!-- 动态参数的缩写 (2.6.0+) --&gt;&lt;a @[event]=&quot;doSomething&quot;&gt; ... &lt;/a&gt; : 与 @ 对于 attribute 名来说都是合法字符，在所有支持 Vue 的浏览器都能被正确地解析。而且，它们不会出现在最终渲染的标记中。 8. 计算属性123&lt;div id=&quot;example&quot;&gt; &#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;&lt;/div&gt; 这里是想要显示变量 message 的翻转字符串。当你想要在模板中的多处包含此翻转字符串时，就会更加难以处理。 所以，对于任何复杂逻辑，你都应当使用计算属性 例如： 1234&lt;div id=&quot;example&quot;&gt; &lt;p&gt;Original message: &quot;&#123;&#123; message &#125;&#125;&quot;&lt;/p&gt; &lt;p&gt;Computed reversed message: &quot;&#123;&#123; reversedMessage &#125;&#125;&quot;&lt;/p&gt;&lt;/div&gt; 1234567891011121314151617var vm = new Vue(&#123; el: &#x27;#example&#x27;, data: &#123; message: &#x27;Hello&#x27; &#125;, computed: &#123; // 计算属性的 getter reversedMessage: function () &#123; // `this` 指向 vm 实例 return this.message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125; &#125;&#125;)//页面显示：//Original message: &quot;Hello&quot;//Computed reversed message: &quot;olleH&quot; 声明了一个计算属性reversedMessage；我们提供的函数将用作property vm.reversedMessage的getter函数 123console.log(vm.reversedMessage) // olleHvm.message = &#x27;Goodbye&#x27;console.log(vm.reversedMessage) // =&gt; &#x27;eybdooG&#x27; 你可以打开浏览器的控制台，自行修改例子中的 vm。vm.reversedMessage 的值始终取决于 vm.message 的值。 你可以像绑定普通 property 一样在模板中绑定计算属性。Vue 知道 vm.reversedMessage 依赖于 vm.message，因此当 vm.message 发生改变时，所有依赖 vm.reversedMessage 的绑定也会更新。以声明的方式创建了这种依赖关系：计算属性的 getter 函数是没有副作用 (side effect) 的。 计算属性 VS 方法使用表达式中调用方法同样可以达到上面的结果 1&lt;p&gt;Reversed message: &quot;&#123;&#123; reversedMessage() &#125;&#125;&quot;&lt;/p&gt; 123456// 在组件中methods: &#123; reversedMessage: function () &#123; return this.message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125; 我们可以将同一函数定义为一个方法而不是一个计算属性。两种方式的最终结果确实是完全相同的。然而，不同的是计算属性是基于它们的响应式依赖进行缓存的。只在相关响应式依赖发生改变时它们才会重新求值。这就意味着只要 message 还没有发生改变，多次访问 reversedMessage 计算属性会立即返回之前的计算结果，而不必再次执行函数。 这也同样意味着下面的计算属性将不再更新，因为 Date.now() 不是响应式依赖： 12345computed: &#123; now: function () &#123; return Date.now() &#125;&#125; 相比之下，每当触发重新渲染时，调用方法将总会再次执行函数。 我们为什么需要缓存？假设我们有一个性能开销比较大的计算属性 A，它需要遍历一个巨大的数组并做大量的计算。然后我们可能有其他的计算属性依赖于 A。如果没有缓存，我们将不可避免的多次执行 A 的 getter！如果你不希望有缓存，请用方法来替代。 计算属性 VS 侦听属性侦听属性：vue提供了一种更通用的方式来观察和响应vue实例上的数据变动；当有一些数据需要随着其他数据变动而变动时；很容易滥用watch;通常更好的做法是使用计算属性而不是命令式的watch回调； 1&lt;div id=&quot;demo&quot;&gt;&#123;&#123; fullName &#125;&#125;&lt;/div&gt; 123456789101112131415161718192021222324var vm = new Vue(&#123; el: &#x27;#demo&#x27;, data: &#123; firstName: &#x27;Foo&#x27;, lastName: &#x27;Bar&#x27;, fullName: &#x27;Foo Bar&#x27; &#125;, //侦听属性watch watch: &#123; firstName: function (val) &#123; this.fullName = val + &#x27; &#x27; + this.lastName &#125;, lastName: function (val) &#123; this.fullName = this.firstName + &#x27; &#x27; + val &#125; &#125;, //计算属性 computed: &#123; fullName: function () &#123; return this.firstName + &#x27; &#x27; + this.lastName &#125; &#125;&#125;) 计算属性的setter计算属性默认只有getter，自己可以提供一个setter 1234567891011121314computed: &#123; fullName: &#123; // getter get: function () &#123; return this.firstName + &#x27; &#x27; + this.lastName &#125;, // setter set: function (newValue) &#123; var names = newValue.split(&#x27; &#x27;) this.firstName = names[0] this.lastName = names[names.length - 1] &#125; &#125;&#125; 现在再运行 vm.fullName = &#39;John Doe&#39; 时，setter 会被调用，vm.firstName 和 vm.lastName 也会相应地被更新。 9. 侦听器当需要在数据变化时执行异步或开销较大的操作时，watch是最有用的；同时也可以自定义侦听器； 1234567&lt;div id=&quot;watch-example&quot;&gt; &lt;p&gt; Ask a yes/no question: &lt;input v-model=&quot;question&quot;&gt; &lt;/p&gt; &lt;p&gt;&#123;&#123; answer &#125;&#125;&lt;/p&gt;&lt;/div&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!-- 因为 AJAX 库和通用工具的生态已经相当丰富，Vue 核心代码没有重复 --&gt;&lt;!-- 提供这些功能以保持精简。这也可以让你自由选择自己更熟悉的工具。 --&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/axios@0.12.0/dist/axios.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/lodash@4.13.1/lodash.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;var watchExampleVM = new Vue(&#123; el: &#x27;#watch-example&#x27;, data: &#123; question: &#x27;&#x27;, answer: &#x27;I cannot give you an answer until you ask a question!&#x27; &#125;, watch: &#123; // 如果 `question` 发生改变，这个函数就会运行 question: function (newQuestion, oldQuestion) &#123; this.answer = &#x27;Waiting for you to stop typing...&#x27; this.debouncedGetAnswer() &#125; &#125;, created: function () &#123; // `_.debounce` 是一个通过 Lodash 限制操作频率的函数。 // 在这个例子中，我们希望限制访问 yesno.wtf/api 的频率 // AJAX 请求直到用户输入完毕才会发出。想要了解更多关于 // `_.debounce` 函数 (及其近亲 `_.throttle`) 的知识， // 请参考：https://lodash.com/docs#debounce this.debouncedGetAnswer = _.debounce(this.getAnswer, 500) &#125;, methods: &#123; getAnswer: function () &#123; if (this.question.indexOf(&#x27;?&#x27;) === -1) &#123; this.answer = &#x27;Questions usually contain a question mark. ;-)&#x27; return &#125; this.answer = &#x27;Thinking...&#x27; var vm = this axios.get(&#x27;https://yesno.wtf/api&#x27;) .then(function (response) &#123; vm.answer = _.capitalize(response.data.answer) &#125;) //异常捕获 .catch(function (error) &#123; vm.answer = &#x27;Error! Could not reach the API. &#x27; + error &#125;) &#125; &#125;&#125;)&lt;/script&gt; 使用 watch 选项允许我们执行异步操作 (访问一个 API)，限制我们执行该操作的频率，并在我们得到最终结果前，设置中间状态。这些都是计算属性无法做到的 10. class与style绑定将 v-bind 用于 class 和 style 时，Vue.js 做了专门的增强。表达式结果的类型除了字符串之外，还可以是对象或数组 10.1 绑定html class10.1.1对象语法方式一：内联 123456789&lt;div class=&quot;static&quot; v-bind:class=&quot;&#123; active: isActive, &#x27;text-danger&#x27;: hasError &#125;&quot;&gt;&lt;/div&gt;//datadata: &#123; isActive: true, hasError: false&#125; 方式二：绑定的数据对象不必内联定义在模板里 12345678&lt;div v-bind:class=&quot;classObject&quot;&gt;&lt;/div&gt;//vue datadata: &#123; classObject: &#123; active: true, &#x27;text-danger&#x27;: false &#125;&#125; 方式三：绑定一个返回对象的计算属性（常用） 123456789101112131415&lt;div v-bind:class=&quot;classObject&quot;&gt;&lt;/div&gt;//vue datadata: &#123; isActive: true, error: null&#125;,computed: &#123; classObject: function () &#123; return &#123; active: this.isActive &amp;&amp; !this.error, &#x27;text-danger&#x27;: this.error &amp;&amp; this.error.type === &#x27;fatal&#x27; &#125; &#125;&#125; 10.1.2 数组语法","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://xiaoyuge5201.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://xiaoyuge5201.github.io/tags/vue/"}]},{"title":"springCloud之FeignClient访问微服务接口缓慢","slug":"bug-sprigCloud","date":"2021-07-03T09:08:10.000Z","updated":"2021-12-11T09:08:21.205Z","comments":false,"path":"202107/feignclient-of-springcloud-accesses-microservice-interface-slowly.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/feignclient-of-springcloud-accesses-microservice-interface-slowly.html","excerpt":"","text":"问题描述逻辑是A服务调用B服务(AB在同一个局域网内)。 经过反复测试，有一个访问缓慢的现象，具体表现为：程序启动第一次访问初始化1.2秒左右，还可以理解。但后面访问还是要1.1秒左右（格式化到SSS毫秒打印日志监控的）。但如果连续访问几次，后面几次又是几十毫秒。过一会再访问，或者换浏览器换post工具请求，又会1.2秒左右。 原因排查1查看连接查实的接口发现接口调用的是这个地址，其实是别人启动项目的时候吧自己的ip注册到了eureka注册中心，导致接口有时候走的是getway，有时候又是走的别人的接口 解决方法：eureka.client.register-with-eureka 为false 这样就不会注册到eureka注册中心了 原因排查2 查看日志 查看是否是hystrix 配置的时间小于了ribbon的时间","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://xiaoyuge5201.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://xiaoyuge5201.github.io/tags/SpringCloud/"}]},{"title":"ConcurrentHashMap线程安全","slug":"ConcurrentHashMap","date":"2021-07-02T08:17:29.000Z","updated":"2021-12-11T09:10:46.608Z","comments":false,"path":"202107/ConcurrentHashMap-thread-safety.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/ConcurrentHashMap-thread-safety.html","excerpt":"","text":"##1. jdk1.7 ConcurrentHashMapjdk1.7 ConcurrentHashMap是由一个Segment数组和多个HashEntry数组组成其实就是将HashMap分为多个小HashMap,每个Segment元素维护一个小HashMap,目的是锁分离，本来实现同步，直接可以是对整个HashMap加锁，但是加锁粒度太大，影响并发性能，所以变换成此结构，仅仅对Segment元素加锁，降低锁粒度，提高并发性能 ###1.1 初始化过程由于变换成Segment数组+HashEntry数组，所以初始化时，需要依次对Segment数组和HashEntry数组初始化 Segment数组初始化 初始化时，使用右移一位，乘以2的计算方式，保证ssize是2的幂次方，小于指定参数concurrencyLevel的最大2的幂次方 1234567int sshift = 0;//记录Segment数组大小int ssize = 1;while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1;&#125; HashEntry数组初始化 跟Segment数组初始化方式相同 1234int cap = 1;while(cap &lt; c)&#123; cap &lt;&lt;=1;&#125; 1.2 put操作对于插入操作，需要两次Hash映射去定位数据存储位置 首先通过第一次hash过程，定位Segment位置 然后通过第二次hash过程定位HashEntry位置 Segment继承ReentrantLock,在数据插入指定HashEntry过程的时候会尝试调用ReentrantLock的tryLock方法获取锁，如果获取成功就直接插入相应位置，如果有线程获取该Segment的锁，当前线程就会以自旋方式去继续调用tryLock方法去获取锁，超过指定次数就挂起，等待唤醒。 1.3 get操作也是两次Hash映射，相对于put操作，少了加锁过程 1.4 size操作size操作就是计算ConcurrentHashMap的大小，有两种方案 给每个Segment都加上锁(相当于给整个Map加上锁)，然后计算size返回 不加锁的模式，尝试多次计算ConcurrentHashMap的size,最多三次，比较前后计算的结果，结果一致就认为当前没有元素加入，计算结果是准确的。(查看计算出size的前后modCount的数值有没有发生变化，modCount的值用于记录元素变化的操作。如put，remove，clear) 2. jdk1.8 ConcurrentHashMapjdk1.8ConcurrentHashMap是数组+链表，或者数组+红黑树结构,并发控制使用Synchronized关键字和CAS操作 2.1关键概念点 sizeCtl变量(volatile修饰) 通过CAS操作+volatile, 控制数组初始化和扩容操作 -1 代表正在初始化 -N 前16位记录数组容量，后16位记录扩容线程大小+1，是个负数 正数0，表示未初始化 正数，0.75*当前数组大小 &lt;key,value&gt;键值对，封装为Node对象 table变量(volatile)：也就是所说的数组，默认为null，默认大小为16的数组，每次扩容时大小总是2的幂次方 nextTable(volatile):扩容时新生成的数组，大小为table的两倍 2.2put函数123public V put(K key, V value) &#123; return putVal(key, value, false);&#125; 1.putValue函数首先调用spread函数，计算hash值，之后进入一个自旋循环过程，直到插入或替换成功，才会返回。如果table未被初始化，则调用initTable进行初始化。之后判断hash映射的位置是否为null,如果为null,直接通过CAS自旋操作，插入元素成功，则直接返回，如果映射的位置值为MOVED(-1),则直接去协助扩容，排除以上条件后，尝试对链头Node节点f加锁，加锁成功后，链表通过尾插遍历，进行插入或替换。红黑树通过查询遍历，进行插入或替换。之后如果当前链表节点数量大于阈值，则调用treeifyBin函数，转换为红黑树最后通过调用addCount,执行CAS操作，更新数组大小，并且判断是否需要进行扩容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); //spread函数计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //自旋过程 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); //判断映射位置节点是否为空 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; &#125; //如果映射位置节点value==MOVED，说明正在进行扩容操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //红黑树结构 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; //链表节点数量超过阈值，转为红黑树 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 2. spread函数spread函数，计算hash值。key的hash值与其高16位相异或，然后与HASH_BITS将最高位置0 1234static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS; //HASH_BITS=0x7fffffff&#125; 3. tableAt函数获取最新的tab[i] 4. casTabAt函数通过CAS操作，将值赋值进tab中对应位置 12345678static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125;static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; 5. addCount函数尝试使用CAS操作，将BASECOUNT加1，操作失败，则说明有其他线程在进行加一操作,发生冲突。之后判断是否需要扩容 123456789101112131415161718192021222324252627282930313233343536373839404142434445private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //使用CAS操作，将BASECOUNT加1 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; //发生冲突 boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; //多线程冲突执行 fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //判断是否需要扩容 大于0.75当前数组大小 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; //判断是否需要帮助扩容 //扩容完成，或者扩容线程达到阈值不需要进行扩容，直接break if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //帮助扩容，扩容线程数+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //进行扩容操作 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125; 2.3 initTable函数进入一个自旋过程，一旦有线程扩容成功，才break 如果sizeCtl &lt; 0,说明已经有线程正在扩容，所以直接让出线程。 如果sizeCtl&gt;=0,说明当前没有线程扩容，尝试CAS操作，设置sizeCtl为-1 设置sizeCtl为-1成功的线程，进行扩容操作，并且将sc更新为数组负载阈值0.75*n123456789101112131415161718192021222324private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; //自旋过程 while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //0.75*n sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 2.4 统计ConCurrentHashMap中的元素个数1. mappingCount函数 12345//调用sumCount,获得元素数量public long mappingCount() &#123;long n = sumCount();return (n &lt; 0L) ? 0L : n; // ignore transient negative values&#125; 2. sumCount函数 baseCount+ counterCells各个元素值，就是元素数量其实baseCount就是记录容器数量的，直接放回baseCount不就可以了吗？为什么sumCount()方法中还要遍历counterCells数组，累加对象的值呢？其中：counterCells是个全局的变量，表示的是CounterCell类数组。CounterCell是ConcurrentHashmap的内部类，它就是存储一个值。JDK1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据put()或则删除数据remove()时，会通过addCount()方法更新baseCount初始化时counterCells为空，在并发量很高时，如果存在两个线程同时执行CAS修改baseCount值，则失败的线程会继续执行方法体中的逻辑，执行fullAddCount(x, uncontended)方法，这个方法其实就是初始化counterCells，并将x的值插入到counterCell类中，而x值一般也就是1或-1，这可以从put()方法中得知。这些对象是因为在CAS更新baseCount值时，由于高并发而导致失败，最终将值保存到CounterCell中，放到counterCells里。这也就是为什么sumCount()中需要遍历counterCells数组，sum累加CounterCell.value值了。 1234567891011final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 3. CounterCell类只存储一个值 1234static final class CounterCell&#123; volatile long value; CountCell(long x) &#123;value = x;&#125;&#125; 原文链接：https://blog.csdn.net/zycxnanwang/article/details/105424734","categories":[{"name":"知识整理","slug":"知识整理","permalink":"https://xiaoyuge5201.github.io/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/tags/Java/"}]},{"title":"常见sql优化方式","slug":"sql-01","date":"2021-07-01T08:00:57.000Z","updated":"2021-12-11T09:24:33.254Z","comments":false,"path":"202107/common-SQL-optimization-methods.html","link":"","permalink":"https://xiaoyuge5201.github.io/202107/common-SQL-optimization-methods.html","excerpt":"","text":"对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： 123select id from t where num is null -- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num=0 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： 12345select id from t where num=10 or num=20 --可以这样查询： select id from t where num=10 union all select id from t where num=20 in 和 not in 也要慎用，否则会导致全表扫描，如： 123select id from t where num in(1,2,3) --对于连续的数值，能用 between 就不要用 in 了： select id from t where num between 1 and 3 下面的查询也将导致全表扫描： 1select id from t where name like &#x27;%abc%&#x27; 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： 123select id from t where num/2=100 ---应改为: select id from t where num=100*2 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： 123select id from t where substring(name,1,3)=&#x27;abc&#x27;--name以abc开头的id ---应改为: select id from t where name like &#x27;abc%&#x27; 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 不要写一些没有意义的查询，如需要生成一个空表结构： 123select col1,col2 into #t from t where 1=0 --这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(...) 很多时候用 exists 代替 in 是一个好的选择： 123select num from a where num in(select num from b) --用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 尽可能的使用 varchar 代替 char ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。 避免频繁创建和删除临时表，以减少系统表资源的消耗。 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 尽量避免大事务操作，提高系统并发能力。 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"}]},{"title":"面试常见的趣味题","slug":"interest","date":"2021-06-14T02:09:15.000Z","updated":"2021-12-11T09:28:49.009Z","comments":false,"path":"202106/interesting-questions-in-interview.html","link":"","permalink":"https://xiaoyuge5201.github.io/202106/interesting-questions-in-interview.html","excerpt":"","text":"8升、5升、3升水桶各一个,如何分成两个4升 以面向对象的思想设计长方形和正方形 方式1：设计接口，然后长方形和正方形各自实现这个接口12345//形状类：结算面积和周长public interface Shape &#123; public double area(); public double perimeter();&#125; 1234567891011121314151617//长方形：实现接口并实现方法public class Rectangle implements Shape &#123; private double width; private double height; public Rectangle(double width,double height)&#123; this.width=width; this.height=height; &#125; @Override public double area() &#123; return this.width*this.height; &#125; @Override public double perimeter() &#123; return 2*(this.width+this.height); &#125;&#125; 12345678910111213141516//正方形：实现接口并实现方法public class Square implements Shape &#123; private double side; public Square(double side)&#123; this.side=side; &#125; @Override public double area() &#123; return side*side; &#125; @Override public double perimeter() &#123; return 4*side; &#125;&#125; 方式2：使用extents因为正方形 is a 长方形，所以可以使用继承来设计正方形，然后在构造函数中使用super函数； 123456789101112public class Square extends Rectangle&#123; private double side; public Square(double side)&#123; super(side,side); this.side=side; &#125; public static void main(String[] args) &#123; Square s=new Square(2.5); System.out.println(s.perimeter()); System.out.println(s.area()); &#125;&#125; java使用递归计算1+2+3+…+n之间的和1234567891011121314public class SumNumber &#123; public static void main(String[] args) &#123; System.out.println(sumN(10)); &#125; //使用递归的方法计算1+2+3+4+....n的和; 切记注意n不能小于1 public static int sumN(int n) &#123; if (n == 1)&#123; return 1; &#125; return n+ sumN(n-1); &#125;&#125; java读取一篇英文文章，并输出其中出现单词次数最多的3个单词以及次数文件文章中存在,.以及空格 读取文件内容 对文件进行内容匹配 使用map 保存单词、次数 map排序 输出1234567891011121314151617181920212223242526272829303132333435363738394041public class WordCount &#123; public static void main(String[] args) &#123; try &#123; //1. 使用流读取文件 BufferedReader reader = new BufferedReader(new FileReader(&quot;d:/n.txt&quot;)); StringBuffer sb = new StringBuffer(); String line; while ((line = reader.readLine()) != null) &#123; sb.append(line); &#125; reader.close(); //替换所有的英文逗号和句号 String temp = sb.toString().replaceAll(&quot;/[\\\\w\\\\,\\\\.]+/&quot;, &quot;&quot;); //2.使用正则表达式匹配 Pattern pattern = Pattern.compile(&quot;/[a-zA-Z\\\\w\\\\,\\\\.]+/&quot;); Matcher matcher = pattern.matcher(temp); Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(16); String word; int count; while (matcher.find()) &#123; word = matcher.group(); if (map.containsKey(word)) &#123; count = map.get(word); map.put(word, count + 1); &#125; else &#123; map.put(word, 1); &#125; &#125; //将map的数据根据count排序； List&lt;Map.Entry&lt;String, Integer&gt;&gt; list = new ArrayList&lt;&gt;(map.entrySet()); Collections.sort(list, Comparator.comparing(Map.Entry::getValue)); int last = list.size() - 1; for (int i = last; i &gt; last - 5; i--) &#123; System.out.println(&quot;key=&quot; + list.get(i).getKey() + &quot; value=&quot; + list.get(i).getValue()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; java 获取字符串第一次出现重复的字符12345678910public static int findDuplicate(String str)&#123; char[] chars = str.toCharArray(); Set&lt;Character&gt; uniqueChars = new HashSet(chars.length,1); for (int i = 0; i &lt; chars.length; i++) &#123; if (!uniqueChars.add(chars[i]))&#123; return i; &#125; &#125; return -1;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"}]},{"title":"Java内部类初始化","slug":"java-inner-class-01","date":"2021-05-31T16:00:00.000Z","updated":"2021-12-11T09:15:18.588Z","comments":false,"path":"202106/java-internal-class-initialization.html","link":"","permalink":"https://xiaoyuge5201.github.io/202106/java-internal-class-initialization.html","excerpt":"","text":"1. 在同个java文件中，但不是内部类1234567public class C &#123;&#125;//在同一个Java文件中只能存在一个public类，除内部类外//只允许使用“public”、“abstract”和“final”。class D&#123; &#125; 1234//实例化public static void main(String[] args) &#123; D d = new D();&#125; 2. 常规内部类要实例化内部类对象，必须先有外部类对象，通过外部类对象.new 内部类();来实例化内部类对象，在其他文件或者其他包内都是这样，只是要能在其他包实例化的话，内部类Inner还得加上修饰符public。 1234567891011121314151617181920212223242526public class Outter &#123; class Inner &#123; &#125; public static void main(String[] args) &#123; Outter out = new Outter(); Outter.Inner in = out.new Inner(); &#125;&#125;//第二种情况：通过提供方法来获取实例对象public class A &#123; public class B&#123; public void test()&#123; System.out.println(111); &#125; &#125; public B getInstance()&#123; return new B(); &#125; public static void main(String[] args) &#123; A a = new A(); B b = a.getInstance(); b.test(); &#125;&#125; 3. 静态内部类实例化静态内部类和实例化常规内部类有类似的地方，而不同之处在与静态内部类由于是静态的，所以不需要外部类对象就可以实例化，如上例Outter.Inner in = new Outter.Inner();在其他Java文件也是这么实例化的 12345678910class Outter &#123; static class Inner &#123;&#125;&#125;public class TestDemo &#123; public static void main(String[] args) &#123; Outter.Inner in = new Outter.Inner(); &#125;&#125; 4. 局部内部类局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内，所以只能在方法或者该作用域内实例化,局部内部类不能有访问说明符,因为它不是外围类的一部分,但是可以访问当前代码块的常量,以及此外围类的所有成员 12345678910111213141516171819public class A &#123; class B &#123; &#125; public void pint() &#123; class C &#123; &#125; new C(); &#125; public void pint(boolean b) &#123; if (b) &#123; class D &#123; &#125; new D(); &#125; &#125;&#125; 5. 匿名内部类匿名内部类可以继承一个类或实现一个接口，这里的ClassOrInterfaceName是匿名内部类所继承的类名或实现的接口名。但匿名内部类不能同时实现一个接口和继承一个类，也不能实现多个接口。如果实现了一个接口，该类是Object类的直接子类，匿名类继承一个类或实现一个接口，不需要extends和implements关键字 1234567891011ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;() &#123;&#123; add(&quot;A&quot;); add(&quot;B&quot;); add(&quot;C&quot;);&#125;&#125;;new Thread( new Runnable() &#123; public void run() &#123; ... &#125; &#125;).start();","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"内部类","slug":"内部类","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E9%83%A8%E7%B1%BB/"}]},{"title":"Linux环境下安装Redis","slug":"redis_install","date":"2021-05-13T05:40:44.000Z","updated":"2021-12-11T09:35:30.574Z","comments":false,"path":"202105/redis-install.html","link":"","permalink":"https://xiaoyuge5201.github.io/202105/redis-install.html","excerpt":"","text":"1. 安装gcc 1yum -y install gcc gcc-c++ 2. 下载安装包 1wget http://download.redis.io/redis-stable.tar.gz 3. 解压 1tar xvzf redis-stable.tar.gz 4. 编译 1234//如果使用make失败，那么就加上参数，因为jemalloc重载了Linux下的ANSI C的malloc和free函数make MALLOC=libc//make之后如果出现Hint: To run &#x27;make test&#x27; is a good idea ;//运行make test, 会提示需要安装tcl,执行yum install tcl 5. 配置密码以及允许外网ip访问 12345678910#在redis.conf中配置requirepass 密码以及port端口号（非必须）requirepass xxxport 6379 #开启redis允许外网ip访问，在 Linux 中安装了redis 服务，当在客户端通过远程连接的方式连接时，报could not connect错误。错误的原因为：redis采用的安全策略，默认会只准许本地访问。#将所有的bing信息全部屏蔽#bind 192.168.1.100 10.0.0.1#配置redis后台启动，如果不配置的话可以使用hohup启动daemonize yes 6. 启动redis服务 12cd ./srcnohup ./redis-server ../redis.conf &amp; 7. 查看redis进程 1[root@localhost redis]# pstree","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"}]},{"title":"在线修改静态文件","slug":"在线修改静态文件","date":"2021-05-13T05:40:44.000Z","updated":"2021-12-11T09:29:08.740Z","comments":false,"path":"202105/tatic-file-modify-online.html","link":"","permalink":"https://xiaoyuge5201.github.io/202105/tatic-file-modify-online.html","excerpt":"","text":"项目运行时，如果需要修改某个css、js、html等文件的时候，需要自己连接到服务器然后修改，更有甚者需要连接vpn、堡垒机等等，特别烦！！！！于是弄了一个在线修改静态文件的工具，在此记录一下。 1. 引入pom12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoyuge5201&lt;/groupId&gt; &lt;artifactId&gt;static-file-modify-online&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt;&lt;/dependency&gt; 2. 添加前后台代码前台使用的是thymeleaf，根据自己项目的实际情况修改！ 12链接: https://pan.baidu.com/s/1oW38vpj74yKOOtbu5xGCOQ 密码: tcmg","categories":[{"name":"技术实践","slug":"技术实践","permalink":"https://xiaoyuge5201.github.io/categories/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/"}],"tags":[{"name":"个人工具","slug":"个人工具","permalink":"https://xiaoyuge5201.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/"}]},{"title":"Java线程的声明周期状态","slug":"thread-status","date":"2020-06-02T08:04:02.000Z","updated":"2021-12-11T09:25:30.386Z","comments":false,"path":"202006/thread-status.html","link":"","permalink":"https://xiaoyuge5201.github.io/202006/thread-status.html","excerpt":"","text":"**新建(NEW)**：新创建了一个线程对象。 **可运行(RUNNABLE)**：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。 **运行(RUNNING)**：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。 **阻塞(BLOCKED)**：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。 **死亡(DEAD)**：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。","categories":[{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xiaoyuge5201.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java 8学习","slug":"java8特性","date":"2020-04-23T06:04:02.000Z","updated":"2021-12-11T09:14:44.090Z","comments":false,"path":"202004/java8-learning.html","link":"","permalink":"https://xiaoyuge5201.github.io/202004/java8-learning.html","excerpt":"","text":"1. OptionalOptional 类主要解决的问题是臭名昭著的空指针异常（NullPointerException)。本质上，这是一个包含有可选值的包装类，这意味着 Optional 类既可以含有对象也可以为空 1.1. optional构造方式 Optional.of(T) 该方式的入参不能为null，否则会有NPE，在确定入参不为空时使用该方式。 Optional.ofNullable(T) 该方式的入参可以为null，当入参不确定为非null时使用。 Optional.empty() 这种方式是返回一个空Optional，等效Optional.ofNullable(null) 1.2. 如何正确的使用Optional 尽量避免使用的地方 避免使用Optional.isPresent()来检查实例是否存在，因为这种方式和null != obj没有区别，这样用就没什么意义了。 避免使用Optional.get()方式来获取实例对象，因为使用前需要使用Optional.isPresent()来检查实例是否存在，否则会出现NPE问题。 避免使用Optional作为类或者实例的属性，而应该在返回值中用来包装返回实例对象。 避免使用Optional作为方法的参数，原因同3。 正确使用方式 实例对象存在则返回，否则提供默认值或者通过方法来设置返回值，即使用orElse/orElseGet方式： 12345678910111213141516171819202122//存在则返回User king = new User(1, &quot;king&quot;);Optional&lt;User&gt; userOpt = Optional.of(king);User user = userOpt.orElse(null);System.out.println(user.getName());//不存在提供默认值User user2 = null;Optional&lt;User&gt; userOpt2 = Optional.ofNullable(user2);User user3 = userOpt2.orElse(unknown);System.out.println(user3.getName());//通过方法提供值User user4 = userOpt2.orElseGet(() -&gt; new User(0, &quot;DEFAULT&quot;)); System.out.println(user4.getName()) //不建议下面这种使用if(userOpt.isPresent()) &#123; System.out.println(userOpt.get().getName());&#125; else &#123; //。。。&#125; 使用ifPresent()来进行对象操作，存在则操作，否则不操作。 123//实例存在则操作，否则不操作userOpt.ifPresent(u -&gt; System.out.println(u.getName()));userOpt2.ifPresent(u -&gt; System.out.println(u.getName())); 使用map/flatMap来获取关联数据 1234567891011//使用map方法获取关联数据System.out.println(userOpt.map(u -&gt; u.getName()).orElse(&quot;Unknown&quot;));System.out.println(userOpt2.map(u -&gt; u.getName()).orElse(&quot;Default&quot;));//使用flatMap方法获取关联数据List&lt;String&gt; interests = new ArrayList&lt;String&gt;();interests.add(&quot;a&quot;);interests.add(&quot;b&quot;);interests.add(&quot;c&quot;);user.setInterests(interests);List&lt;String&gt; interests2 = Optional.of(user) .flatMap(u -&gt; Optional.ofNullable(u.getInterests())) .orElse(Collections.emptyList());System.out.println(interests2.isEmpty()); 1.3.Optional判断第三方接口使用java8的optional可以减少很多的NPE，再也不用当心别人的接口返回值问题了，也不用满屏的if（a != null）这种判断，下面是使用过程中遇到的问题以及如何使用Optional解决。 1.3.1. 接口返回参数问题 在微服务中使用feign调用其他接口，总担心别人返回的参数是否符合标准 参数符合标准后，然后再进行数据判断，先判断是否code为200，然后判断数据存不存在，这样冗余的代码就很多 这是我们期望的返回格式 12345&#123; &quot;code&quot;: &quot;200&quot;, &quot;msg&quot;: &quot;调用成功!&quot;, &quot;data&quot;: []&#125; 12345678//模拟接口调用方法Map&lt;String,Object&gt; map = serviceImpl.queryList();//即使map为空也能正常返回，配合map直接映射数据值return Optional.ofNullable(map).map(r-&gt; r.get(&quot;data&quot;)).orElseGet(ArrayList:: new) //JSONObject 判断是否返回成功，如果成功返回200， 不成功返回400 JSONObject jsonObject = service.updateDate();Optional.ofNullable(jsonObject).map(r-&gt;r.getInteger(&quot;code&quot;)).orElse(400) 1.3.2. 避免判断风暴对象层层嵌套，为了逻辑严谨必须要进行空判断 1234567891011121314151617181920//对于一个对象里面嵌套对象，那么需要层层去判断非空School school = null;if(school != null)&#123; Clazz clazz = school.getClazz(); if(clazz != null)&#123; Student student = clazz.getStudent(); if(student != null)&#123; String name = student.getName(); if(name == null || &quot;&quot;.equals(name))&#123; name = &quot;学生的姓名为空&quot;; &#125; &#125; &#125;&#125;//使用Optional后 String name = Optional.ofNullable(school) .map(School::getClazz) .map(Clazz::getStudent) .map(Student::getName) .orElse(&quot;学生的姓名为空&quot;); 2. Stream123//找出某一个字段等于某个值的那一条数据JaponicaRiceCheck1 streamCheck = listItemRice.stream().filter(o -&gt; o.getSYS_PARENTID().equals(check.getSYS_ID())).findAny().orElse(null);","categories":[{"name":"知识整理","slug":"知识整理","permalink":"https://xiaoyuge5201.github.io/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]}],"categories":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/categories/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://xiaoyuge5201.github.io/categories/Docker/"},{"name":"Nginx","slug":"Nginx","permalink":"https://xiaoyuge5201.github.io/categories/Nginx/"},{"name":"数据库","slug":"数据库","permalink":"https://xiaoyuge5201.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/categories/Java/"},{"name":"算法","slug":"算法","permalink":"https://xiaoyuge5201.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://xiaoyuge5201.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"},{"name":"中间件","slug":"中间件","permalink":"https://xiaoyuge5201.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"学习笔记","slug":"学习笔记","permalink":"https://xiaoyuge5201.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"知识整理","slug":"知识整理","permalink":"https://xiaoyuge5201.github.io/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"},{"name":"技术实践","slug":"技术实践","permalink":"https://xiaoyuge5201.github.io/categories/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://xiaoyuge5201.github.io/tags/Linux/"},{"name":"nginx","slug":"nginx","permalink":"https://xiaoyuge5201.github.io/tags/nginx/"},{"name":"mysql","slug":"mysql","permalink":"https://xiaoyuge5201.github.io/tags/mysql/"},{"name":"docker","slug":"docker","permalink":"https://xiaoyuge5201.github.io/tags/docker/"},{"name":"tidb","slug":"tidb","permalink":"https://xiaoyuge5201.github.io/tags/tidb/"},{"name":"集合","slug":"集合","permalink":"https://xiaoyuge5201.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"shutdown","slug":"shutdown","permalink":"https://xiaoyuge5201.github.io/tags/shutdown/"},{"name":"Centos","slug":"Centos","permalink":"https://xiaoyuge5201.github.io/tags/Centos/"},{"name":"线程","slug":"线程","permalink":"https://xiaoyuge5201.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"algorithm","slug":"algorithm","permalink":"https://xiaoyuge5201.github.io/tags/algorithm/"},{"name":"springboot","slug":"springboot","permalink":"https://xiaoyuge5201.github.io/tags/springboot/"},{"name":"hexo","slug":"hexo","permalink":"https://xiaoyuge5201.github.io/tags/hexo/"},{"name":"守护线程","slug":"守护线程","permalink":"https://xiaoyuge5201.github.io/tags/%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B/"},{"name":"redis","slug":"redis","permalink":"https://xiaoyuge5201.github.io/tags/redis/"},{"name":"内存溢出","slug":"内存溢出","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/"},{"name":"ClassLoader","slug":"ClassLoader","permalink":"https://xiaoyuge5201.github.io/tags/ClassLoader/"},{"name":"mycat","slug":"mycat","permalink":"https://xiaoyuge5201.github.io/tags/mycat/"},{"name":"lock","slug":"lock","permalink":"https://xiaoyuge5201.github.io/tags/lock/"},{"name":"ELK","slug":"ELK","permalink":"https://xiaoyuge5201.github.io/tags/ELK/"},{"name":"vue","slug":"vue","permalink":"https://xiaoyuge5201.github.io/tags/vue/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://xiaoyuge5201.github.io/tags/SpringCloud/"},{"name":"Java","slug":"Java","permalink":"https://xiaoyuge5201.github.io/tags/Java/"},{"name":"内部类","slug":"内部类","permalink":"https://xiaoyuge5201.github.io/tags/%E5%86%85%E9%83%A8%E7%B1%BB/"},{"name":"个人工具","slug":"个人工具","permalink":"https://xiaoyuge5201.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%B7%A5%E5%85%B7/"},{"name":"java","slug":"java","permalink":"https://xiaoyuge5201.github.io/tags/java/"}]}